{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. cell 생성 및 rnn 구동 (input = (1,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 차원:  (1, 1, 4)\n",
      "출력 값:  [[[-0.08205257 -0.01191202]]]\n",
      "출력 차원:  (1, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[[1,0,0,0]]], dtype=np.float32)\n",
    "\n",
    "#ht에 대한 dimension 정의\n",
    "hidden_size = 2\n",
    "print(\"입력 데이터 차원: \", x_data.shape)\n",
    "\n",
    "\n",
    "with tf.variable_scope('lstm1', reuse=True):\n",
    "    \n",
    "    #1. cell 정의(ht에 대한 dimension 정의)\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    \n",
    "    #2. cell 구동\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(\"출력 값: \", outputs.eval())\n",
    "    print(\"출력 차원: \", outputs.eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. cell 생성 및 rnn 구동(input = (1,5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 차원:  (1, 5, 4)\n",
      "출력 값:  [[[ 0.04653593 -0.09376747]\n",
      "  [ 0.07885884 -0.1869417 ]\n",
      "  [ 0.12290448 -0.07888173]\n",
      "  [ 0.15421937  0.00226069]\n",
      "  [ 0.13376617  0.1231476 ]]]\n",
      "출력 차원:  (1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "#ht에 대한 dimension 정의\n",
    "hidden_size = 2\n",
    "\n",
    "h = [1,0,0,0]\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]\n",
    "\n",
    "x_data = np.array([[h,e,l,l,o]], dtype=np.float32)\n",
    "print(\"입력 데이터 차원: \", x_data.shape)\n",
    "\n",
    "with tf.variable_scope('lstm1', reuse=True):\n",
    "    #1. cell 정의(ht에 대한 dimension 정의)\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    \n",
    "    #2. cell 구동\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(\"출력 값: \", outputs.eval())\n",
    "    print(\"출력 차원: \", outputs.eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. cell 생성 및 rnn 구동(input = (3,5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 차원:  (3, 5, 4)\n",
      "출력 값:  [[[ 0.08319841 -0.07219824]\n",
      "  [-0.03352327 -0.10916224]\n",
      "  [ 0.06199432 -0.04653881]\n",
      "  [ 0.13939244 -0.0192358 ]\n",
      "  [ 0.10877636 -0.04709471]]\n",
      "\n",
      " [[-0.09506787 -0.057366  ]\n",
      "  [-0.05326831 -0.03307088]\n",
      "  [ 0.05138043  0.00655901]\n",
      "  [ 0.12849385  0.01301786]\n",
      "  [ 0.10040542 -0.0195493 ]]\n",
      "\n",
      " [[ 0.09069875  0.01526689]\n",
      "  [-0.03492649 -0.05159034]\n",
      "  [-0.12483385 -0.09275628]\n",
      "  [-0.03942011 -0.02740682]\n",
      "  [ 0.06261769  0.00357484]]]\n",
      "출력 차원:  (3, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "#ht에 대한 dimension 정의\n",
    "hidden_size = 2\n",
    "\n",
    "h = [1,0,0,0]\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]\n",
    "\n",
    "x_data = np.array([[h,e,l,l,o],\n",
    "                   [e,o,l,l,o],\n",
    "                   [l,e,e,l,l]], dtype=np.float32)\n",
    "\n",
    "print(\"입력 데이터 차원: \", x_data.shape)\n",
    "\n",
    "with tf.variable_scope('lstm1', reuse=True):\n",
    "    #1. cell 정의(ht에 대한 dimension 정의)\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    \n",
    "    #2. cell 구동\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(\"출력 값: \", outputs.eval())\n",
    "    print(\"출력 차원: \", outputs.eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4. RNN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 차원:  (1, 6, 5)\n",
      "목표 데이터 차원:  (1, 6)\n",
      "0 loss:  1.69838 prediction:  [[4 0 4 2 3 3]] true Y:  [[1 0 2 3 3 4]]\n",
      "[4 0 4 2 3 3]\n",
      "\tPrediction str:  ohoell\n",
      "100 loss:  0.460376 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "200 loss:  0.450198 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "300 loss:  0.446881 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "400 loss:  0.444936 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "500 loss:  0.443614 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "600 loss:  0.442638 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "700 loss:  0.441877 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "800 loss:  0.441261 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "900 loss:  0.440749 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1000 loss:  0.440313 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1100 loss:  0.439935 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1200 loss:  0.439604 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1300 loss:  0.439309 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1400 loss:  0.439045 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1500 loss:  0.438806 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1600 loss:  0.438589 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1700 loss:  0.438389 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1800 loss:  0.438219 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n",
      "1900 loss:  0.438057 prediction:  [[1 0 2 3 3 4]] true Y:  [[1 0 2 3 3 4]]\n",
      "[1 0 2 3 3 4]\n",
      "\tPrediction str:  ihello\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 6\n",
    "input_dim = 5\n",
    "batch_size = 1\n",
    "\n",
    "#1. 데이터 정의\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "x_data = [[0, 1, 0, 2, 3, 3]] #hihell\n",
    "x_one_hot = [[[1,0,0,0,0],\n",
    "              [0,1,0,0,0],\n",
    "              [1,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,1,0],\n",
    "              [0,0,0,1,0]]]\n",
    "\n",
    "x_data = np.array(x_one_hot) \n",
    "y_data = np.array([[1,0,2,3,3,4]]) # ihello\n",
    "\n",
    "print(\"입력 데이터 차원: \", x_data.shape)\n",
    "print(\"목표 데이터 차원: \", y_data.shape)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "#2. cell 정의\n",
    "with tf.variable_scope('lstm1'):\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units=input_dim)\n",
    "    iniital_state = cell.zero_state(batch_size, tf.float32)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, X, initial_state=iniital_state, dtype=tf.float32)\n",
    "\n",
    "    #3. cost function 정의\n",
    "    weights = tf.ones([batch_size, sequence_length])\n",
    "    sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "    loss = tf.reduce_mean(sequence_loss)\n",
    "\n",
    "    #4. optimizer 정의\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "    #5. prediction 정의\n",
    "    prediction = tf.argmax(outputs, axis=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(2000):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_one_hot, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_one_hot})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i, \"loss: \", l, \"prediction: \", result, \"true Y: \", y_data)\n",
    "\n",
    "            #print char using dic\n",
    "            print(np.squeeze(result))\n",
    "            result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "            print('\\tPrediction str: ', ''.join(result_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
