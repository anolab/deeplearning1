{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. short sequence RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. 데이터 정의\n",
    "sample = \"if you want me\"\n",
    "idx2char = list(set(sample))\n",
    "char2idx = {c: i for i, c in enumerate(idx2char)}\n",
    "\n",
    "#hyper parameter\n",
    "dic_size = len(char2idx)\n",
    "rnn_hidden_size = len(char2idx)\n",
    "num_classes = len(char2idx)\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = len(sample) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_idx = [char2idx[c] for c in sample]\n",
    "\n",
    "x_data = [sample_idx[:-1]] # x_data\n",
    "y_data = [sample_idx[1:]] # y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', 'w', 'e', 'n', 'y', 'a', 't', 'f', 'u', 'o', ' ', 'i']\n",
      "{'m': 0, 'w': 1, 'e': 2, 'n': 3, 'y': 4, 'a': 5, 't': 6, 'f': 7, 'u': 8, 'o': 9, ' ': 10, 'i': 11}\n"
     ]
    }
   ],
   "source": [
    "print(idx2char)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_one_hot = tf.one_hot(X, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. cell 정의\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _staes = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. loss 정의\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. optimizer 정의\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. prediction 정의\n",
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  2.47518 Prediction:  oonwwnnanayyy\n",
      "1 loss:  2.47259 Prediction:  oonwwnnanayyn\n",
      "2 loss:  2.47003 Prediction:  oonwwnnanayyn\n",
      "3 loss:  2.46752 Prediction:  o nwwnnanay n\n",
      "4 loss:  2.46506 Prediction:  o nwwnnanay n\n",
      "5 loss:  2.46264 Prediction:  o nwwnnanay n\n",
      "6 loss:  2.46026 Prediction:  o  wwnnann  n\n",
      "7 loss:  2.45793 Prediction:  o  wwnnann  n\n",
      "8 loss:  2.45564 Prediction:  o  wwnnann  n\n",
      "9 loss:  2.4534 Prediction:  o  uwnnnnn  n\n",
      "10 loss:  2.45119 Prediction:  o  uwnnnnn  n\n",
      "11 loss:  2.44903 Prediction:  o  uwnnnn   n\n",
      "12 loss:  2.4469 Prediction:  o  uu nnn   n\n",
      "13 loss:  2.44482 Prediction:  o   u nnn   n\n",
      "14 loss:  2.44277 Prediction:  o       n   n\n",
      "15 loss:  2.44076 Prediction:  o       n    \n",
      "16 loss:  2.43879 Prediction:  o       n    \n",
      "17 loss:  2.43685 Prediction:  o       n    \n",
      "18 loss:  2.43494 Prediction:  o       n    \n",
      "19 loss:  2.43307 Prediction:  o       n    \n",
      "20 loss:  2.43123 Prediction:  o       n    \n",
      "21 loss:  2.42942 Prediction:  o       n    \n",
      "22 loss:  2.42764 Prediction:  o       n    \n",
      "23 loss:  2.42589 Prediction:  o       n    \n",
      "24 loss:  2.42417 Prediction:  o       n    \n",
      "25 loss:  2.42248 Prediction:  o       n    \n",
      "26 loss:  2.42081 Prediction:  o       n    \n",
      "27 loss:  2.41917 Prediction:  o       n    \n",
      "28 loss:  2.41755 Prediction:  o            \n",
      "29 loss:  2.41595 Prediction:  o            \n",
      "30 loss:  2.41438 Prediction:  o            \n",
      "31 loss:  2.41283 Prediction:  o            \n",
      "32 loss:  2.4113 Prediction:  o            \n",
      "33 loss:  2.40979 Prediction:  o            \n",
      "34 loss:  2.4083 Prediction:  o            \n",
      "35 loss:  2.40683 Prediction:               \n",
      "36 loss:  2.40538 Prediction:               \n",
      "37 loss:  2.40394 Prediction:               \n",
      "38 loss:  2.40252 Prediction:               \n",
      "39 loss:  2.40112 Prediction:               \n",
      "40 loss:  2.39974 Prediction:               \n",
      "41 loss:  2.39837 Prediction:               \n",
      "42 loss:  2.39701 Prediction:               \n",
      "43 loss:  2.39567 Prediction:               \n",
      "44 loss:  2.39434 Prediction:               \n",
      "45 loss:  2.39303 Prediction:               \n",
      "46 loss:  2.39173 Prediction:               \n",
      "47 loss:  2.39044 Prediction:               \n",
      "48 loss:  2.38916 Prediction:               \n",
      "49 loss:  2.3879 Prediction:               \n",
      "50 loss:  2.38665 Prediction:               \n",
      "51 loss:  2.3854 Prediction:               \n",
      "52 loss:  2.38417 Prediction:               \n",
      "53 loss:  2.38295 Prediction:               \n",
      "54 loss:  2.38174 Prediction:               \n",
      "55 loss:  2.38054 Prediction:               \n",
      "56 loss:  2.37935 Prediction:               \n",
      "57 loss:  2.37816 Prediction:               \n",
      "58 loss:  2.37699 Prediction:               \n",
      "59 loss:  2.37582 Prediction:               \n",
      "60 loss:  2.37467 Prediction:               \n",
      "61 loss:  2.37352 Prediction:               \n",
      "62 loss:  2.37238 Prediction:               \n",
      "63 loss:  2.37125 Prediction:               \n",
      "64 loss:  2.37012 Prediction:               \n",
      "65 loss:  2.36901 Prediction:               \n",
      "66 loss:  2.3679 Prediction:               \n",
      "67 loss:  2.3668 Prediction:               \n",
      "68 loss:  2.3657 Prediction:               \n",
      "69 loss:  2.36461 Prediction:               \n",
      "70 loss:  2.36353 Prediction:               \n",
      "71 loss:  2.36245 Prediction:               \n",
      "72 loss:  2.36139 Prediction:               \n",
      "73 loss:  2.36032 Prediction:               \n",
      "74 loss:  2.35927 Prediction:               \n",
      "75 loss:  2.35822 Prediction:               \n",
      "76 loss:  2.35717 Prediction:               \n",
      "77 loss:  2.35613 Prediction:               \n",
      "78 loss:  2.3551 Prediction:               \n",
      "79 loss:  2.35407 Prediction:               \n",
      "80 loss:  2.35305 Prediction:               \n",
      "81 loss:  2.35204 Prediction:               \n",
      "82 loss:  2.35102 Prediction:               \n",
      "83 loss:  2.35002 Prediction:               \n",
      "84 loss:  2.34902 Prediction:               \n",
      "85 loss:  2.34802 Prediction:               \n",
      "86 loss:  2.34703 Prediction:               \n",
      "87 loss:  2.34604 Prediction:               \n",
      "88 loss:  2.34506 Prediction:               \n",
      "89 loss:  2.34408 Prediction:               \n",
      "90 loss:  2.3431 Prediction:               \n",
      "91 loss:  2.34213 Prediction:               \n",
      "92 loss:  2.34117 Prediction:               \n",
      "93 loss:  2.34021 Prediction:               \n",
      "94 loss:  2.33925 Prediction:               \n",
      "95 loss:  2.33829 Prediction:               \n",
      "96 loss:  2.33734 Prediction:               \n",
      "97 loss:  2.3364 Prediction:               \n",
      "98 loss:  2.33545 Prediction:               \n",
      "99 loss:  2.33451 Prediction:               \n",
      "100 loss:  2.33358 Prediction:               \n",
      "101 loss:  2.33264 Prediction:               \n",
      "102 loss:  2.33171 Prediction:               \n",
      "103 loss:  2.33079 Prediction:               \n",
      "104 loss:  2.32986 Prediction:               \n",
      "105 loss:  2.32894 Prediction:               \n",
      "106 loss:  2.32802 Prediction:               \n",
      "107 loss:  2.32711 Prediction:               \n",
      "108 loss:  2.3262 Prediction:               \n",
      "109 loss:  2.32529 Prediction:               \n",
      "110 loss:  2.32438 Prediction:               \n",
      "111 loss:  2.32347 Prediction:               \n",
      "112 loss:  2.32257 Prediction:               \n",
      "113 loss:  2.32167 Prediction:               \n",
      "114 loss:  2.32077 Prediction:               \n",
      "115 loss:  2.31987 Prediction:               \n",
      "116 loss:  2.31898 Prediction:               \n",
      "117 loss:  2.31809 Prediction:               \n",
      "118 loss:  2.3172 Prediction:               \n",
      "119 loss:  2.31631 Prediction:               \n",
      "120 loss:  2.31542 Prediction:               \n",
      "121 loss:  2.31454 Prediction:               \n",
      "122 loss:  2.31365 Prediction:               \n",
      "123 loss:  2.31277 Prediction:               \n",
      "124 loss:  2.31189 Prediction:               \n",
      "125 loss:  2.31101 Prediction:               \n",
      "126 loss:  2.31013 Prediction:               \n",
      "127 loss:  2.30925 Prediction:               \n",
      "128 loss:  2.30837 Prediction:               \n",
      "129 loss:  2.3075 Prediction:               \n",
      "130 loss:  2.30663 Prediction:               \n",
      "131 loss:  2.30575 Prediction:               \n",
      "132 loss:  2.30488 Prediction:               \n",
      "133 loss:  2.30401 Prediction:               \n",
      "134 loss:  2.30314 Prediction:               \n",
      "135 loss:  2.30227 Prediction:               \n",
      "136 loss:  2.3014 Prediction:               \n",
      "137 loss:  2.30053 Prediction:               \n",
      "138 loss:  2.29966 Prediction:               \n",
      "139 loss:  2.29879 Prediction:               \n",
      "140 loss:  2.29792 Prediction:               \n",
      "141 loss:  2.29706 Prediction:               \n",
      "142 loss:  2.29619 Prediction:               \n",
      "143 loss:  2.29532 Prediction:               \n",
      "144 loss:  2.29445 Prediction:               \n",
      "145 loss:  2.29359 Prediction:               \n",
      "146 loss:  2.29272 Prediction:               \n",
      "147 loss:  2.29185 Prediction:               \n",
      "148 loss:  2.29099 Prediction:               \n",
      "149 loss:  2.29012 Prediction:               \n",
      "150 loss:  2.28925 Prediction:               \n",
      "151 loss:  2.28838 Prediction:               \n",
      "152 loss:  2.28752 Prediction:               \n",
      "153 loss:  2.28665 Prediction:               \n",
      "154 loss:  2.28578 Prediction:               \n",
      "155 loss:  2.28491 Prediction:               \n",
      "156 loss:  2.28404 Prediction:               \n",
      "157 loss:  2.28317 Prediction:               \n",
      "158 loss:  2.2823 Prediction:               \n",
      "159 loss:  2.28143 Prediction:               \n",
      "160 loss:  2.28056 Prediction:               \n",
      "161 loss:  2.27969 Prediction:               \n",
      "162 loss:  2.27881 Prediction:               \n",
      "163 loss:  2.27794 Prediction:               \n",
      "164 loss:  2.27707 Prediction:               \n",
      "165 loss:  2.27619 Prediction:               \n",
      "166 loss:  2.27531 Prediction:               \n",
      "167 loss:  2.27444 Prediction:               \n",
      "168 loss:  2.27356 Prediction:               \n",
      "169 loss:  2.27268 Prediction:               \n",
      "170 loss:  2.2718 Prediction:               \n",
      "171 loss:  2.27092 Prediction:               \n",
      "172 loss:  2.27003 Prediction:               \n",
      "173 loss:  2.26915 Prediction:               \n",
      "174 loss:  2.26827 Prediction:               \n",
      "175 loss:  2.26738 Prediction:               \n",
      "176 loss:  2.26649 Prediction:               \n",
      "177 loss:  2.2656 Prediction:               \n",
      "178 loss:  2.26471 Prediction:               \n",
      "179 loss:  2.26382 Prediction:               \n",
      "180 loss:  2.26293 Prediction:               \n",
      "181 loss:  2.26204 Prediction:               \n",
      "182 loss:  2.26114 Prediction:               \n",
      "183 loss:  2.26024 Prediction:               \n",
      "184 loss:  2.25934 Prediction:               \n",
      "185 loss:  2.25844 Prediction:               \n",
      "186 loss:  2.25754 Prediction:               \n",
      "187 loss:  2.25664 Prediction:               \n",
      "188 loss:  2.25573 Prediction:               \n",
      "189 loss:  2.25483 Prediction:               \n",
      "190 loss:  2.25392 Prediction:               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 loss:  2.25301 Prediction:               \n",
      "192 loss:  2.2521 Prediction:               \n",
      "193 loss:  2.25118 Prediction:               \n",
      "194 loss:  2.25027 Prediction:               \n",
      "195 loss:  2.24935 Prediction:               \n",
      "196 loss:  2.24843 Prediction:               \n",
      "197 loss:  2.24751 Prediction:               \n",
      "198 loss:  2.24659 Prediction:               \n",
      "199 loss:  2.24566 Prediction:               \n",
      "200 loss:  2.24473 Prediction:               \n",
      "201 loss:  2.2438 Prediction:               \n",
      "202 loss:  2.24287 Prediction:               \n",
      "203 loss:  2.24194 Prediction:               \n",
      "204 loss:  2.24101 Prediction:               \n",
      "205 loss:  2.24007 Prediction:               \n",
      "206 loss:  2.23913 Prediction:               \n",
      "207 loss:  2.23819 Prediction:               \n",
      "208 loss:  2.23725 Prediction:               \n",
      "209 loss:  2.2363 Prediction:               \n",
      "210 loss:  2.23535 Prediction:               \n",
      "211 loss:  2.2344 Prediction:               \n",
      "212 loss:  2.23345 Prediction:               \n",
      "213 loss:  2.2325 Prediction:               \n",
      "214 loss:  2.23154 Prediction:               \n",
      "215 loss:  2.23058 Prediction:               \n",
      "216 loss:  2.22962 Prediction:               \n",
      "217 loss:  2.22866 Prediction:               \n",
      "218 loss:  2.22769 Prediction:               \n",
      "219 loss:  2.22673 Prediction:               \n",
      "220 loss:  2.22576 Prediction:               \n",
      "221 loss:  2.22478 Prediction:               \n",
      "222 loss:  2.22381 Prediction:               \n",
      "223 loss:  2.22283 Prediction:               \n",
      "224 loss:  2.22185 Prediction:               \n",
      "225 loss:  2.22087 Prediction:               \n",
      "226 loss:  2.21989 Prediction:               \n",
      "227 loss:  2.2189 Prediction:               \n",
      "228 loss:  2.21791 Prediction:               \n",
      "229 loss:  2.21692 Prediction:               \n",
      "230 loss:  2.21593 Prediction:               \n",
      "231 loss:  2.21493 Prediction:               \n",
      "232 loss:  2.21393 Prediction:               \n",
      "233 loss:  2.21293 Prediction:               \n",
      "234 loss:  2.21193 Prediction:               \n",
      "235 loss:  2.21092 Prediction:               \n",
      "236 loss:  2.20991 Prediction:               \n",
      "237 loss:  2.2089 Prediction:               \n",
      "238 loss:  2.20789 Prediction:               \n",
      "239 loss:  2.20688 Prediction:               \n",
      "240 loss:  2.20586 Prediction:               \n",
      "241 loss:  2.20484 Prediction:               \n",
      "242 loss:  2.20381 Prediction:               \n",
      "243 loss:  2.20279 Prediction:               \n",
      "244 loss:  2.20176 Prediction:               \n",
      "245 loss:  2.20073 Prediction:               \n",
      "246 loss:  2.1997 Prediction:               \n",
      "247 loss:  2.19866 Prediction:               \n",
      "248 loss:  2.19762 Prediction:               \n",
      "249 loss:  2.19658 Prediction:               \n",
      "250 loss:  2.19554 Prediction:               \n",
      "251 loss:  2.1945 Prediction:               \n",
      "252 loss:  2.19345 Prediction:               \n",
      "253 loss:  2.1924 Prediction:               \n",
      "254 loss:  2.19135 Prediction:               \n",
      "255 loss:  2.19029 Prediction:               \n",
      "256 loss:  2.18923 Prediction:               \n",
      "257 loss:  2.18817 Prediction:               \n",
      "258 loss:  2.18711 Prediction:               \n",
      "259 loss:  2.18605 Prediction:               \n",
      "260 loss:  2.18498 Prediction:               \n",
      "261 loss:  2.18391 Prediction:               \n",
      "262 loss:  2.18284 Prediction:               \n",
      "263 loss:  2.18176 Prediction:               \n",
      "264 loss:  2.18069 Prediction:               \n",
      "265 loss:  2.17961 Prediction:               \n",
      "266 loss:  2.17853 Prediction:               \n",
      "267 loss:  2.17744 Prediction:               \n",
      "268 loss:  2.17636 Prediction:               \n",
      "269 loss:  2.17527 Prediction:               \n",
      "270 loss:  2.17418 Prediction:               \n",
      "271 loss:  2.17308 Prediction:               \n",
      "272 loss:  2.17199 Prediction:               \n",
      "273 loss:  2.17089 Prediction:               \n",
      "274 loss:  2.16979 Prediction:               \n",
      "275 loss:  2.16869 Prediction:               \n",
      "276 loss:  2.16758 Prediction:               \n",
      "277 loss:  2.16648 Prediction:               \n",
      "278 loss:  2.16537 Prediction:               \n",
      "279 loss:  2.16426 Prediction:               \n",
      "280 loss:  2.16314 Prediction:               \n",
      "281 loss:  2.16203 Prediction:               \n",
      "282 loss:  2.16091 Prediction:               \n",
      "283 loss:  2.15979 Prediction:               \n",
      "284 loss:  2.15867 Prediction:               \n",
      "285 loss:  2.15754 Prediction:               \n",
      "286 loss:  2.15642 Prediction:               \n",
      "287 loss:  2.15529 Prediction:               \n",
      "288 loss:  2.15416 Prediction:               \n",
      "289 loss:  2.15303 Prediction:               \n",
      "290 loss:  2.15189 Prediction:               \n",
      "291 loss:  2.15075 Prediction:               \n",
      "292 loss:  2.14962 Prediction:               \n",
      "293 loss:  2.14848 Prediction:               \n",
      "294 loss:  2.14733 Prediction:               \n",
      "295 loss:  2.14619 Prediction:               \n",
      "296 loss:  2.14504 Prediction:               \n",
      "297 loss:  2.1439 Prediction:               \n",
      "298 loss:  2.14275 Prediction:               \n",
      "299 loss:  2.14159 Prediction:               \n",
      "300 loss:  2.14044 Prediction:               \n",
      "301 loss:  2.13929 Prediction:               \n",
      "302 loss:  2.13813 Prediction:               \n",
      "303 loss:  2.13697 Prediction:               \n",
      "304 loss:  2.13581 Prediction:               \n",
      "305 loss:  2.13465 Prediction:               \n",
      "306 loss:  2.13349 Prediction:               \n",
      "307 loss:  2.13232 Prediction:               \n",
      "308 loss:  2.13115 Prediction:               \n",
      "309 loss:  2.12999 Prediction:               \n",
      "310 loss:  2.12882 Prediction:               \n",
      "311 loss:  2.12764 Prediction:               \n",
      "312 loss:  2.12647 Prediction:               \n",
      "313 loss:  2.1253 Prediction:               \n",
      "314 loss:  2.12412 Prediction:               \n",
      "315 loss:  2.12294 Prediction:               \n",
      "316 loss:  2.12177 Prediction:               \n",
      "317 loss:  2.12059 Prediction:               \n",
      "318 loss:  2.11941 Prediction:               \n",
      "319 loss:  2.11822 Prediction:               \n",
      "320 loss:  2.11704 Prediction:               \n",
      "321 loss:  2.11585 Prediction:               \n",
      "322 loss:  2.11467 Prediction:               \n",
      "323 loss:  2.11348 Prediction:               \n",
      "324 loss:  2.11229 Prediction:               \n",
      "325 loss:  2.1111 Prediction:               \n",
      "326 loss:  2.10991 Prediction:               \n",
      "327 loss:  2.10872 Prediction:               \n",
      "328 loss:  2.10753 Prediction:               \n",
      "329 loss:  2.10634 Prediction:               \n",
      "330 loss:  2.10514 Prediction:               \n",
      "331 loss:  2.10394 Prediction:               \n",
      "332 loss:  2.10275 Prediction:               \n",
      "333 loss:  2.10155 Prediction:               \n",
      "334 loss:  2.10035 Prediction:               \n",
      "335 loss:  2.09915 Prediction:               \n",
      "336 loss:  2.09795 Prediction:               \n",
      "337 loss:  2.09675 Prediction:               \n",
      "338 loss:  2.09555 Prediction:               \n",
      "339 loss:  2.09435 Prediction:               \n",
      "340 loss:  2.09314 Prediction:               \n",
      "341 loss:  2.09194 Prediction:               \n",
      "342 loss:  2.09074 Prediction:               \n",
      "343 loss:  2.08953 Prediction:               \n",
      "344 loss:  2.08832 Prediction:               \n",
      "345 loss:  2.08712 Prediction:               \n",
      "346 loss:  2.08591 Prediction:               \n",
      "347 loss:  2.0847 Prediction:               \n",
      "348 loss:  2.08349 Prediction:               \n",
      "349 loss:  2.08229 Prediction:               \n",
      "350 loss:  2.08108 Prediction:               \n",
      "351 loss:  2.07987 Prediction:               \n",
      "352 loss:  2.07866 Prediction:               \n",
      "353 loss:  2.07745 Prediction:               \n",
      "354 loss:  2.07623 Prediction:               \n",
      "355 loss:  2.07502 Prediction:               \n",
      "356 loss:  2.07381 Prediction:               \n",
      "357 loss:  2.0726 Prediction:               \n",
      "358 loss:  2.07138 Prediction:               \n",
      "359 loss:  2.07017 Prediction:               \n",
      "360 loss:  2.06896 Prediction:               \n",
      "361 loss:  2.06774 Prediction:               \n",
      "362 loss:  2.06653 Prediction:               \n",
      "363 loss:  2.06532 Prediction:               \n",
      "364 loss:  2.0641 Prediction:               \n",
      "365 loss:  2.06289 Prediction:               \n",
      "366 loss:  2.06167 Prediction:               \n",
      "367 loss:  2.06045 Prediction:               \n",
      "368 loss:  2.05924 Prediction:               \n",
      "369 loss:  2.05802 Prediction:               \n",
      "370 loss:  2.05681 Prediction:               \n",
      "371 loss:  2.05559 Prediction:               \n",
      "372 loss:  2.05437 Prediction:               \n",
      "373 loss:  2.05316 Prediction:               \n",
      "374 loss:  2.05194 Prediction:               \n",
      "375 loss:  2.05072 Prediction:               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 loss:  2.04951 Prediction:               \n",
      "377 loss:  2.04829 Prediction:               \n",
      "378 loss:  2.04707 Prediction:               \n",
      "379 loss:  2.04585 Prediction:               \n",
      "380 loss:  2.04464 Prediction:               \n",
      "381 loss:  2.04342 Prediction:               \n",
      "382 loss:  2.0422 Prediction:               \n",
      "383 loss:  2.04099 Prediction:               \n",
      "384 loss:  2.03977 Prediction:               \n",
      "385 loss:  2.03855 Prediction:               \n",
      "386 loss:  2.03733 Prediction:               \n",
      "387 loss:  2.03612 Prediction:               \n",
      "388 loss:  2.0349 Prediction:               \n",
      "389 loss:  2.03368 Prediction:               \n",
      "390 loss:  2.03247 Prediction:               \n",
      "391 loss:  2.03125 Prediction:               \n",
      "392 loss:  2.03003 Prediction:               \n",
      "393 loss:  2.02882 Prediction:               \n",
      "394 loss:  2.0276 Prediction:               \n",
      "395 loss:  2.02639 Prediction:               \n",
      "396 loss:  2.02517 Prediction:               \n",
      "397 loss:  2.02396 Prediction:               \n",
      "398 loss:  2.02274 Prediction:               \n",
      "399 loss:  2.02153 Prediction:               \n",
      "400 loss:  2.02032 Prediction:               \n",
      "401 loss:  2.0191 Prediction:               \n",
      "402 loss:  2.01789 Prediction:               \n",
      "403 loss:  2.01668 Prediction:               \n",
      "404 loss:  2.01547 Prediction:               \n",
      "405 loss:  2.01426 Prediction:               \n",
      "406 loss:  2.01305 Prediction:               \n",
      "407 loss:  2.01184 Prediction:               \n",
      "408 loss:  2.01063 Prediction:               \n",
      "409 loss:  2.00942 Prediction:               \n",
      "410 loss:  2.00821 Prediction:               \n",
      "411 loss:  2.00701 Prediction:               \n",
      "412 loss:  2.0058 Prediction:              e\n",
      "413 loss:  2.0046 Prediction:              e\n",
      "414 loss:  2.00339 Prediction:              e\n",
      "415 loss:  2.00219 Prediction:              e\n",
      "416 loss:  2.00099 Prediction:              e\n",
      "417 loss:  1.99979 Prediction:              e\n",
      "418 loss:  1.99859 Prediction:              e\n",
      "419 loss:  1.99739 Prediction:              e\n",
      "420 loss:  1.99619 Prediction:              e\n",
      "421 loss:  1.995 Prediction:              e\n",
      "422 loss:  1.9938 Prediction:              e\n",
      "423 loss:  1.99261 Prediction:              e\n",
      "424 loss:  1.99142 Prediction:              e\n",
      "425 loss:  1.99023 Prediction:              e\n",
      "426 loss:  1.98904 Prediction:              e\n",
      "427 loss:  1.98785 Prediction:              e\n",
      "428 loss:  1.98666 Prediction:              e\n",
      "429 loss:  1.98548 Prediction:              e\n",
      "430 loss:  1.98429 Prediction:              e\n",
      "431 loss:  1.98311 Prediction:              e\n",
      "432 loss:  1.98193 Prediction:              e\n",
      "433 loss:  1.98075 Prediction:              e\n",
      "434 loss:  1.97957 Prediction:              e\n",
      "435 loss:  1.97839 Prediction:              e\n",
      "436 loss:  1.97722 Prediction:              e\n",
      "437 loss:  1.97605 Prediction:              e\n",
      "438 loss:  1.97488 Prediction:              e\n",
      "439 loss:  1.97371 Prediction:              e\n",
      "440 loss:  1.97254 Prediction:              e\n",
      "441 loss:  1.97137 Prediction:              e\n",
      "442 loss:  1.97021 Prediction:              e\n",
      "443 loss:  1.96905 Prediction:              e\n",
      "444 loss:  1.96788 Prediction:              e\n",
      "445 loss:  1.96673 Prediction:              e\n",
      "446 loss:  1.96557 Prediction:              e\n",
      "447 loss:  1.96441 Prediction:              e\n",
      "448 loss:  1.96326 Prediction:              e\n",
      "449 loss:  1.96211 Prediction:              e\n",
      "450 loss:  1.96096 Prediction:              e\n",
      "451 loss:  1.95981 Prediction:              e\n",
      "452 loss:  1.95866 Prediction:              e\n",
      "453 loss:  1.95752 Prediction:              e\n",
      "454 loss:  1.95637 Prediction:              e\n",
      "455 loss:  1.95523 Prediction:              e\n",
      "456 loss:  1.95409 Prediction:              e\n",
      "457 loss:  1.95296 Prediction:              e\n",
      "458 loss:  1.95182 Prediction:              e\n",
      "459 loss:  1.95069 Prediction:              e\n",
      "460 loss:  1.94956 Prediction:              e\n",
      "461 loss:  1.94843 Prediction:              e\n",
      "462 loss:  1.9473 Prediction:              e\n",
      "463 loss:  1.94617 Prediction:              e\n",
      "464 loss:  1.94505 Prediction:              e\n",
      "465 loss:  1.94393 Prediction:              e\n",
      "466 loss:  1.94281 Prediction:              e\n",
      "467 loss:  1.94169 Prediction:              e\n",
      "468 loss:  1.94057 Prediction:              e\n",
      "469 loss:  1.93945 Prediction:              e\n",
      "470 loss:  1.93834 Prediction:              e\n",
      "471 loss:  1.93723 Prediction:              e\n",
      "472 loss:  1.93612 Prediction:              e\n",
      "473 loss:  1.93501 Prediction:              e\n",
      "474 loss:  1.93391 Prediction:              e\n",
      "475 loss:  1.9328 Prediction:              e\n",
      "476 loss:  1.9317 Prediction:              e\n",
      "477 loss:  1.9306 Prediction:              e\n",
      "478 loss:  1.9295 Prediction:              e\n",
      "479 loss:  1.92841 Prediction:              e\n",
      "480 loss:  1.92731 Prediction:              e\n",
      "481 loss:  1.92622 Prediction:              e\n",
      "482 loss:  1.92513 Prediction:              e\n",
      "483 loss:  1.92404 Prediction:              e\n",
      "484 loss:  1.92295 Prediction:              e\n",
      "485 loss:  1.92187 Prediction:              e\n",
      "486 loss:  1.92078 Prediction:              e\n",
      "487 loss:  1.9197 Prediction:              e\n",
      "488 loss:  1.91862 Prediction:              e\n",
      "489 loss:  1.91754 Prediction:              e\n",
      "490 loss:  1.91646 Prediction:              e\n",
      "491 loss:  1.91539 Prediction:              e\n",
      "492 loss:  1.91431 Prediction:              e\n",
      "493 loss:  1.91324 Prediction:              e\n",
      "494 loss:  1.91217 Prediction:              e\n",
      "495 loss:  1.9111 Prediction:              e\n",
      "496 loss:  1.91004 Prediction:              e\n",
      "497 loss:  1.90897 Prediction:              e\n",
      "498 loss:  1.90791 Prediction:              e\n",
      "499 loss:  1.90685 Prediction:              e\n",
      "500 loss:  1.90579 Prediction:              e\n",
      "501 loss:  1.90473 Prediction:              e\n",
      "502 loss:  1.90367 Prediction:              e\n",
      "503 loss:  1.90262 Prediction:              e\n",
      "504 loss:  1.90156 Prediction:              e\n",
      "505 loss:  1.90051 Prediction:              e\n",
      "506 loss:  1.89946 Prediction:              e\n",
      "507 loss:  1.89841 Prediction:              e\n",
      "508 loss:  1.89737 Prediction:              e\n",
      "509 loss:  1.89632 Prediction:              e\n",
      "510 loss:  1.89528 Prediction:              e\n",
      "511 loss:  1.89424 Prediction:              e\n",
      "512 loss:  1.8932 Prediction:              e\n",
      "513 loss:  1.89216 Prediction:              e\n",
      "514 loss:  1.89112 Prediction:              e\n",
      "515 loss:  1.89009 Prediction:              e\n",
      "516 loss:  1.88905 Prediction:              e\n",
      "517 loss:  1.88802 Prediction:              e\n",
      "518 loss:  1.88699 Prediction:              e\n",
      "519 loss:  1.88596 Prediction:              e\n",
      "520 loss:  1.88493 Prediction:              e\n",
      "521 loss:  1.88391 Prediction:              e\n",
      "522 loss:  1.88288 Prediction:              e\n",
      "523 loss:  1.88186 Prediction:              e\n",
      "524 loss:  1.88084 Prediction:              e\n",
      "525 loss:  1.87982 Prediction:              e\n",
      "526 loss:  1.8788 Prediction:              e\n",
      "527 loss:  1.87778 Prediction:              e\n",
      "528 loss:  1.87677 Prediction:              e\n",
      "529 loss:  1.87575 Prediction:              e\n",
      "530 loss:  1.87474 Prediction:              e\n",
      "531 loss:  1.87373 Prediction:              e\n",
      "532 loss:  1.87272 Prediction:              e\n",
      "533 loss:  1.87171 Prediction:              e\n",
      "534 loss:  1.87071 Prediction:              e\n",
      "535 loss:  1.8697 Prediction:              e\n",
      "536 loss:  1.8687 Prediction:              e\n",
      "537 loss:  1.8677 Prediction:              e\n",
      "538 loss:  1.8667 Prediction:              e\n",
      "539 loss:  1.8657 Prediction:              e\n",
      "540 loss:  1.8647 Prediction:              e\n",
      "541 loss:  1.8637 Prediction:              e\n",
      "542 loss:  1.86271 Prediction:              e\n",
      "543 loss:  1.86172 Prediction:              e\n",
      "544 loss:  1.86072 Prediction:              e\n",
      "545 loss:  1.85973 Prediction:              e\n",
      "546 loss:  1.85875 Prediction:              e\n",
      "547 loss:  1.85776 Prediction:              e\n",
      "548 loss:  1.85677 Prediction:              e\n",
      "549 loss:  1.85579 Prediction:              e\n",
      "550 loss:  1.8548 Prediction:              e\n",
      "551 loss:  1.85382 Prediction:              e\n",
      "552 loss:  1.85284 Prediction:              e\n",
      "553 loss:  1.85186 Prediction:              e\n",
      "554 loss:  1.85088 Prediction:              e\n",
      "555 loss:  1.84991 Prediction:              e\n",
      "556 loss:  1.84893 Prediction:              e\n",
      "557 loss:  1.84796 Prediction:              e\n",
      "558 loss:  1.84699 Prediction:              e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 loss:  1.84602 Prediction:              e\n",
      "560 loss:  1.84505 Prediction:              e\n",
      "561 loss:  1.84408 Prediction:              e\n",
      "562 loss:  1.84311 Prediction:              e\n",
      "563 loss:  1.84215 Prediction:              e\n",
      "564 loss:  1.84118 Prediction:              e\n",
      "565 loss:  1.84022 Prediction:              e\n",
      "566 loss:  1.83926 Prediction:              e\n",
      "567 loss:  1.8383 Prediction:              e\n",
      "568 loss:  1.83734 Prediction:              e\n",
      "569 loss:  1.83638 Prediction:              e\n",
      "570 loss:  1.83543 Prediction:              e\n",
      "571 loss:  1.83447 Prediction:              e\n",
      "572 loss:  1.83352 Prediction:              e\n",
      "573 loss:  1.83256 Prediction:              e\n",
      "574 loss:  1.83161 Prediction:              e\n",
      "575 loss:  1.83066 Prediction:              e\n",
      "576 loss:  1.82972 Prediction:              e\n",
      "577 loss:  1.82877 Prediction:              e\n",
      "578 loss:  1.82782 Prediction:              e\n",
      "579 loss:  1.82688 Prediction:              e\n",
      "580 loss:  1.82593 Prediction:              e\n",
      "581 loss:  1.82499 Prediction:              e\n",
      "582 loss:  1.82405 Prediction:              e\n",
      "583 loss:  1.82311 Prediction:              e\n",
      "584 loss:  1.82217 Prediction:              e\n",
      "585 loss:  1.82123 Prediction:              e\n",
      "586 loss:  1.8203 Prediction:              e\n",
      "587 loss:  1.81936 Prediction:              e\n",
      "588 loss:  1.81843 Prediction:              e\n",
      "589 loss:  1.8175 Prediction:              e\n",
      "590 loss:  1.81657 Prediction:              e\n",
      "591 loss:  1.81563 Prediction:              e\n",
      "592 loss:  1.81471 Prediction:              e\n",
      "593 loss:  1.81378 Prediction:              e\n",
      "594 loss:  1.81285 Prediction:              e\n",
      "595 loss:  1.81193 Prediction:              e\n",
      "596 loss:  1.811 Prediction:              e\n",
      "597 loss:  1.81008 Prediction:              e\n",
      "598 loss:  1.80915 Prediction:              e\n",
      "599 loss:  1.80823 Prediction:              e\n",
      "600 loss:  1.80731 Prediction:              e\n",
      "601 loss:  1.80639 Prediction:              e\n",
      "602 loss:  1.80548 Prediction:              e\n",
      "603 loss:  1.80456 Prediction:              e\n",
      "604 loss:  1.80364 Prediction:              e\n",
      "605 loss:  1.80273 Prediction:              e\n",
      "606 loss:  1.80181 Prediction:              e\n",
      "607 loss:  1.8009 Prediction:              e\n",
      "608 loss:  1.79999 Prediction:              e\n",
      "609 loss:  1.79908 Prediction:              e\n",
      "610 loss:  1.79817 Prediction:              e\n",
      "611 loss:  1.79726 Prediction:              e\n",
      "612 loss:  1.79635 Prediction:             me\n",
      "613 loss:  1.79545 Prediction:             me\n",
      "614 loss:  1.79454 Prediction:             me\n",
      "615 loss:  1.79363 Prediction:             me\n",
      "616 loss:  1.79273 Prediction:             me\n",
      "617 loss:  1.79183 Prediction:             me\n",
      "618 loss:  1.79093 Prediction:             me\n",
      "619 loss:  1.79002 Prediction:     o       me\n",
      "620 loss:  1.78912 Prediction:     o       me\n",
      "621 loss:  1.78822 Prediction:     o       me\n",
      "622 loss:  1.78732 Prediction:     o       me\n",
      "623 loss:  1.78643 Prediction:     o       me\n",
      "624 loss:  1.78553 Prediction:     o       me\n",
      "625 loss:  1.78463 Prediction:     o       me\n",
      "626 loss:  1.78374 Prediction:     o       me\n",
      "627 loss:  1.78284 Prediction:     o       me\n",
      "628 loss:  1.78195 Prediction:     o       me\n",
      "629 loss:  1.78106 Prediction:     o       me\n",
      "630 loss:  1.78016 Prediction:     o       me\n",
      "631 loss:  1.77927 Prediction:     o       me\n",
      "632 loss:  1.77838 Prediction:     o       me\n",
      "633 loss:  1.77749 Prediction:     o       me\n",
      "634 loss:  1.7766 Prediction:     o       me\n",
      "635 loss:  1.77571 Prediction:     o       me\n",
      "636 loss:  1.77482 Prediction:     o       me\n",
      "637 loss:  1.77393 Prediction:     o       me\n",
      "638 loss:  1.77305 Prediction:     o       me\n",
      "639 loss:  1.77216 Prediction:     o       me\n",
      "640 loss:  1.77127 Prediction:     o       me\n",
      "641 loss:  1.77039 Prediction:     o       me\n",
      "642 loss:  1.7695 Prediction:     o       me\n",
      "643 loss:  1.76862 Prediction:     o       me\n",
      "644 loss:  1.76773 Prediction:     o       me\n",
      "645 loss:  1.76685 Prediction:     o       me\n",
      "646 loss:  1.76597 Prediction:     o       me\n",
      "647 loss:  1.76508 Prediction:     o       me\n",
      "648 loss:  1.7642 Prediction:     o       me\n",
      "649 loss:  1.76332 Prediction:     o       me\n",
      "650 loss:  1.76244 Prediction:     o       me\n",
      "651 loss:  1.76156 Prediction:     o       me\n",
      "652 loss:  1.76068 Prediction:     o       me\n",
      "653 loss:  1.7598 Prediction:     o       me\n",
      "654 loss:  1.75892 Prediction:     o       me\n",
      "655 loss:  1.75804 Prediction:     o       me\n",
      "656 loss:  1.75716 Prediction:     o       me\n",
      "657 loss:  1.75628 Prediction:     o       me\n",
      "658 loss:  1.7554 Prediction:     o       me\n",
      "659 loss:  1.75452 Prediction:     o       me\n",
      "660 loss:  1.75365 Prediction:     o       me\n",
      "661 loss:  1.75277 Prediction:     o       me\n",
      "662 loss:  1.75189 Prediction:     o       me\n",
      "663 loss:  1.75102 Prediction:     o       me\n",
      "664 loss:  1.75014 Prediction:     o       me\n",
      "665 loss:  1.74926 Prediction:     o       me\n",
      "666 loss:  1.74839 Prediction:     o       me\n",
      "667 loss:  1.74751 Prediction:     o       me\n",
      "668 loss:  1.74664 Prediction:     o       me\n",
      "669 loss:  1.74576 Prediction:     o       me\n",
      "670 loss:  1.74489 Prediction:     o       me\n",
      "671 loss:  1.74401 Prediction:     ou      me\n",
      "672 loss:  1.74314 Prediction:     ou      me\n",
      "673 loss:  1.74227 Prediction:     ou      me\n",
      "674 loss:  1.7414 Prediction:     ou      me\n",
      "675 loss:  1.74052 Prediction:     ou      me\n",
      "676 loss:  1.73965 Prediction:     ou      me\n",
      "677 loss:  1.73878 Prediction:     ou      me\n",
      "678 loss:  1.73791 Prediction:     ou      me\n",
      "679 loss:  1.73704 Prediction:     ou      me\n",
      "680 loss:  1.73617 Prediction:     ou      me\n",
      "681 loss:  1.7353 Prediction:     ou      me\n",
      "682 loss:  1.73443 Prediction:     ou      me\n",
      "683 loss:  1.73356 Prediction:     ou      me\n",
      "684 loss:  1.7327 Prediction:     ou      me\n",
      "685 loss:  1.73183 Prediction:     ou      me\n",
      "686 loss:  1.73096 Prediction:     ou      me\n",
      "687 loss:  1.7301 Prediction:     ou      me\n",
      "688 loss:  1.72923 Prediction:     ou      me\n",
      "689 loss:  1.72837 Prediction:     ou      me\n",
      "690 loss:  1.72751 Prediction:     ou      me\n",
      "691 loss:  1.72665 Prediction:     ou      me\n",
      "692 loss:  1.72579 Prediction:     ou      me\n",
      "693 loss:  1.72493 Prediction:     ou      me\n",
      "694 loss:  1.72407 Prediction:     ou      me\n",
      "695 loss:  1.72321 Prediction:     ou      me\n",
      "696 loss:  1.72235 Prediction:     ou      me\n",
      "697 loss:  1.7215 Prediction:     ou      me\n",
      "698 loss:  1.72064 Prediction:     ou      me\n",
      "699 loss:  1.71979 Prediction:     ou      me\n",
      "700 loss:  1.71894 Prediction:     ou      me\n",
      "701 loss:  1.71809 Prediction:     ou      me\n",
      "702 loss:  1.71724 Prediction:     ou      me\n",
      "703 loss:  1.71639 Prediction:     ou      me\n",
      "704 loss:  1.71554 Prediction:     ou      me\n",
      "705 loss:  1.7147 Prediction:     ou      me\n",
      "706 loss:  1.71385 Prediction:     ou      me\n",
      "707 loss:  1.71301 Prediction:     ou      me\n",
      "708 loss:  1.71217 Prediction:     ou      me\n",
      "709 loss:  1.71133 Prediction:     ou      me\n",
      "710 loss:  1.71049 Prediction:     ou      me\n",
      "711 loss:  1.70966 Prediction:     ou      me\n",
      "712 loss:  1.70882 Prediction:     ou      me\n",
      "713 loss:  1.70799 Prediction:     ou      me\n",
      "714 loss:  1.70716 Prediction:     ou      me\n",
      "715 loss:  1.70633 Prediction:     ou      me\n",
      "716 loss:  1.7055 Prediction:     ou      me\n",
      "717 loss:  1.70467 Prediction:     ou      me\n",
      "718 loss:  1.70385 Prediction:     ou      me\n",
      "719 loss:  1.70302 Prediction:     ou      me\n",
      "720 loss:  1.7022 Prediction:     ou      me\n",
      "721 loss:  1.70138 Prediction:     ou      me\n",
      "722 loss:  1.70056 Prediction:     ou      me\n",
      "723 loss:  1.69975 Prediction:     ou      me\n",
      "724 loss:  1.69894 Prediction:     ou      me\n",
      "725 loss:  1.69812 Prediction:     ou      me\n",
      "726 loss:  1.69731 Prediction:     ou      me\n",
      "727 loss:  1.6965 Prediction:     ou      me\n",
      "728 loss:  1.6957 Prediction:     ou      me\n",
      "729 loss:  1.69489 Prediction:     ou      me\n",
      "730 loss:  1.69409 Prediction:     ou      me\n",
      "731 loss:  1.69329 Prediction:     ou      me\n",
      "732 loss:  1.69249 Prediction:     ou      me\n",
      "733 loss:  1.69169 Prediction:     ou      me\n",
      "734 loss:  1.6909 Prediction:     ou      me\n",
      "735 loss:  1.69011 Prediction:     ou      me\n",
      "736 loss:  1.68931 Prediction:     ou      me\n",
      "737 loss:  1.68852 Prediction:     ou      me\n",
      "738 loss:  1.68774 Prediction:     ou      me\n",
      "739 loss:  1.68695 Prediction:     ou      mm\n",
      "740 loss:  1.68617 Prediction:     ou      mm\n",
      "741 loss:  1.68539 Prediction:     ou      mm\n",
      "742 loss:  1.68461 Prediction:     ou      mm\n",
      "743 loss:  1.68383 Prediction:     ou      mm\n",
      "744 loss:  1.68305 Prediction:     ou      mm\n",
      "745 loss:  1.68228 Prediction:     ou      mm\n",
      "746 loss:  1.68151 Prediction:     ou      mm\n",
      "747 loss:  1.68074 Prediction:     ou      mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 loss:  1.67997 Prediction:     ou      mm\n",
      "749 loss:  1.67921 Prediction:     ou      mm\n",
      "750 loss:  1.67844 Prediction:     ou      mm\n",
      "751 loss:  1.67768 Prediction:     ou      mm\n",
      "752 loss:  1.67692 Prediction:     ou      mm\n",
      "753 loss:  1.67616 Prediction:     ou      mm\n",
      "754 loss:  1.67541 Prediction:     ou      mm\n",
      "755 loss:  1.67465 Prediction:     ou      mm\n",
      "756 loss:  1.6739 Prediction:     ou      mm\n",
      "757 loss:  1.67315 Prediction:     ou      mm\n",
      "758 loss:  1.6724 Prediction:     ou      mm\n",
      "759 loss:  1.67166 Prediction:     ou      mm\n",
      "760 loss:  1.67091 Prediction:     ou      mm\n",
      "761 loss:  1.67017 Prediction:     ou      mm\n",
      "762 loss:  1.66943 Prediction:     ou      mm\n",
      "763 loss:  1.66869 Prediction:     ou      mm\n",
      "764 loss:  1.66795 Prediction:     ou      mm\n",
      "765 loss:  1.66722 Prediction:     ou      mm\n",
      "766 loss:  1.66649 Prediction:     ou      mm\n",
      "767 loss:  1.66576 Prediction:     ou      mm\n",
      "768 loss:  1.66503 Prediction:     ou      mm\n",
      "769 loss:  1.6643 Prediction:     ou      mm\n",
      "770 loss:  1.66357 Prediction:     ou      mm\n",
      "771 loss:  1.66285 Prediction:     ou      mm\n",
      "772 loss:  1.66213 Prediction:     ou      mm\n",
      "773 loss:  1.66141 Prediction:     ou      mm\n",
      "774 loss:  1.66069 Prediction:     ou      mm\n",
      "775 loss:  1.65998 Prediction:     ou      mm\n",
      "776 loss:  1.65926 Prediction:     ou      mm\n",
      "777 loss:  1.65855 Prediction:     ou      mm\n",
      "778 loss:  1.65784 Prediction:     ou      mm\n",
      "779 loss:  1.65713 Prediction:     ou      mm\n",
      "780 loss:  1.65643 Prediction:     ou      mm\n",
      "781 loss:  1.65572 Prediction:     ou      mm\n",
      "782 loss:  1.65502 Prediction:     ou      mm\n",
      "783 loss:  1.65432 Prediction:     ou      mm\n",
      "784 loss:  1.65362 Prediction:     ou      mm\n",
      "785 loss:  1.65292 Prediction:     ou      mm\n",
      "786 loss:  1.65223 Prediction:     ou      mm\n",
      "787 loss:  1.65154 Prediction:     ou      mm\n",
      "788 loss:  1.65084 Prediction:     ou      mm\n",
      "789 loss:  1.65015 Prediction:     ou      mm\n",
      "790 loss:  1.64947 Prediction:     ou      mm\n",
      "791 loss:  1.64878 Prediction:     ou      mm\n",
      "792 loss:  1.64809 Prediction:     ou      mm\n",
      "793 loss:  1.64741 Prediction:     ou      mm\n",
      "794 loss:  1.64673 Prediction:     ou      mm\n",
      "795 loss:  1.64605 Prediction:     ou      mm\n",
      "796 loss:  1.64537 Prediction:     ou      mm\n",
      "797 loss:  1.6447 Prediction:     ou      mm\n",
      "798 loss:  1.64402 Prediction:     ou      mm\n",
      "799 loss:  1.64335 Prediction:     ou      mm\n",
      "800 loss:  1.64268 Prediction:     ou      mm\n",
      "801 loss:  1.64201 Prediction:  f  ou      mm\n",
      "802 loss:  1.64135 Prediction:  f  ou      mm\n",
      "803 loss:  1.64068 Prediction:  f  ou      mm\n",
      "804 loss:  1.64002 Prediction:  f  ou      mm\n",
      "805 loss:  1.63936 Prediction:  f  ou      mm\n",
      "806 loss:  1.6387 Prediction:  f  ou      mm\n",
      "807 loss:  1.63804 Prediction:  f  ou      mm\n",
      "808 loss:  1.63738 Prediction:  f  ou      mm\n",
      "809 loss:  1.63673 Prediction:  f  ou      mm\n",
      "810 loss:  1.63607 Prediction:  f  ou      mm\n",
      "811 loss:  1.63542 Prediction:  f  ou      mm\n",
      "812 loss:  1.63477 Prediction:  f  ou      mm\n",
      "813 loss:  1.63412 Prediction:  f  ou      mm\n",
      "814 loss:  1.63348 Prediction:  f  ou      mm\n",
      "815 loss:  1.63283 Prediction:  f  ou      mm\n",
      "816 loss:  1.63219 Prediction:  f  ou      mm\n",
      "817 loss:  1.63155 Prediction:  f  ou      mm\n",
      "818 loss:  1.63091 Prediction:  f  ou      mm\n",
      "819 loss:  1.63027 Prediction:  f  ou      mm\n",
      "820 loss:  1.62963 Prediction:  f  ou      mm\n",
      "821 loss:  1.62899 Prediction:  f  ou      mm\n",
      "822 loss:  1.62836 Prediction:  f  ou      mm\n",
      "823 loss:  1.62773 Prediction:  f  ou      mm\n",
      "824 loss:  1.6271 Prediction:  f  ou      mm\n",
      "825 loss:  1.62647 Prediction:  f  ou      mm\n",
      "826 loss:  1.62584 Prediction:  f  ou      mm\n",
      "827 loss:  1.62522 Prediction:  f  ou      mm\n",
      "828 loss:  1.62459 Prediction:  f  ou      mm\n",
      "829 loss:  1.62397 Prediction:  f  ou      mm\n",
      "830 loss:  1.62335 Prediction:  f  ou      mm\n",
      "831 loss:  1.62273 Prediction:  f  ou      mm\n",
      "832 loss:  1.62211 Prediction:  f  ou      mm\n",
      "833 loss:  1.6215 Prediction:  f  ou      mm\n",
      "834 loss:  1.62088 Prediction:  f  ou      mm\n",
      "835 loss:  1.62027 Prediction:  f  ou      mm\n",
      "836 loss:  1.61966 Prediction:  f  ou      mm\n",
      "837 loss:  1.61905 Prediction:  f  ou      mm\n",
      "838 loss:  1.61844 Prediction:  f  ou      mm\n",
      "839 loss:  1.61783 Prediction:  f  ou      mm\n",
      "840 loss:  1.61722 Prediction:  f  ou      mm\n",
      "841 loss:  1.61662 Prediction:  f  ou      mm\n",
      "842 loss:  1.61602 Prediction:  f  ou      mm\n",
      "843 loss:  1.61542 Prediction:  f  ou      mm\n",
      "844 loss:  1.61482 Prediction:  f  ou      mm\n",
      "845 loss:  1.61422 Prediction:  f you      mm\n",
      "846 loss:  1.61362 Prediction:  f you      mm\n",
      "847 loss:  1.61303 Prediction:  f you      mm\n",
      "848 loss:  1.61243 Prediction:  f you      mm\n",
      "849 loss:  1.61184 Prediction:  f you      mm\n",
      "850 loss:  1.61125 Prediction:  f you      mm\n",
      "851 loss:  1.61066 Prediction:  f you      mm\n",
      "852 loss:  1.61007 Prediction:  f you      mm\n",
      "853 loss:  1.60948 Prediction:  f you      mm\n",
      "854 loss:  1.6089 Prediction:  f you      mm\n",
      "855 loss:  1.60831 Prediction:  f you      mm\n",
      "856 loss:  1.60773 Prediction:  f you      mm\n",
      "857 loss:  1.60715 Prediction:  f you      mm\n",
      "858 loss:  1.60657 Prediction:  f you      mm\n",
      "859 loss:  1.60599 Prediction:  f you      mm\n",
      "860 loss:  1.60541 Prediction:  f you      mm\n",
      "861 loss:  1.60484 Prediction:  f you      mm\n",
      "862 loss:  1.60426 Prediction:  f you      mm\n",
      "863 loss:  1.60369 Prediction:  f you      mm\n",
      "864 loss:  1.60312 Prediction:  f you      mm\n",
      "865 loss:  1.60255 Prediction:  f you      mm\n",
      "866 loss:  1.60198 Prediction:  f you      mm\n",
      "867 loss:  1.60141 Prediction:  f you      mm\n",
      "868 loss:  1.60085 Prediction:  f you      mm\n",
      "869 loss:  1.60028 Prediction:  f you      mm\n",
      "870 loss:  1.59972 Prediction:  f you      mm\n",
      "871 loss:  1.59916 Prediction:  f you      mm\n",
      "872 loss:  1.5986 Prediction:  f you      mm\n",
      "873 loss:  1.59804 Prediction:  f you      mm\n",
      "874 loss:  1.59748 Prediction:  f you      mm\n",
      "875 loss:  1.59692 Prediction:  f you      mm\n",
      "876 loss:  1.59637 Prediction:  f you      mm\n",
      "877 loss:  1.59581 Prediction:  f you      mm\n",
      "878 loss:  1.59526 Prediction:  f you      mm\n",
      "879 loss:  1.59471 Prediction:  f you      mm\n",
      "880 loss:  1.59416 Prediction:  f you      mm\n",
      "881 loss:  1.59361 Prediction:  f you      mm\n",
      "882 loss:  1.59306 Prediction:  f you      mm\n",
      "883 loss:  1.59251 Prediction:  f you      mm\n",
      "884 loss:  1.59197 Prediction:  f you      mm\n",
      "885 loss:  1.59142 Prediction:  f you      mm\n",
      "886 loss:  1.59088 Prediction:  f you      mm\n",
      "887 loss:  1.59034 Prediction:  f you      mm\n",
      "888 loss:  1.5898 Prediction:  f you      mm\n",
      "889 loss:  1.58926 Prediction:  f you      mm\n",
      "890 loss:  1.58872 Prediction:  f you      mm\n",
      "891 loss:  1.58818 Prediction:  f you      mm\n",
      "892 loss:  1.58764 Prediction:  f you      mm\n",
      "893 loss:  1.58711 Prediction:  f you      mm\n",
      "894 loss:  1.58658 Prediction:  f you      mm\n",
      "895 loss:  1.58604 Prediction:  f you      mm\n",
      "896 loss:  1.58551 Prediction:  f you      mm\n",
      "897 loss:  1.58498 Prediction:  f you      mm\n",
      "898 loss:  1.58445 Prediction:  f you      mm\n",
      "899 loss:  1.58393 Prediction:  f you      mm\n",
      "900 loss:  1.5834 Prediction:  f you      mm\n",
      "901 loss:  1.58288 Prediction:  f you      mm\n",
      "902 loss:  1.58235 Prediction:  f you      mm\n",
      "903 loss:  1.58183 Prediction:  f you      mm\n",
      "904 loss:  1.58131 Prediction:  f you      mm\n",
      "905 loss:  1.58079 Prediction:  f you      mm\n",
      "906 loss:  1.58027 Prediction:  f you      mm\n",
      "907 loss:  1.57975 Prediction:  f you      mm\n",
      "908 loss:  1.57923 Prediction:  f you      mm\n",
      "909 loss:  1.57871 Prediction:  f you      mm\n",
      "910 loss:  1.5782 Prediction:  f you    t mm\n",
      "911 loss:  1.57768 Prediction:  f you    t mm\n",
      "912 loss:  1.57717 Prediction:  f you    t mm\n",
      "913 loss:  1.57666 Prediction:  f you    t mm\n",
      "914 loss:  1.57615 Prediction:  f you    t mm\n",
      "915 loss:  1.57564 Prediction:  f you    t mm\n",
      "916 loss:  1.57513 Prediction:  f you    t mm\n",
      "917 loss:  1.57462 Prediction:  f you    t mm\n",
      "918 loss:  1.57412 Prediction:  f you    t mm\n",
      "919 loss:  1.57361 Prediction:  f you   nt mm\n",
      "920 loss:  1.57311 Prediction:  f you   nt mm\n",
      "921 loss:  1.5726 Prediction:  f you   nt mm\n",
      "922 loss:  1.5721 Prediction:  f you   nt mm\n",
      "923 loss:  1.5716 Prediction:  f you   nt mm\n",
      "924 loss:  1.5711 Prediction:  f you   nt mm\n",
      "925 loss:  1.5706 Prediction:  f you   nt mm\n",
      "926 loss:  1.5701 Prediction:  f you   nt mm\n",
      "927 loss:  1.56961 Prediction:  f you   nt mm\n",
      "928 loss:  1.56911 Prediction:  f you   nt mm\n",
      "929 loss:  1.56862 Prediction:  f you   nt mm\n",
      "930 loss:  1.56812 Prediction:  f you   nt mm\n",
      "931 loss:  1.56763 Prediction:  f you   nt mm\n",
      "932 loss:  1.56714 Prediction:  f you   nt mm\n",
      "933 loss:  1.56665 Prediction:  f you   nt mm\n",
      "934 loss:  1.56616 Prediction:  f you   nt mm\n",
      "935 loss:  1.56567 Prediction:  f you   nt mm\n",
      "936 loss:  1.56518 Prediction:  f you   nt mm\n",
      "937 loss:  1.56469 Prediction:  f you   nt mm\n",
      "938 loss:  1.56421 Prediction:  f you   nt mm\n",
      "939 loss:  1.56372 Prediction:  f you   nt mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940 loss:  1.56324 Prediction:  f you   nt mm\n",
      "941 loss:  1.56275 Prediction:  f you   nt mm\n",
      "942 loss:  1.56227 Prediction:  f you   nt mm\n",
      "943 loss:  1.56179 Prediction:  f you   nt mm\n",
      "944 loss:  1.56131 Prediction:  f you   nt mm\n",
      "945 loss:  1.56083 Prediction:  f you   nt mm\n",
      "946 loss:  1.56035 Prediction:  f you w nt mm\n",
      "947 loss:  1.55988 Prediction:  f you w nt mm\n",
      "948 loss:  1.5594 Prediction:  f you w nt mm\n",
      "949 loss:  1.55892 Prediction:  f you w nt mm\n",
      "950 loss:  1.55845 Prediction:  f you w nt mm\n",
      "951 loss:  1.55798 Prediction:  f you w nt mm\n",
      "952 loss:  1.5575 Prediction:  f you w nt mm\n",
      "953 loss:  1.55703 Prediction:  f you w nt mm\n",
      "954 loss:  1.55656 Prediction:  f you w nt mm\n",
      "955 loss:  1.55609 Prediction:  f you w nt mm\n",
      "956 loss:  1.55562 Prediction:  f you w nt mm\n",
      "957 loss:  1.55515 Prediction:  f you w nt mm\n",
      "958 loss:  1.55469 Prediction:  f you w nt mm\n",
      "959 loss:  1.55422 Prediction:  f you w nt mm\n",
      "960 loss:  1.55375 Prediction:  f you w nt mm\n",
      "961 loss:  1.55329 Prediction:  f you w nt mm\n",
      "962 loss:  1.55283 Prediction:  f you w nt mm\n",
      "963 loss:  1.55236 Prediction:  f you w nt mm\n",
      "964 loss:  1.5519 Prediction:  f you w nt mm\n",
      "965 loss:  1.55144 Prediction:  f you w nt mm\n",
      "966 loss:  1.55098 Prediction:  f you w nt mm\n",
      "967 loss:  1.55052 Prediction:  f you w nt mm\n",
      "968 loss:  1.55006 Prediction:  f you w nt mm\n",
      "969 loss:  1.54961 Prediction:  f you w nt mm\n",
      "970 loss:  1.54915 Prediction:  f you w nt mm\n",
      "971 loss:  1.54869 Prediction:  f you w nt mm\n",
      "972 loss:  1.54824 Prediction:  f you w nt mm\n",
      "973 loss:  1.54779 Prediction:  f you w nt mm\n",
      "974 loss:  1.54733 Prediction:  f you w nt mm\n",
      "975 loss:  1.54688 Prediction:  f you w nt mm\n",
      "976 loss:  1.54643 Prediction:  f you w nt mm\n",
      "977 loss:  1.54598 Prediction:  f you w nt mm\n",
      "978 loss:  1.54553 Prediction:  f you w nt mm\n",
      "979 loss:  1.54508 Prediction:  f you w nt mm\n",
      "980 loss:  1.54463 Prediction:  f you w nt mm\n",
      "981 loss:  1.54419 Prediction:  f you w nt mm\n",
      "982 loss:  1.54374 Prediction:  f you w nt mm\n",
      "983 loss:  1.54329 Prediction:  f you w nt mm\n",
      "984 loss:  1.54285 Prediction:  f you w nt mm\n",
      "985 loss:  1.54241 Prediction:  f you w nt mm\n",
      "986 loss:  1.54196 Prediction:  f you w nt mm\n",
      "987 loss:  1.54152 Prediction:  f you w nt mm\n",
      "988 loss:  1.54108 Prediction:  f you w nt mm\n",
      "989 loss:  1.54064 Prediction:  f you w nt mm\n",
      "990 loss:  1.5402 Prediction:  f you w nt mm\n",
      "991 loss:  1.53976 Prediction:  f you w nt mm\n",
      "992 loss:  1.53932 Prediction:  f you w nt mm\n",
      "993 loss:  1.53889 Prediction:  f you w nt mm\n",
      "994 loss:  1.53845 Prediction:  f you w nt mm\n",
      "995 loss:  1.53801 Prediction:  f you w nt mm\n",
      "996 loss:  1.53758 Prediction:  f you w nt mm\n",
      "997 loss:  1.53714 Prediction:  f you w nt mm\n",
      "998 loss:  1.53671 Prediction:  f you w nt mm\n",
      "999 loss:  1.53628 Prediction:  f you w nt mm\n",
      "1000 loss:  1.53585 Prediction:  f you w nt mm\n",
      "1001 loss:  1.53542 Prediction:  f you w nt mm\n",
      "1002 loss:  1.53499 Prediction:  f you w nt mm\n",
      "1003 loss:  1.53456 Prediction:  f you w nt mm\n",
      "1004 loss:  1.53413 Prediction:  f you w nt mm\n",
      "1005 loss:  1.5337 Prediction:  f you w nt mm\n",
      "1006 loss:  1.53327 Prediction:  f you w nt mm\n",
      "1007 loss:  1.53285 Prediction:  f you w nt mm\n",
      "1008 loss:  1.53242 Prediction:  f you want mm\n",
      "1009 loss:  1.532 Prediction:  f you want mm\n",
      "1010 loss:  1.53157 Prediction:  f you want mm\n",
      "1011 loss:  1.53115 Prediction:  f you want mm\n",
      "1012 loss:  1.53073 Prediction:  f you want mm\n",
      "1013 loss:  1.53031 Prediction:  f you want mm\n",
      "1014 loss:  1.52989 Prediction:  f you want mm\n",
      "1015 loss:  1.52947 Prediction:  f you want mm\n",
      "1016 loss:  1.52905 Prediction:  f you want mm\n",
      "1017 loss:  1.52863 Prediction:  f you want mm\n",
      "1018 loss:  1.52821 Prediction:  f you want mm\n",
      "1019 loss:  1.52779 Prediction:  f you want mm\n",
      "1020 loss:  1.52738 Prediction:  f you want mm\n",
      "1021 loss:  1.52696 Prediction:  f you want mm\n",
      "1022 loss:  1.52655 Prediction:  f you want mm\n",
      "1023 loss:  1.52613 Prediction:  f you want mm\n",
      "1024 loss:  1.52572 Prediction:  f you want mm\n",
      "1025 loss:  1.52531 Prediction:  f you want mm\n",
      "1026 loss:  1.5249 Prediction:  f you want mm\n",
      "1027 loss:  1.52449 Prediction:  f you want mm\n",
      "1028 loss:  1.52408 Prediction:  f you want mm\n",
      "1029 loss:  1.52367 Prediction:  f you want mm\n",
      "1030 loss:  1.52326 Prediction:  f you want mm\n",
      "1031 loss:  1.52285 Prediction:  f you want mm\n",
      "1032 loss:  1.52244 Prediction:  f you want mm\n",
      "1033 loss:  1.52204 Prediction:  f you want mm\n",
      "1034 loss:  1.52163 Prediction:  f you want mm\n",
      "1035 loss:  1.52123 Prediction:  f you want mm\n",
      "1036 loss:  1.52082 Prediction:  f you want mm\n",
      "1037 loss:  1.52042 Prediction:  f you want mm\n",
      "1038 loss:  1.52002 Prediction:  f you want mm\n",
      "1039 loss:  1.51961 Prediction:  f you want mm\n",
      "1040 loss:  1.51921 Prediction:  f you want mm\n",
      "1041 loss:  1.51881 Prediction:  f you want mm\n",
      "1042 loss:  1.51841 Prediction:  f you want mm\n",
      "1043 loss:  1.51801 Prediction:  f you want mm\n",
      "1044 loss:  1.51761 Prediction:  f you want mm\n",
      "1045 loss:  1.51722 Prediction:  f you want mm\n",
      "1046 loss:  1.51682 Prediction:  f you want mm\n",
      "1047 loss:  1.51642 Prediction:  f you want mm\n",
      "1048 loss:  1.51603 Prediction:  f you want mm\n",
      "1049 loss:  1.51563 Prediction:  f you want mm\n",
      "1050 loss:  1.51524 Prediction:  f you want mm\n",
      "1051 loss:  1.51485 Prediction:  f you want mm\n",
      "1052 loss:  1.51445 Prediction:  f you want mm\n",
      "1053 loss:  1.51406 Prediction:  f you want mm\n",
      "1054 loss:  1.51367 Prediction:  f you want mm\n",
      "1055 loss:  1.51328 Prediction:  f you want mm\n",
      "1056 loss:  1.51289 Prediction:  f you want mm\n",
      "1057 loss:  1.5125 Prediction:  f you want mm\n",
      "1058 loss:  1.51211 Prediction:  f you want mm\n",
      "1059 loss:  1.51172 Prediction:  f you want mm\n",
      "1060 loss:  1.51134 Prediction:  f you want mm\n",
      "1061 loss:  1.51095 Prediction:  f you want mm\n",
      "1062 loss:  1.51056 Prediction:  f you want mm\n",
      "1063 loss:  1.51018 Prediction:  f you want mm\n",
      "1064 loss:  1.50979 Prediction:  f you want mm\n",
      "1065 loss:  1.50941 Prediction:  f you want mm\n",
      "1066 loss:  1.50903 Prediction:  f you want mm\n",
      "1067 loss:  1.50865 Prediction:  f you want mm\n",
      "1068 loss:  1.50826 Prediction:  f you want mm\n",
      "1069 loss:  1.50788 Prediction:  f you want mm\n",
      "1070 loss:  1.5075 Prediction:  f you want mm\n",
      "1071 loss:  1.50712 Prediction:  f you want mm\n",
      "1072 loss:  1.50675 Prediction:  f you want mm\n",
      "1073 loss:  1.50637 Prediction:  f you want mm\n",
      "1074 loss:  1.50599 Prediction:  f you want mm\n",
      "1075 loss:  1.50561 Prediction:  f you want mm\n",
      "1076 loss:  1.50524 Prediction:  f you want mm\n",
      "1077 loss:  1.50486 Prediction:  f you want mm\n",
      "1078 loss:  1.50449 Prediction:  f you want mm\n",
      "1079 loss:  1.50411 Prediction:  f you want mm\n",
      "1080 loss:  1.50374 Prediction:  f you want mm\n",
      "1081 loss:  1.50337 Prediction:  f you want mm\n",
      "1082 loss:  1.503 Prediction:  f you want mm\n",
      "1083 loss:  1.50262 Prediction:  f you want mm\n",
      "1084 loss:  1.50225 Prediction:  f you want mm\n",
      "1085 loss:  1.50188 Prediction:  f you want mm\n",
      "1086 loss:  1.50152 Prediction:  f you want mm\n",
      "1087 loss:  1.50115 Prediction:  f you want mm\n",
      "1088 loss:  1.50078 Prediction:  f you want mm\n",
      "1089 loss:  1.50041 Prediction:  f you want mm\n",
      "1090 loss:  1.50005 Prediction:  f you want mm\n",
      "1091 loss:  1.49968 Prediction:  f you want mm\n",
      "1092 loss:  1.49931 Prediction:  f you want mm\n",
      "1093 loss:  1.49895 Prediction:  f you want mm\n",
      "1094 loss:  1.49859 Prediction:  f you want mm\n",
      "1095 loss:  1.49822 Prediction:  f you want mm\n",
      "1096 loss:  1.49786 Prediction:  f you want mm\n",
      "1097 loss:  1.4975 Prediction:  f you want mm\n",
      "1098 loss:  1.49714 Prediction:  f you want mm\n",
      "1099 loss:  1.49678 Prediction:  f you want mm\n",
      "1100 loss:  1.49642 Prediction:  f you want mm\n",
      "1101 loss:  1.49606 Prediction:  f you want mm\n",
      "1102 loss:  1.4957 Prediction:  f you want mm\n",
      "1103 loss:  1.49534 Prediction:  f you want mm\n",
      "1104 loss:  1.49498 Prediction:  f you want mm\n",
      "1105 loss:  1.49463 Prediction:  f you want mm\n",
      "1106 loss:  1.49427 Prediction:  f you want mm\n",
      "1107 loss:  1.49392 Prediction:  f you want mm\n",
      "1108 loss:  1.49356 Prediction:  f you want mm\n",
      "1109 loss:  1.49321 Prediction:  f you want mm\n",
      "1110 loss:  1.49286 Prediction:  f you want mm\n",
      "1111 loss:  1.4925 Prediction:  f you want mm\n",
      "1112 loss:  1.49215 Prediction:  f you want mm\n",
      "1113 loss:  1.4918 Prediction:  f you want mm\n",
      "1114 loss:  1.49145 Prediction:  f you want mm\n",
      "1115 loss:  1.4911 Prediction:  f you want mm\n",
      "1116 loss:  1.49075 Prediction:  f you want mm\n",
      "1117 loss:  1.4904 Prediction:  f you want mm\n",
      "1118 loss:  1.49005 Prediction:  f you want mm\n",
      "1119 loss:  1.48971 Prediction:  f you want mm\n",
      "1120 loss:  1.48936 Prediction:  f you want mm\n",
      "1121 loss:  1.48901 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122 loss:  1.48867 Prediction:  f you want mm\n",
      "1123 loss:  1.48832 Prediction:  f you want mm\n",
      "1124 loss:  1.48798 Prediction:  f you want mm\n",
      "1125 loss:  1.48763 Prediction:  f you want mm\n",
      "1126 loss:  1.48729 Prediction:  f you want mm\n",
      "1127 loss:  1.48695 Prediction:  f you want mm\n",
      "1128 loss:  1.48661 Prediction:  f you want mm\n",
      "1129 loss:  1.48627 Prediction:  f you want mm\n",
      "1130 loss:  1.48593 Prediction:  f you want mm\n",
      "1131 loss:  1.48559 Prediction:  f you want mm\n",
      "1132 loss:  1.48525 Prediction:  f you want mm\n",
      "1133 loss:  1.48491 Prediction:  f you want mm\n",
      "1134 loss:  1.48457 Prediction:  f you want mm\n",
      "1135 loss:  1.48423 Prediction:  f you want mm\n",
      "1136 loss:  1.4839 Prediction:  f you want mm\n",
      "1137 loss:  1.48356 Prediction:  f you want mm\n",
      "1138 loss:  1.48322 Prediction:  f you want mm\n",
      "1139 loss:  1.48289 Prediction:  f you want mm\n",
      "1140 loss:  1.48256 Prediction:  f you want mm\n",
      "1141 loss:  1.48222 Prediction:  f you want mm\n",
      "1142 loss:  1.48189 Prediction:  f you want mm\n",
      "1143 loss:  1.48156 Prediction:  f you want mm\n",
      "1144 loss:  1.48123 Prediction:  f you want mm\n",
      "1145 loss:  1.48089 Prediction:  f you want mm\n",
      "1146 loss:  1.48056 Prediction:  f you want mm\n",
      "1147 loss:  1.48023 Prediction:  f you want mm\n",
      "1148 loss:  1.47991 Prediction:  f you want mm\n",
      "1149 loss:  1.47958 Prediction:  f you want mm\n",
      "1150 loss:  1.47925 Prediction:  f you want mm\n",
      "1151 loss:  1.47892 Prediction:  f you want mm\n",
      "1152 loss:  1.47859 Prediction:  f you want mm\n",
      "1153 loss:  1.47827 Prediction:  f you want mm\n",
      "1154 loss:  1.47794 Prediction:  f you want mm\n",
      "1155 loss:  1.47762 Prediction:  f you want mm\n",
      "1156 loss:  1.47729 Prediction:  f you want mm\n",
      "1157 loss:  1.47697 Prediction:  f you want mm\n",
      "1158 loss:  1.47665 Prediction:  f you want mm\n",
      "1159 loss:  1.47632 Prediction:  f you want mm\n",
      "1160 loss:  1.476 Prediction:  f you want mm\n",
      "1161 loss:  1.47568 Prediction:  f you want mm\n",
      "1162 loss:  1.47536 Prediction:  f you want mm\n",
      "1163 loss:  1.47504 Prediction:  f you want mm\n",
      "1164 loss:  1.47472 Prediction:  f you want mm\n",
      "1165 loss:  1.4744 Prediction:  f you want mm\n",
      "1166 loss:  1.47408 Prediction:  f you want mm\n",
      "1167 loss:  1.47377 Prediction:  f you want mm\n",
      "1168 loss:  1.47345 Prediction:  f you want mm\n",
      "1169 loss:  1.47313 Prediction:  f you want mm\n",
      "1170 loss:  1.47282 Prediction:  f you want mm\n",
      "1171 loss:  1.4725 Prediction:  f you want mm\n",
      "1172 loss:  1.47219 Prediction:  f you want mm\n",
      "1173 loss:  1.47187 Prediction:  f you want mm\n",
      "1174 loss:  1.47156 Prediction:  f you want mm\n",
      "1175 loss:  1.47125 Prediction:  f you want mm\n",
      "1176 loss:  1.47093 Prediction:  f you want mm\n",
      "1177 loss:  1.47062 Prediction:  f you want mm\n",
      "1178 loss:  1.47031 Prediction:  f you want mm\n",
      "1179 loss:  1.47 Prediction:  f you want mm\n",
      "1180 loss:  1.46969 Prediction:  f you want mm\n",
      "1181 loss:  1.46938 Prediction:  f you want mm\n",
      "1182 loss:  1.46907 Prediction:  f you want mm\n",
      "1183 loss:  1.46876 Prediction:  f you want mm\n",
      "1184 loss:  1.46846 Prediction:  f you want mm\n",
      "1185 loss:  1.46815 Prediction:  f you want mm\n",
      "1186 loss:  1.46784 Prediction:  f you want mm\n",
      "1187 loss:  1.46754 Prediction:  f you want mm\n",
      "1188 loss:  1.46723 Prediction:  f you want mm\n",
      "1189 loss:  1.46693 Prediction:  f you want mm\n",
      "1190 loss:  1.46662 Prediction:  f you want mm\n",
      "1191 loss:  1.46632 Prediction:  f you want mm\n",
      "1192 loss:  1.46602 Prediction:  f you want mm\n",
      "1193 loss:  1.46571 Prediction:  f you want mm\n",
      "1194 loss:  1.46541 Prediction:  f you want mm\n",
      "1195 loss:  1.46511 Prediction:  f you want mm\n",
      "1196 loss:  1.46481 Prediction:  f you want mm\n",
      "1197 loss:  1.46451 Prediction:  f you want mm\n",
      "1198 loss:  1.46421 Prediction:  f you want mm\n",
      "1199 loss:  1.46391 Prediction:  f you want mm\n",
      "1200 loss:  1.46361 Prediction:  f you want mm\n",
      "1201 loss:  1.46331 Prediction:  f you want mm\n",
      "1202 loss:  1.46302 Prediction:  f you want mm\n",
      "1203 loss:  1.46272 Prediction:  f you want mm\n",
      "1204 loss:  1.46242 Prediction:  f you want mm\n",
      "1205 loss:  1.46213 Prediction:  f you want mm\n",
      "1206 loss:  1.46183 Prediction:  f you want mm\n",
      "1207 loss:  1.46154 Prediction:  f you want mm\n",
      "1208 loss:  1.46124 Prediction:  f you want mm\n",
      "1209 loss:  1.46095 Prediction:  f you want mm\n",
      "1210 loss:  1.46066 Prediction:  f you want mm\n",
      "1211 loss:  1.46036 Prediction:  f you want mm\n",
      "1212 loss:  1.46007 Prediction:  f you want mm\n",
      "1213 loss:  1.45978 Prediction:  f you want mm\n",
      "1214 loss:  1.45949 Prediction:  f you want mm\n",
      "1215 loss:  1.4592 Prediction:  f you want mm\n",
      "1216 loss:  1.45891 Prediction:  f you want mm\n",
      "1217 loss:  1.45862 Prediction:  f you want mm\n",
      "1218 loss:  1.45833 Prediction:  f you want mm\n",
      "1219 loss:  1.45804 Prediction:  f you want mm\n",
      "1220 loss:  1.45776 Prediction:  f you want mm\n",
      "1221 loss:  1.45747 Prediction:  f you want mm\n",
      "1222 loss:  1.45718 Prediction:  f you want mm\n",
      "1223 loss:  1.4569 Prediction:  f you want mm\n",
      "1224 loss:  1.45661 Prediction:  f you want mm\n",
      "1225 loss:  1.45633 Prediction:  f you want mm\n",
      "1226 loss:  1.45604 Prediction:  f you want mm\n",
      "1227 loss:  1.45576 Prediction:  f you want mm\n",
      "1228 loss:  1.45548 Prediction:  f you want mm\n",
      "1229 loss:  1.45519 Prediction:  f you want mm\n",
      "1230 loss:  1.45491 Prediction:  f you want mm\n",
      "1231 loss:  1.45463 Prediction:  f you want mm\n",
      "1232 loss:  1.45435 Prediction:  f you want mm\n",
      "1233 loss:  1.45407 Prediction:  f you want mm\n",
      "1234 loss:  1.45379 Prediction:  f you want mm\n",
      "1235 loss:  1.45351 Prediction:  f you want mm\n",
      "1236 loss:  1.45323 Prediction:  f you want mm\n",
      "1237 loss:  1.45295 Prediction:  f you want mm\n",
      "1238 loss:  1.45267 Prediction:  f you want mm\n",
      "1239 loss:  1.45239 Prediction:  f you want mm\n",
      "1240 loss:  1.45212 Prediction:  f you want mm\n",
      "1241 loss:  1.45184 Prediction:  f you want mm\n",
      "1242 loss:  1.45157 Prediction:  f you want mm\n",
      "1243 loss:  1.45129 Prediction:  f you want mm\n",
      "1244 loss:  1.45102 Prediction:  f you want mm\n",
      "1245 loss:  1.45074 Prediction:  f you want mm\n",
      "1246 loss:  1.45047 Prediction:  f you want mm\n",
      "1247 loss:  1.45019 Prediction:  f you want mm\n",
      "1248 loss:  1.44992 Prediction:  f you want mm\n",
      "1249 loss:  1.44965 Prediction:  f you want mm\n",
      "1250 loss:  1.44938 Prediction:  f you want mm\n",
      "1251 loss:  1.44911 Prediction:  f you want mm\n",
      "1252 loss:  1.44883 Prediction:  f you want mm\n",
      "1253 loss:  1.44856 Prediction:  f you want mm\n",
      "1254 loss:  1.44829 Prediction:  f you want mm\n",
      "1255 loss:  1.44803 Prediction:  f you want mm\n",
      "1256 loss:  1.44776 Prediction:  f you want mm\n",
      "1257 loss:  1.44749 Prediction:  f you want mm\n",
      "1258 loss:  1.44722 Prediction:  f you want mm\n",
      "1259 loss:  1.44695 Prediction:  f you want mm\n",
      "1260 loss:  1.44669 Prediction:  f you want mm\n",
      "1261 loss:  1.44642 Prediction:  f you want mm\n",
      "1262 loss:  1.44615 Prediction:  f you want mm\n",
      "1263 loss:  1.44589 Prediction:  f you want mm\n",
      "1264 loss:  1.44563 Prediction:  f you want mm\n",
      "1265 loss:  1.44536 Prediction:  f you want mm\n",
      "1266 loss:  1.4451 Prediction:  f you want mm\n",
      "1267 loss:  1.44483 Prediction:  f you want mm\n",
      "1268 loss:  1.44457 Prediction:  f you want mm\n",
      "1269 loss:  1.44431 Prediction:  f you want mm\n",
      "1270 loss:  1.44405 Prediction:  f you want mm\n",
      "1271 loss:  1.44379 Prediction:  f you want mm\n",
      "1272 loss:  1.44352 Prediction:  f you want mm\n",
      "1273 loss:  1.44326 Prediction:  f you want mm\n",
      "1274 loss:  1.443 Prediction:  f you want mm\n",
      "1275 loss:  1.44275 Prediction:  f you want mm\n",
      "1276 loss:  1.44249 Prediction:  f you want mm\n",
      "1277 loss:  1.44223 Prediction:  f you want mm\n",
      "1278 loss:  1.44197 Prediction:  f you want mm\n",
      "1279 loss:  1.44171 Prediction:  f you want mm\n",
      "1280 loss:  1.44146 Prediction:  f you want mm\n",
      "1281 loss:  1.4412 Prediction:  f you want mm\n",
      "1282 loss:  1.44094 Prediction:  f you want mm\n",
      "1283 loss:  1.44069 Prediction:  f you want mm\n",
      "1284 loss:  1.44043 Prediction:  f you want mm\n",
      "1285 loss:  1.44018 Prediction:  f you want mm\n",
      "1286 loss:  1.43992 Prediction:  f you want mm\n",
      "1287 loss:  1.43967 Prediction:  f you want mm\n",
      "1288 loss:  1.43942 Prediction:  f you want mm\n",
      "1289 loss:  1.43917 Prediction:  f you want mm\n",
      "1290 loss:  1.43891 Prediction:  f you want mm\n",
      "1291 loss:  1.43866 Prediction:  f you want mm\n",
      "1292 loss:  1.43841 Prediction:  f you want mm\n",
      "1293 loss:  1.43816 Prediction:  f you want mm\n",
      "1294 loss:  1.43791 Prediction:  f you want mm\n",
      "1295 loss:  1.43766 Prediction:  f you want mm\n",
      "1296 loss:  1.43741 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1297 loss:  1.43716 Prediction:  f you want mm\n",
      "1298 loss:  1.43691 Prediction:  f you want mm\n",
      "1299 loss:  1.43666 Prediction:  f you want mm\n",
      "1300 loss:  1.43642 Prediction:  f you want mm\n",
      "1301 loss:  1.43617 Prediction:  f you want mm\n",
      "1302 loss:  1.43592 Prediction:  f you want mm\n",
      "1303 loss:  1.43568 Prediction:  f you want mm\n",
      "1304 loss:  1.43543 Prediction:  f you want mm\n",
      "1305 loss:  1.43519 Prediction:  f you want mm\n",
      "1306 loss:  1.43494 Prediction:  f you want mm\n",
      "1307 loss:  1.4347 Prediction:  f you want mm\n",
      "1308 loss:  1.43445 Prediction:  f you want mm\n",
      "1309 loss:  1.43421 Prediction:  f you want mm\n",
      "1310 loss:  1.43397 Prediction:  f you want mm\n",
      "1311 loss:  1.43372 Prediction:  f you want mm\n",
      "1312 loss:  1.43348 Prediction:  f you want mm\n",
      "1313 loss:  1.43324 Prediction:  f you want mm\n",
      "1314 loss:  1.433 Prediction:  f you want mm\n",
      "1315 loss:  1.43276 Prediction:  f you want mm\n",
      "1316 loss:  1.43252 Prediction:  f you want mm\n",
      "1317 loss:  1.43228 Prediction:  f you want mm\n",
      "1318 loss:  1.43204 Prediction:  f you want mm\n",
      "1319 loss:  1.4318 Prediction:  f you want mm\n",
      "1320 loss:  1.43156 Prediction:  f you want mm\n",
      "1321 loss:  1.43132 Prediction:  f you want mm\n",
      "1322 loss:  1.43109 Prediction:  f you want mm\n",
      "1323 loss:  1.43085 Prediction:  f you want mm\n",
      "1324 loss:  1.43061 Prediction:  f you want mm\n",
      "1325 loss:  1.43038 Prediction:  f you want mm\n",
      "1326 loss:  1.43014 Prediction:  f you want mm\n",
      "1327 loss:  1.4299 Prediction:  f you want mm\n",
      "1328 loss:  1.42967 Prediction:  f you want mm\n",
      "1329 loss:  1.42944 Prediction:  f you want mm\n",
      "1330 loss:  1.4292 Prediction:  f you want mm\n",
      "1331 loss:  1.42897 Prediction:  f you want mm\n",
      "1332 loss:  1.42873 Prediction:  f you want mm\n",
      "1333 loss:  1.4285 Prediction:  f you want mm\n",
      "1334 loss:  1.42827 Prediction:  f you want mm\n",
      "1335 loss:  1.42804 Prediction:  f you want mm\n",
      "1336 loss:  1.42781 Prediction:  f you want mm\n",
      "1337 loss:  1.42757 Prediction:  f you want mm\n",
      "1338 loss:  1.42734 Prediction:  f you want mm\n",
      "1339 loss:  1.42711 Prediction:  f you want mm\n",
      "1340 loss:  1.42688 Prediction:  f you want mm\n",
      "1341 loss:  1.42665 Prediction:  f you want mm\n",
      "1342 loss:  1.42643 Prediction:  f you want mm\n",
      "1343 loss:  1.4262 Prediction:  f you want mm\n",
      "1344 loss:  1.42597 Prediction:  f you want mm\n",
      "1345 loss:  1.42574 Prediction:  f you want mm\n",
      "1346 loss:  1.42551 Prediction:  f you want mm\n",
      "1347 loss:  1.42529 Prediction:  f you want mm\n",
      "1348 loss:  1.42506 Prediction:  f you want mm\n",
      "1349 loss:  1.42483 Prediction:  f you want mm\n",
      "1350 loss:  1.42461 Prediction:  f you want mm\n",
      "1351 loss:  1.42438 Prediction:  f you want mm\n",
      "1352 loss:  1.42416 Prediction:  f you want mm\n",
      "1353 loss:  1.42393 Prediction:  f you want mm\n",
      "1354 loss:  1.42371 Prediction:  f you want mm\n",
      "1355 loss:  1.42349 Prediction:  f you want mm\n",
      "1356 loss:  1.42326 Prediction:  f you want mm\n",
      "1357 loss:  1.42304 Prediction:  f you want mm\n",
      "1358 loss:  1.42282 Prediction:  f you want mm\n",
      "1359 loss:  1.4226 Prediction:  f you want mm\n",
      "1360 loss:  1.42237 Prediction:  f you want mm\n",
      "1361 loss:  1.42215 Prediction:  f you want mm\n",
      "1362 loss:  1.42193 Prediction:  f you want mm\n",
      "1363 loss:  1.42171 Prediction:  f you want mm\n",
      "1364 loss:  1.42149 Prediction:  f you want mm\n",
      "1365 loss:  1.42127 Prediction:  f you want mm\n",
      "1366 loss:  1.42105 Prediction:  f you want mm\n",
      "1367 loss:  1.42084 Prediction:  f you want mm\n",
      "1368 loss:  1.42062 Prediction:  f you want mm\n",
      "1369 loss:  1.4204 Prediction:  f you want mm\n",
      "1370 loss:  1.42018 Prediction:  f you want mm\n",
      "1371 loss:  1.41996 Prediction:  f you want mm\n",
      "1372 loss:  1.41975 Prediction:  f you want mm\n",
      "1373 loss:  1.41953 Prediction:  f you want mm\n",
      "1374 loss:  1.41932 Prediction:  f you want mm\n",
      "1375 loss:  1.4191 Prediction:  f you want mm\n",
      "1376 loss:  1.41888 Prediction:  f you want mm\n",
      "1377 loss:  1.41867 Prediction:  f you want mm\n",
      "1378 loss:  1.41846 Prediction:  f you want mm\n",
      "1379 loss:  1.41824 Prediction:  f you want mm\n",
      "1380 loss:  1.41803 Prediction:  f you want mm\n",
      "1381 loss:  1.41781 Prediction:  f you want mm\n",
      "1382 loss:  1.4176 Prediction:  f you want mm\n",
      "1383 loss:  1.41739 Prediction:  f you want mm\n",
      "1384 loss:  1.41718 Prediction:  f you want mm\n",
      "1385 loss:  1.41697 Prediction:  f you want mm\n",
      "1386 loss:  1.41675 Prediction:  f you want mm\n",
      "1387 loss:  1.41654 Prediction:  f you want mm\n",
      "1388 loss:  1.41633 Prediction:  f you want mm\n",
      "1389 loss:  1.41612 Prediction:  f you want mm\n",
      "1390 loss:  1.41591 Prediction:  f you want mm\n",
      "1391 loss:  1.4157 Prediction:  f you want mm\n",
      "1392 loss:  1.41549 Prediction:  f you want mm\n",
      "1393 loss:  1.41529 Prediction:  f you want mm\n",
      "1394 loss:  1.41508 Prediction:  f you want mm\n",
      "1395 loss:  1.41487 Prediction:  f you want mm\n",
      "1396 loss:  1.41466 Prediction:  f you want mm\n",
      "1397 loss:  1.41446 Prediction:  f you want mm\n",
      "1398 loss:  1.41425 Prediction:  f you want mm\n",
      "1399 loss:  1.41404 Prediction:  f you want mm\n",
      "1400 loss:  1.41384 Prediction:  f you want mm\n",
      "1401 loss:  1.41363 Prediction:  f you want mm\n",
      "1402 loss:  1.41343 Prediction:  f you want mm\n",
      "1403 loss:  1.41322 Prediction:  f you want mm\n",
      "1404 loss:  1.41302 Prediction:  f you want mm\n",
      "1405 loss:  1.41281 Prediction:  f you want mm\n",
      "1406 loss:  1.41261 Prediction:  f you want mm\n",
      "1407 loss:  1.41241 Prediction:  f you want mm\n",
      "1408 loss:  1.4122 Prediction:  f you want mm\n",
      "1409 loss:  1.412 Prediction:  f you want mm\n",
      "1410 loss:  1.4118 Prediction:  f you want mm\n",
      "1411 loss:  1.4116 Prediction:  f you want mm\n",
      "1412 loss:  1.41139 Prediction:  f you want mm\n",
      "1413 loss:  1.41119 Prediction:  f you want mm\n",
      "1414 loss:  1.41099 Prediction:  f you want mm\n",
      "1415 loss:  1.41079 Prediction:  f you want mm\n",
      "1416 loss:  1.41059 Prediction:  f you want mm\n",
      "1417 loss:  1.41039 Prediction:  f you want mm\n",
      "1418 loss:  1.41019 Prediction:  f you want mm\n",
      "1419 loss:  1.40999 Prediction:  f you want mm\n",
      "1420 loss:  1.40979 Prediction:  f you want mm\n",
      "1421 loss:  1.4096 Prediction:  f you want mm\n",
      "1422 loss:  1.4094 Prediction:  f you want mm\n",
      "1423 loss:  1.4092 Prediction:  f you want mm\n",
      "1424 loss:  1.409 Prediction:  f you want mm\n",
      "1425 loss:  1.40881 Prediction:  f you want mm\n",
      "1426 loss:  1.40861 Prediction:  f you want mm\n",
      "1427 loss:  1.40841 Prediction:  f you want mm\n",
      "1428 loss:  1.40822 Prediction:  f you want mm\n",
      "1429 loss:  1.40802 Prediction:  f you want mm\n",
      "1430 loss:  1.40783 Prediction:  f you want mm\n",
      "1431 loss:  1.40763 Prediction:  f you want mm\n",
      "1432 loss:  1.40744 Prediction:  f you want mm\n",
      "1433 loss:  1.40724 Prediction:  f you want mm\n",
      "1434 loss:  1.40705 Prediction:  f you want mm\n",
      "1435 loss:  1.40686 Prediction:  f you want mm\n",
      "1436 loss:  1.40666 Prediction:  f you want mm\n",
      "1437 loss:  1.40647 Prediction:  f you want mm\n",
      "1438 loss:  1.40628 Prediction:  f you want mm\n",
      "1439 loss:  1.40609 Prediction:  f you want mm\n",
      "1440 loss:  1.40589 Prediction:  f you want mm\n",
      "1441 loss:  1.4057 Prediction:  f you want mm\n",
      "1442 loss:  1.40551 Prediction:  f you want mm\n",
      "1443 loss:  1.40532 Prediction:  f you want mm\n",
      "1444 loss:  1.40513 Prediction:  f you want mm\n",
      "1445 loss:  1.40494 Prediction:  f you want mm\n",
      "1446 loss:  1.40475 Prediction:  f you want mm\n",
      "1447 loss:  1.40456 Prediction:  f you want mm\n",
      "1448 loss:  1.40437 Prediction:  f you want mm\n",
      "1449 loss:  1.40418 Prediction:  f you want mm\n",
      "1450 loss:  1.404 Prediction:  f you want mm\n",
      "1451 loss:  1.40381 Prediction:  f you want mm\n",
      "1452 loss:  1.40362 Prediction:  f you want mm\n",
      "1453 loss:  1.40343 Prediction:  f you want mm\n",
      "1454 loss:  1.40325 Prediction:  f you want mm\n",
      "1455 loss:  1.40306 Prediction:  f you want mm\n",
      "1456 loss:  1.40287 Prediction:  f you want mm\n",
      "1457 loss:  1.40269 Prediction:  f you want mm\n",
      "1458 loss:  1.4025 Prediction:  f you want mm\n",
      "1459 loss:  1.40232 Prediction:  f you want mm\n",
      "1460 loss:  1.40213 Prediction:  f you want mm\n",
      "1461 loss:  1.40195 Prediction:  f you want mm\n",
      "1462 loss:  1.40176 Prediction:  f you want mm\n",
      "1463 loss:  1.40158 Prediction:  f you want mm\n",
      "1464 loss:  1.40139 Prediction:  f you want mm\n",
      "1465 loss:  1.40121 Prediction:  f you want mm\n",
      "1466 loss:  1.40103 Prediction:  f you want mm\n",
      "1467 loss:  1.40084 Prediction:  f you want mm\n",
      "1468 loss:  1.40066 Prediction:  f you want mm\n",
      "1469 loss:  1.40048 Prediction:  f you want mm\n",
      "1470 loss:  1.4003 Prediction:  f you want mm\n",
      "1471 loss:  1.40012 Prediction:  f you want mm\n",
      "1472 loss:  1.39994 Prediction:  f you want mm\n",
      "1473 loss:  1.39975 Prediction:  f you want mm\n",
      "1474 loss:  1.39957 Prediction:  f you want mm\n",
      "1475 loss:  1.39939 Prediction:  f you want mm\n",
      "1476 loss:  1.39921 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1477 loss:  1.39903 Prediction:  f you want mm\n",
      "1478 loss:  1.39885 Prediction:  f you want mm\n",
      "1479 loss:  1.39868 Prediction:  f you want mm\n",
      "1480 loss:  1.3985 Prediction:  f you want mm\n",
      "1481 loss:  1.39832 Prediction:  f you want mm\n",
      "1482 loss:  1.39814 Prediction:  f you want mm\n",
      "1483 loss:  1.39796 Prediction:  f you want mm\n",
      "1484 loss:  1.39779 Prediction:  f you want mm\n",
      "1485 loss:  1.39761 Prediction:  f you want mm\n",
      "1486 loss:  1.39743 Prediction:  f you want mm\n",
      "1487 loss:  1.39726 Prediction:  f you want mm\n",
      "1488 loss:  1.39708 Prediction:  f you want mm\n",
      "1489 loss:  1.3969 Prediction:  f you want mm\n",
      "1490 loss:  1.39673 Prediction:  f you want mm\n",
      "1491 loss:  1.39655 Prediction:  f you want mm\n",
      "1492 loss:  1.39638 Prediction:  f you want mm\n",
      "1493 loss:  1.3962 Prediction:  f you want mm\n",
      "1494 loss:  1.39603 Prediction:  f you want mm\n",
      "1495 loss:  1.39585 Prediction:  f you want mm\n",
      "1496 loss:  1.39568 Prediction:  f you want mm\n",
      "1497 loss:  1.39551 Prediction:  f you want mm\n",
      "1498 loss:  1.39533 Prediction:  f you want mm\n",
      "1499 loss:  1.39516 Prediction:  f you want mm\n",
      "1500 loss:  1.39499 Prediction:  f you want mm\n",
      "1501 loss:  1.39482 Prediction:  f you want mm\n",
      "1502 loss:  1.39464 Prediction:  f you want mm\n",
      "1503 loss:  1.39447 Prediction:  f you want mm\n",
      "1504 loss:  1.3943 Prediction:  f you want mm\n",
      "1505 loss:  1.39413 Prediction:  f you want mm\n",
      "1506 loss:  1.39396 Prediction:  f you want mm\n",
      "1507 loss:  1.39379 Prediction:  f you want mm\n",
      "1508 loss:  1.39362 Prediction:  f you want mm\n",
      "1509 loss:  1.39345 Prediction:  f you want mm\n",
      "1510 loss:  1.39328 Prediction:  f you want mm\n",
      "1511 loss:  1.39311 Prediction:  f you want mm\n",
      "1512 loss:  1.39294 Prediction:  f you want mm\n",
      "1513 loss:  1.39277 Prediction:  f you want mm\n",
      "1514 loss:  1.3926 Prediction:  f you want mm\n",
      "1515 loss:  1.39244 Prediction:  f you want mm\n",
      "1516 loss:  1.39227 Prediction:  f you want mm\n",
      "1517 loss:  1.3921 Prediction:  f you want mm\n",
      "1518 loss:  1.39193 Prediction:  f you want mm\n",
      "1519 loss:  1.39177 Prediction:  f you want mm\n",
      "1520 loss:  1.3916 Prediction:  f you want mm\n",
      "1521 loss:  1.39143 Prediction:  f you want mm\n",
      "1522 loss:  1.39127 Prediction:  f you want mm\n",
      "1523 loss:  1.3911 Prediction:  f you want mm\n",
      "1524 loss:  1.39094 Prediction:  f you want mm\n",
      "1525 loss:  1.39077 Prediction:  f you want mm\n",
      "1526 loss:  1.39061 Prediction:  f you want mm\n",
      "1527 loss:  1.39044 Prediction:  f you want mm\n",
      "1528 loss:  1.39028 Prediction:  f you want mm\n",
      "1529 loss:  1.39011 Prediction:  f you want mm\n",
      "1530 loss:  1.38995 Prediction:  f you want mm\n",
      "1531 loss:  1.38979 Prediction:  f you want mm\n",
      "1532 loss:  1.38962 Prediction:  f you want mm\n",
      "1533 loss:  1.38946 Prediction:  f you want mm\n",
      "1534 loss:  1.3893 Prediction:  f you want mm\n",
      "1535 loss:  1.38913 Prediction:  f you want mm\n",
      "1536 loss:  1.38897 Prediction:  f you want mm\n",
      "1537 loss:  1.38881 Prediction:  f you want mm\n",
      "1538 loss:  1.38865 Prediction:  f you want mm\n",
      "1539 loss:  1.38849 Prediction:  f you want mm\n",
      "1540 loss:  1.38833 Prediction:  f you want mm\n",
      "1541 loss:  1.38817 Prediction:  f you want mm\n",
      "1542 loss:  1.388 Prediction:  f you want mm\n",
      "1543 loss:  1.38784 Prediction:  f you want mm\n",
      "1544 loss:  1.38768 Prediction:  f you want mm\n",
      "1545 loss:  1.38752 Prediction:  f you want mm\n",
      "1546 loss:  1.38737 Prediction:  f you want mm\n",
      "1547 loss:  1.38721 Prediction:  f you want mm\n",
      "1548 loss:  1.38705 Prediction:  f you want mm\n",
      "1549 loss:  1.38689 Prediction:  f you want mm\n",
      "1550 loss:  1.38673 Prediction:  f you want mm\n",
      "1551 loss:  1.38657 Prediction:  f you want mm\n",
      "1552 loss:  1.38641 Prediction:  f you want mm\n",
      "1553 loss:  1.38626 Prediction:  f you want mm\n",
      "1554 loss:  1.3861 Prediction:  f you want mm\n",
      "1555 loss:  1.38594 Prediction:  f you want mm\n",
      "1556 loss:  1.38579 Prediction:  f you want mm\n",
      "1557 loss:  1.38563 Prediction:  f you want mm\n",
      "1558 loss:  1.38547 Prediction:  f you want mm\n",
      "1559 loss:  1.38532 Prediction:  f you want mm\n",
      "1560 loss:  1.38516 Prediction:  f you want mm\n",
      "1561 loss:  1.38501 Prediction:  f you want mm\n",
      "1562 loss:  1.38485 Prediction:  f you want mm\n",
      "1563 loss:  1.3847 Prediction:  f you want mm\n",
      "1564 loss:  1.38454 Prediction:  f you want mm\n",
      "1565 loss:  1.38439 Prediction:  f you want mm\n",
      "1566 loss:  1.38423 Prediction:  f you want mm\n",
      "1567 loss:  1.38408 Prediction:  f you want mm\n",
      "1568 loss:  1.38392 Prediction:  f you want mm\n",
      "1569 loss:  1.38377 Prediction:  f you want mm\n",
      "1570 loss:  1.38362 Prediction:  f you want mm\n",
      "1571 loss:  1.38347 Prediction:  f you want mm\n",
      "1572 loss:  1.38331 Prediction:  f you want mm\n",
      "1573 loss:  1.38316 Prediction:  f you want mm\n",
      "1574 loss:  1.38301 Prediction:  f you want mm\n",
      "1575 loss:  1.38286 Prediction:  f you want mm\n",
      "1576 loss:  1.3827 Prediction:  f you want mm\n",
      "1577 loss:  1.38255 Prediction:  f you want mm\n",
      "1578 loss:  1.3824 Prediction:  f you want mm\n",
      "1579 loss:  1.38225 Prediction:  f you want mm\n",
      "1580 loss:  1.3821 Prediction:  f you want mm\n",
      "1581 loss:  1.38195 Prediction:  f you want mm\n",
      "1582 loss:  1.3818 Prediction:  f you want mm\n",
      "1583 loss:  1.38165 Prediction:  f you want mm\n",
      "1584 loss:  1.3815 Prediction:  f you want mm\n",
      "1585 loss:  1.38135 Prediction:  f you want mm\n",
      "1586 loss:  1.3812 Prediction:  f you want mm\n",
      "1587 loss:  1.38105 Prediction:  f you want mm\n",
      "1588 loss:  1.38091 Prediction:  f you want mm\n",
      "1589 loss:  1.38076 Prediction:  f you want mm\n",
      "1590 loss:  1.38061 Prediction:  f you want mm\n",
      "1591 loss:  1.38046 Prediction:  f you want mm\n",
      "1592 loss:  1.38031 Prediction:  f you want mm\n",
      "1593 loss:  1.38017 Prediction:  f you want mm\n",
      "1594 loss:  1.38002 Prediction:  f you want mm\n",
      "1595 loss:  1.37987 Prediction:  f you want mm\n",
      "1596 loss:  1.37973 Prediction:  f you want mm\n",
      "1597 loss:  1.37958 Prediction:  f you want mm\n",
      "1598 loss:  1.37943 Prediction:  f you want mm\n",
      "1599 loss:  1.37929 Prediction:  f you want mm\n",
      "1600 loss:  1.37914 Prediction:  f you want mm\n",
      "1601 loss:  1.379 Prediction:  f you want mm\n",
      "1602 loss:  1.37885 Prediction:  f you want mm\n",
      "1603 loss:  1.37871 Prediction:  f you want mm\n",
      "1604 loss:  1.37856 Prediction:  f you want mm\n",
      "1605 loss:  1.37842 Prediction:  f you want mm\n",
      "1606 loss:  1.37827 Prediction:  f you want mm\n",
      "1607 loss:  1.37813 Prediction:  f you want mm\n",
      "1608 loss:  1.37798 Prediction:  f you want mm\n",
      "1609 loss:  1.37784 Prediction:  f you want mm\n",
      "1610 loss:  1.3777 Prediction:  f you want mm\n",
      "1611 loss:  1.37755 Prediction:  f you want mm\n",
      "1612 loss:  1.37741 Prediction:  f you want mm\n",
      "1613 loss:  1.37727 Prediction:  f you want mm\n",
      "1614 loss:  1.37713 Prediction:  f you want mm\n",
      "1615 loss:  1.37698 Prediction:  f you want mm\n",
      "1616 loss:  1.37684 Prediction:  f you want mm\n",
      "1617 loss:  1.3767 Prediction:  f you want mm\n",
      "1618 loss:  1.37656 Prediction:  f you want mm\n",
      "1619 loss:  1.37642 Prediction:  f you want mm\n",
      "1620 loss:  1.37628 Prediction:  f you want mm\n",
      "1621 loss:  1.37614 Prediction:  f you want mm\n",
      "1622 loss:  1.376 Prediction:  f you want mm\n",
      "1623 loss:  1.37586 Prediction:  f you want mm\n",
      "1624 loss:  1.37572 Prediction:  f you want mm\n",
      "1625 loss:  1.37558 Prediction:  f you want mm\n",
      "1626 loss:  1.37544 Prediction:  f you want mm\n",
      "1627 loss:  1.3753 Prediction:  f you want mm\n",
      "1628 loss:  1.37516 Prediction:  f you want mm\n",
      "1629 loss:  1.37502 Prediction:  f you want mm\n",
      "1630 loss:  1.37488 Prediction:  f you want mm\n",
      "1631 loss:  1.37474 Prediction:  f you want mm\n",
      "1632 loss:  1.3746 Prediction:  f you want mm\n",
      "1633 loss:  1.37446 Prediction:  f you want mm\n",
      "1634 loss:  1.37433 Prediction:  f you want mm\n",
      "1635 loss:  1.37419 Prediction:  f you want mm\n",
      "1636 loss:  1.37405 Prediction:  f you want mm\n",
      "1637 loss:  1.37391 Prediction:  f you want mm\n",
      "1638 loss:  1.37378 Prediction:  f you want mm\n",
      "1639 loss:  1.37364 Prediction:  f you want mm\n",
      "1640 loss:  1.3735 Prediction:  f you want mm\n",
      "1641 loss:  1.37337 Prediction:  f you want mm\n",
      "1642 loss:  1.37323 Prediction:  f you want mm\n",
      "1643 loss:  1.3731 Prediction:  f you want mm\n",
      "1644 loss:  1.37296 Prediction:  f you want mm\n",
      "1645 loss:  1.37283 Prediction:  f you want mm\n",
      "1646 loss:  1.37269 Prediction:  f you want mm\n",
      "1647 loss:  1.37256 Prediction:  f you want mm\n",
      "1648 loss:  1.37242 Prediction:  f you want mm\n",
      "1649 loss:  1.37229 Prediction:  f you want mm\n",
      "1650 loss:  1.37215 Prediction:  f you want mm\n",
      "1651 loss:  1.37202 Prediction:  f you want mm\n",
      "1652 loss:  1.37188 Prediction:  f you want mm\n",
      "1653 loss:  1.37175 Prediction:  f you want mm\n",
      "1654 loss:  1.37162 Prediction:  f you want mm\n",
      "1655 loss:  1.37148 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656 loss:  1.37135 Prediction:  f you want mm\n",
      "1657 loss:  1.37122 Prediction:  f you want mm\n",
      "1658 loss:  1.37108 Prediction:  f you want mm\n",
      "1659 loss:  1.37095 Prediction:  f you want mm\n",
      "1660 loss:  1.37082 Prediction:  f you want mm\n",
      "1661 loss:  1.37069 Prediction:  f you want mm\n",
      "1662 loss:  1.37056 Prediction:  f you want mm\n",
      "1663 loss:  1.37042 Prediction:  f you want mm\n",
      "1664 loss:  1.37029 Prediction:  f you want mm\n",
      "1665 loss:  1.37016 Prediction:  f you want mm\n",
      "1666 loss:  1.37003 Prediction:  f you want mm\n",
      "1667 loss:  1.3699 Prediction:  f you want mm\n",
      "1668 loss:  1.36977 Prediction:  f you want mm\n",
      "1669 loss:  1.36964 Prediction:  f you want mm\n",
      "1670 loss:  1.36951 Prediction:  f you want mm\n",
      "1671 loss:  1.36938 Prediction:  f you want mm\n",
      "1672 loss:  1.36925 Prediction:  f you want mm\n",
      "1673 loss:  1.36912 Prediction:  f you want mm\n",
      "1674 loss:  1.36899 Prediction:  f you want mm\n",
      "1675 loss:  1.36886 Prediction:  f you want mm\n",
      "1676 loss:  1.36873 Prediction:  f you want mm\n",
      "1677 loss:  1.3686 Prediction:  f you want mm\n",
      "1678 loss:  1.36848 Prediction:  f you want mm\n",
      "1679 loss:  1.36835 Prediction:  f you want mm\n",
      "1680 loss:  1.36822 Prediction:  f you want mm\n",
      "1681 loss:  1.36809 Prediction:  f you want mm\n",
      "1682 loss:  1.36796 Prediction:  f you want mm\n",
      "1683 loss:  1.36784 Prediction:  f you want mm\n",
      "1684 loss:  1.36771 Prediction:  f you want mm\n",
      "1685 loss:  1.36758 Prediction:  f you want mm\n",
      "1686 loss:  1.36746 Prediction:  f you want mm\n",
      "1687 loss:  1.36733 Prediction:  f you want mm\n",
      "1688 loss:  1.3672 Prediction:  f you want mm\n",
      "1689 loss:  1.36708 Prediction:  f you want mm\n",
      "1690 loss:  1.36695 Prediction:  f you want mm\n",
      "1691 loss:  1.36682 Prediction:  f you want mm\n",
      "1692 loss:  1.3667 Prediction:  f you want mm\n",
      "1693 loss:  1.36657 Prediction:  f you want mm\n",
      "1694 loss:  1.36645 Prediction:  f you want mm\n",
      "1695 loss:  1.36632 Prediction:  f you want mm\n",
      "1696 loss:  1.3662 Prediction:  f you want mm\n",
      "1697 loss:  1.36607 Prediction:  f you want mm\n",
      "1698 loss:  1.36595 Prediction:  f you want mm\n",
      "1699 loss:  1.36582 Prediction:  f you want mm\n",
      "1700 loss:  1.3657 Prediction:  f you want mm\n",
      "1701 loss:  1.36558 Prediction:  f you want mm\n",
      "1702 loss:  1.36545 Prediction:  f you want mm\n",
      "1703 loss:  1.36533 Prediction:  f you want mm\n",
      "1704 loss:  1.36521 Prediction:  f you want mm\n",
      "1705 loss:  1.36508 Prediction:  f you want mm\n",
      "1706 loss:  1.36496 Prediction:  f you want mm\n",
      "1707 loss:  1.36484 Prediction:  f you want mm\n",
      "1708 loss:  1.36471 Prediction:  f you want mm\n",
      "1709 loss:  1.36459 Prediction:  f you want mm\n",
      "1710 loss:  1.36447 Prediction:  f you want mm\n",
      "1711 loss:  1.36435 Prediction:  f you want mm\n",
      "1712 loss:  1.36423 Prediction:  f you want mm\n",
      "1713 loss:  1.3641 Prediction:  f you want mm\n",
      "1714 loss:  1.36398 Prediction:  f you want mm\n",
      "1715 loss:  1.36386 Prediction:  f you want mm\n",
      "1716 loss:  1.36374 Prediction:  f you want mm\n",
      "1717 loss:  1.36362 Prediction:  f you want mm\n",
      "1718 loss:  1.3635 Prediction:  f you want mm\n",
      "1719 loss:  1.36338 Prediction:  f you want mm\n",
      "1720 loss:  1.36326 Prediction:  f you want mm\n",
      "1721 loss:  1.36314 Prediction:  f you want mm\n",
      "1722 loss:  1.36302 Prediction:  f you want mm\n",
      "1723 loss:  1.3629 Prediction:  f you want mm\n",
      "1724 loss:  1.36278 Prediction:  f you want mm\n",
      "1725 loss:  1.36266 Prediction:  f you want mm\n",
      "1726 loss:  1.36254 Prediction:  f you want mm\n",
      "1727 loss:  1.36242 Prediction:  f you want mm\n",
      "1728 loss:  1.3623 Prediction:  f you want mm\n",
      "1729 loss:  1.36218 Prediction:  f you want mm\n",
      "1730 loss:  1.36206 Prediction:  f you want mm\n",
      "1731 loss:  1.36195 Prediction:  f you want mm\n",
      "1732 loss:  1.36183 Prediction:  f you want mm\n",
      "1733 loss:  1.36171 Prediction:  f you want mm\n",
      "1734 loss:  1.36159 Prediction:  f you want mm\n",
      "1735 loss:  1.36147 Prediction:  f you want mm\n",
      "1736 loss:  1.36136 Prediction:  f you want mm\n",
      "1737 loss:  1.36124 Prediction:  f you want mm\n",
      "1738 loss:  1.36112 Prediction:  f you want mm\n",
      "1739 loss:  1.36101 Prediction:  f you want mm\n",
      "1740 loss:  1.36089 Prediction:  f you want mm\n",
      "1741 loss:  1.36077 Prediction:  f you want mm\n",
      "1742 loss:  1.36066 Prediction:  f you want mm\n",
      "1743 loss:  1.36054 Prediction:  f you want mm\n",
      "1744 loss:  1.36042 Prediction:  f you want mm\n",
      "1745 loss:  1.36031 Prediction:  f you want mm\n",
      "1746 loss:  1.36019 Prediction:  f you want mm\n",
      "1747 loss:  1.36008 Prediction:  f you want mm\n",
      "1748 loss:  1.35996 Prediction:  f you want mm\n",
      "1749 loss:  1.35985 Prediction:  f you want mm\n",
      "1750 loss:  1.35973 Prediction:  f you want mm\n",
      "1751 loss:  1.35962 Prediction:  f you want mm\n",
      "1752 loss:  1.3595 Prediction:  f you want mm\n",
      "1753 loss:  1.35939 Prediction:  f you want mm\n",
      "1754 loss:  1.35927 Prediction:  f you want mm\n",
      "1755 loss:  1.35916 Prediction:  f you want mm\n",
      "1756 loss:  1.35905 Prediction:  f you want mm\n",
      "1757 loss:  1.35893 Prediction:  f you want mm\n",
      "1758 loss:  1.35882 Prediction:  f you want mm\n",
      "1759 loss:  1.35871 Prediction:  f you want mm\n",
      "1760 loss:  1.35859 Prediction:  f you want mm\n",
      "1761 loss:  1.35848 Prediction:  f you want mm\n",
      "1762 loss:  1.35837 Prediction:  f you want mm\n",
      "1763 loss:  1.35825 Prediction:  f you want mm\n",
      "1764 loss:  1.35814 Prediction:  f you want mm\n",
      "1765 loss:  1.35803 Prediction:  f you want mm\n",
      "1766 loss:  1.35792 Prediction:  f you want mm\n",
      "1767 loss:  1.3578 Prediction:  f you want mm\n",
      "1768 loss:  1.35769 Prediction:  f you want mm\n",
      "1769 loss:  1.35758 Prediction:  f you want mm\n",
      "1770 loss:  1.35747 Prediction:  f you want mm\n",
      "1771 loss:  1.35736 Prediction:  f you want mm\n",
      "1772 loss:  1.35725 Prediction:  f you want mm\n",
      "1773 loss:  1.35714 Prediction:  f you want mm\n",
      "1774 loss:  1.35702 Prediction:  f you want mm\n",
      "1775 loss:  1.35691 Prediction:  f you want mm\n",
      "1776 loss:  1.3568 Prediction:  f you want mm\n",
      "1777 loss:  1.35669 Prediction:  f you want mm\n",
      "1778 loss:  1.35658 Prediction:  f you want mm\n",
      "1779 loss:  1.35647 Prediction:  f you want mm\n",
      "1780 loss:  1.35636 Prediction:  f you want mm\n",
      "1781 loss:  1.35625 Prediction:  f you want mm\n",
      "1782 loss:  1.35614 Prediction:  f you want mm\n",
      "1783 loss:  1.35603 Prediction:  f you want mm\n",
      "1784 loss:  1.35592 Prediction:  f you want mm\n",
      "1785 loss:  1.35582 Prediction:  f you want mm\n",
      "1786 loss:  1.35571 Prediction:  f you want mm\n",
      "1787 loss:  1.3556 Prediction:  f you want mm\n",
      "1788 loss:  1.35549 Prediction:  f you want mm\n",
      "1789 loss:  1.35538 Prediction:  f you want mm\n",
      "1790 loss:  1.35527 Prediction:  f you want mm\n",
      "1791 loss:  1.35516 Prediction:  f you want mm\n",
      "1792 loss:  1.35506 Prediction:  f you want mm\n",
      "1793 loss:  1.35495 Prediction:  f you want mm\n",
      "1794 loss:  1.35484 Prediction:  f you want mm\n",
      "1795 loss:  1.35473 Prediction:  f you want mm\n",
      "1796 loss:  1.35463 Prediction:  f you want mm\n",
      "1797 loss:  1.35452 Prediction:  f you want mm\n",
      "1798 loss:  1.35441 Prediction:  f you want mm\n",
      "1799 loss:  1.3543 Prediction:  f you want mm\n",
      "1800 loss:  1.3542 Prediction:  f you want mm\n",
      "1801 loss:  1.35409 Prediction:  f you want mm\n",
      "1802 loss:  1.35399 Prediction:  f you want mm\n",
      "1803 loss:  1.35388 Prediction:  f you want mm\n",
      "1804 loss:  1.35377 Prediction:  f you want mm\n",
      "1805 loss:  1.35367 Prediction:  f you want mm\n",
      "1806 loss:  1.35356 Prediction:  f you want mm\n",
      "1807 loss:  1.35346 Prediction:  f you want mm\n",
      "1808 loss:  1.35335 Prediction:  f you want mm\n",
      "1809 loss:  1.35324 Prediction:  f you want mm\n",
      "1810 loss:  1.35314 Prediction:  f you want mm\n",
      "1811 loss:  1.35303 Prediction:  f you want mm\n",
      "1812 loss:  1.35293 Prediction:  f you want mm\n",
      "1813 loss:  1.35283 Prediction:  f you want mm\n",
      "1814 loss:  1.35272 Prediction:  f you want mm\n",
      "1815 loss:  1.35262 Prediction:  f you want mm\n",
      "1816 loss:  1.35251 Prediction:  f you want mm\n",
      "1817 loss:  1.35241 Prediction:  f you want mm\n",
      "1818 loss:  1.3523 Prediction:  f you want mm\n",
      "1819 loss:  1.3522 Prediction:  f you want mm\n",
      "1820 loss:  1.3521 Prediction:  f you want mm\n",
      "1821 loss:  1.35199 Prediction:  f you want mm\n",
      "1822 loss:  1.35189 Prediction:  f you want mm\n",
      "1823 loss:  1.35179 Prediction:  f you want mm\n",
      "1824 loss:  1.35168 Prediction:  f you want mm\n",
      "1825 loss:  1.35158 Prediction:  f you want mm\n",
      "1826 loss:  1.35148 Prediction:  f you want mm\n",
      "1827 loss:  1.35138 Prediction:  f you want mm\n",
      "1828 loss:  1.35127 Prediction:  f you want mm\n",
      "1829 loss:  1.35117 Prediction:  f you want mm\n",
      "1830 loss:  1.35107 Prediction:  f you want mm\n",
      "1831 loss:  1.35097 Prediction:  f you want mm\n",
      "1832 loss:  1.35086 Prediction:  f you want mm\n",
      "1833 loss:  1.35076 Prediction:  f you want mm\n",
      "1834 loss:  1.35066 Prediction:  f you want mm\n",
      "1835 loss:  1.35056 Prediction:  f you want mm\n",
      "1836 loss:  1.35046 Prediction:  f you want mm\n",
      "1837 loss:  1.35036 Prediction:  f you want mm\n",
      "1838 loss:  1.35026 Prediction:  f you want mm\n",
      "1839 loss:  1.35016 Prediction:  f you want mm\n",
      "1840 loss:  1.35005 Prediction:  f you want mm\n",
      "1841 loss:  1.34995 Prediction:  f you want mm\n",
      "1842 loss:  1.34985 Prediction:  f you want mm\n",
      "1843 loss:  1.34975 Prediction:  f you want mm\n",
      "1844 loss:  1.34965 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845 loss:  1.34955 Prediction:  f you want mm\n",
      "1846 loss:  1.34945 Prediction:  f you want mm\n",
      "1847 loss:  1.34935 Prediction:  f you want mm\n",
      "1848 loss:  1.34925 Prediction:  f you want mm\n",
      "1849 loss:  1.34915 Prediction:  f you want mm\n",
      "1850 loss:  1.34906 Prediction:  f you want mm\n",
      "1851 loss:  1.34896 Prediction:  f you want mm\n",
      "1852 loss:  1.34886 Prediction:  f you want mm\n",
      "1853 loss:  1.34876 Prediction:  f you want mm\n",
      "1854 loss:  1.34866 Prediction:  f you want mm\n",
      "1855 loss:  1.34856 Prediction:  f you want mm\n",
      "1856 loss:  1.34846 Prediction:  f you want mm\n",
      "1857 loss:  1.34836 Prediction:  f you want mm\n",
      "1858 loss:  1.34827 Prediction:  f you want mm\n",
      "1859 loss:  1.34817 Prediction:  f you want mm\n",
      "1860 loss:  1.34807 Prediction:  f you want mm\n",
      "1861 loss:  1.34797 Prediction:  f you want mm\n",
      "1862 loss:  1.34788 Prediction:  f you want mm\n",
      "1863 loss:  1.34778 Prediction:  f you want mm\n",
      "1864 loss:  1.34768 Prediction:  f you want mm\n",
      "1865 loss:  1.34758 Prediction:  f you want mm\n",
      "1866 loss:  1.34749 Prediction:  f you want mm\n",
      "1867 loss:  1.34739 Prediction:  f you want mm\n",
      "1868 loss:  1.34729 Prediction:  f you want mm\n",
      "1869 loss:  1.3472 Prediction:  f you want mm\n",
      "1870 loss:  1.3471 Prediction:  f you want mm\n",
      "1871 loss:  1.347 Prediction:  f you want mm\n",
      "1872 loss:  1.34691 Prediction:  f you want mm\n",
      "1873 loss:  1.34681 Prediction:  f you want mm\n",
      "1874 loss:  1.34672 Prediction:  f you want mm\n",
      "1875 loss:  1.34662 Prediction:  f you want mm\n",
      "1876 loss:  1.34652 Prediction:  f you want mm\n",
      "1877 loss:  1.34643 Prediction:  f you want mm\n",
      "1878 loss:  1.34633 Prediction:  f you want mm\n",
      "1879 loss:  1.34624 Prediction:  f you want mm\n",
      "1880 loss:  1.34614 Prediction:  f you want mm\n",
      "1881 loss:  1.34605 Prediction:  f you want mm\n",
      "1882 loss:  1.34595 Prediction:  f you want mm\n",
      "1883 loss:  1.34586 Prediction:  f you want mm\n",
      "1884 loss:  1.34576 Prediction:  f you want mm\n",
      "1885 loss:  1.34567 Prediction:  f you want mm\n",
      "1886 loss:  1.34557 Prediction:  f you want mm\n",
      "1887 loss:  1.34548 Prediction:  f you want mm\n",
      "1888 loss:  1.34539 Prediction:  f you want mm\n",
      "1889 loss:  1.34529 Prediction:  f you want mm\n",
      "1890 loss:  1.3452 Prediction:  f you want mm\n",
      "1891 loss:  1.3451 Prediction:  f you want mm\n",
      "1892 loss:  1.34501 Prediction:  f you want mm\n",
      "1893 loss:  1.34492 Prediction:  f you want mm\n",
      "1894 loss:  1.34482 Prediction:  f you want mm\n",
      "1895 loss:  1.34473 Prediction:  f you want mm\n",
      "1896 loss:  1.34464 Prediction:  f you want mm\n",
      "1897 loss:  1.34454 Prediction:  f you want mm\n",
      "1898 loss:  1.34445 Prediction:  f you want mm\n",
      "1899 loss:  1.34436 Prediction:  f you want mm\n",
      "1900 loss:  1.34427 Prediction:  f you want mm\n",
      "1901 loss:  1.34417 Prediction:  f you want mm\n",
      "1902 loss:  1.34408 Prediction:  f you want mm\n",
      "1903 loss:  1.34399 Prediction:  f you want mm\n",
      "1904 loss:  1.3439 Prediction:  f you want mm\n",
      "1905 loss:  1.34381 Prediction:  f you want mm\n",
      "1906 loss:  1.34371 Prediction:  f you want mm\n",
      "1907 loss:  1.34362 Prediction:  f you want mm\n",
      "1908 loss:  1.34353 Prediction:  f you want mm\n",
      "1909 loss:  1.34344 Prediction:  f you want mm\n",
      "1910 loss:  1.34335 Prediction:  f you want mm\n",
      "1911 loss:  1.34326 Prediction:  f you want mm\n",
      "1912 loss:  1.34317 Prediction:  f you want mm\n",
      "1913 loss:  1.34308 Prediction:  f you want mm\n",
      "1914 loss:  1.34298 Prediction:  f you want mm\n",
      "1915 loss:  1.34289 Prediction:  f you want mm\n",
      "1916 loss:  1.3428 Prediction:  f you want mm\n",
      "1917 loss:  1.34271 Prediction:  f you want mm\n",
      "1918 loss:  1.34262 Prediction:  f you want mm\n",
      "1919 loss:  1.34253 Prediction:  f you want mm\n",
      "1920 loss:  1.34244 Prediction:  f you want mm\n",
      "1921 loss:  1.34235 Prediction:  f you want mm\n",
      "1922 loss:  1.34226 Prediction:  f you want mm\n",
      "1923 loss:  1.34217 Prediction:  f you want mm\n",
      "1924 loss:  1.34208 Prediction:  f you want mm\n",
      "1925 loss:  1.34199 Prediction:  f you want mm\n",
      "1926 loss:  1.3419 Prediction:  f you want mm\n",
      "1927 loss:  1.34182 Prediction:  f you want mm\n",
      "1928 loss:  1.34173 Prediction:  f you want mm\n",
      "1929 loss:  1.34164 Prediction:  f you want mm\n",
      "1930 loss:  1.34155 Prediction:  f you want mm\n",
      "1931 loss:  1.34146 Prediction:  f you want mm\n",
      "1932 loss:  1.34137 Prediction:  f you want mm\n",
      "1933 loss:  1.34128 Prediction:  f you want mm\n",
      "1934 loss:  1.34119 Prediction:  f you want mm\n",
      "1935 loss:  1.34111 Prediction:  f you want mm\n",
      "1936 loss:  1.34102 Prediction:  f you want mm\n",
      "1937 loss:  1.34093 Prediction:  f you want mm\n",
      "1938 loss:  1.34084 Prediction:  f you want mm\n",
      "1939 loss:  1.34075 Prediction:  f you want mm\n",
      "1940 loss:  1.34067 Prediction:  f you want mm\n",
      "1941 loss:  1.34058 Prediction:  f you want mm\n",
      "1942 loss:  1.34049 Prediction:  f you want mm\n",
      "1943 loss:  1.3404 Prediction:  f you want mm\n",
      "1944 loss:  1.34032 Prediction:  f you want mm\n",
      "1945 loss:  1.34023 Prediction:  f you want mm\n",
      "1946 loss:  1.34014 Prediction:  f you want mm\n",
      "1947 loss:  1.34006 Prediction:  f you want mm\n",
      "1948 loss:  1.33997 Prediction:  f you want mm\n",
      "1949 loss:  1.33988 Prediction:  f you want mm\n",
      "1950 loss:  1.3398 Prediction:  f you want mm\n",
      "1951 loss:  1.33971 Prediction:  f you want mm\n",
      "1952 loss:  1.33962 Prediction:  f you want mm\n",
      "1953 loss:  1.33954 Prediction:  f you want mm\n",
      "1954 loss:  1.33945 Prediction:  f you want mm\n",
      "1955 loss:  1.33937 Prediction:  f you want mm\n",
      "1956 loss:  1.33928 Prediction:  f you want mm\n",
      "1957 loss:  1.3392 Prediction:  f you want mm\n",
      "1958 loss:  1.33911 Prediction:  f you want mm\n",
      "1959 loss:  1.33902 Prediction:  f you want mm\n",
      "1960 loss:  1.33894 Prediction:  f you want mm\n",
      "1961 loss:  1.33885 Prediction:  f you want mm\n",
      "1962 loss:  1.33877 Prediction:  f you want mm\n",
      "1963 loss:  1.33868 Prediction:  f you want mm\n",
      "1964 loss:  1.3386 Prediction:  f you want mm\n",
      "1965 loss:  1.33851 Prediction:  f you want mm\n",
      "1966 loss:  1.33843 Prediction:  f you want mm\n",
      "1967 loss:  1.33835 Prediction:  f you want mm\n",
      "1968 loss:  1.33826 Prediction:  f you want mm\n",
      "1969 loss:  1.33818 Prediction:  f you want mm\n",
      "1970 loss:  1.33809 Prediction:  f you want mm\n",
      "1971 loss:  1.33801 Prediction:  f you want mm\n",
      "1972 loss:  1.33792 Prediction:  f you want mm\n",
      "1973 loss:  1.33784 Prediction:  f you want mm\n",
      "1974 loss:  1.33776 Prediction:  f you want mm\n",
      "1975 loss:  1.33767 Prediction:  f you want mm\n",
      "1976 loss:  1.33759 Prediction:  f you want mm\n",
      "1977 loss:  1.33751 Prediction:  f you want mm\n",
      "1978 loss:  1.33742 Prediction:  f you want mm\n",
      "1979 loss:  1.33734 Prediction:  f you want mm\n",
      "1980 loss:  1.33726 Prediction:  f you want mm\n",
      "1981 loss:  1.33717 Prediction:  f you want mm\n",
      "1982 loss:  1.33709 Prediction:  f you want mm\n",
      "1983 loss:  1.33701 Prediction:  f you want mm\n",
      "1984 loss:  1.33693 Prediction:  f you want mm\n",
      "1985 loss:  1.33684 Prediction:  f you want mm\n",
      "1986 loss:  1.33676 Prediction:  f you want mm\n",
      "1987 loss:  1.33668 Prediction:  f you want mm\n",
      "1988 loss:  1.3366 Prediction:  f you want mm\n",
      "1989 loss:  1.33651 Prediction:  f you want mm\n",
      "1990 loss:  1.33643 Prediction:  f you want mm\n",
      "1991 loss:  1.33635 Prediction:  f you want mm\n",
      "1992 loss:  1.33627 Prediction:  f you want mm\n",
      "1993 loss:  1.33619 Prediction:  f you want mm\n",
      "1994 loss:  1.3361 Prediction:  f you want mm\n",
      "1995 loss:  1.33602 Prediction:  f you want mm\n",
      "1996 loss:  1.33594 Prediction:  f you want mm\n",
      "1997 loss:  1.33586 Prediction:  f you want mm\n",
      "1998 loss:  1.33578 Prediction:  f you want mm\n",
      "1999 loss:  1.3357 Prediction:  f you want mm\n",
      "2000 loss:  1.33562 Prediction:  f you want mm\n",
      "2001 loss:  1.33554 Prediction:  f you want mm\n",
      "2002 loss:  1.33546 Prediction:  f you want mm\n",
      "2003 loss:  1.33538 Prediction:  f you want mm\n",
      "2004 loss:  1.33529 Prediction:  f you want mm\n",
      "2005 loss:  1.33521 Prediction:  f you want mm\n",
      "2006 loss:  1.33513 Prediction:  f you want mm\n",
      "2007 loss:  1.33505 Prediction:  f you want mm\n",
      "2008 loss:  1.33497 Prediction:  f you want mm\n",
      "2009 loss:  1.33489 Prediction:  f you want mm\n",
      "2010 loss:  1.33481 Prediction:  f you want mm\n",
      "2011 loss:  1.33473 Prediction:  f you want mm\n",
      "2012 loss:  1.33465 Prediction:  f you want mm\n",
      "2013 loss:  1.33457 Prediction:  f you want mm\n",
      "2014 loss:  1.3345 Prediction:  f you want mm\n",
      "2015 loss:  1.33442 Prediction:  f you want mm\n",
      "2016 loss:  1.33434 Prediction:  f you want mm\n",
      "2017 loss:  1.33426 Prediction:  f you want mm\n",
      "2018 loss:  1.33418 Prediction:  f you want mm\n",
      "2019 loss:  1.3341 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 loss:  1.33402 Prediction:  f you want mm\n",
      "2021 loss:  1.33394 Prediction:  f you want mm\n",
      "2022 loss:  1.33386 Prediction:  f you want mm\n",
      "2023 loss:  1.33378 Prediction:  f you want mm\n",
      "2024 loss:  1.33371 Prediction:  f you want mm\n",
      "2025 loss:  1.33363 Prediction:  f you want mm\n",
      "2026 loss:  1.33355 Prediction:  f you want mm\n",
      "2027 loss:  1.33347 Prediction:  f you want mm\n",
      "2028 loss:  1.33339 Prediction:  f you want mm\n",
      "2029 loss:  1.33332 Prediction:  f you want mm\n",
      "2030 loss:  1.33324 Prediction:  f you want mm\n",
      "2031 loss:  1.33316 Prediction:  f you want mm\n",
      "2032 loss:  1.33308 Prediction:  f you want mm\n",
      "2033 loss:  1.333 Prediction:  f you want mm\n",
      "2034 loss:  1.33293 Prediction:  f you want mm\n",
      "2035 loss:  1.33285 Prediction:  f you want mm\n",
      "2036 loss:  1.33277 Prediction:  f you want mm\n",
      "2037 loss:  1.33269 Prediction:  f you want mm\n",
      "2038 loss:  1.33262 Prediction:  f you want mm\n",
      "2039 loss:  1.33254 Prediction:  f you want mm\n",
      "2040 loss:  1.33246 Prediction:  f you want mm\n",
      "2041 loss:  1.33239 Prediction:  f you want mm\n",
      "2042 loss:  1.33231 Prediction:  f you want mm\n",
      "2043 loss:  1.33223 Prediction:  f you want mm\n",
      "2044 loss:  1.33216 Prediction:  f you want mm\n",
      "2045 loss:  1.33208 Prediction:  f you want mm\n",
      "2046 loss:  1.332 Prediction:  f you want mm\n",
      "2047 loss:  1.33193 Prediction:  f you want mm\n",
      "2048 loss:  1.33185 Prediction:  f you want mm\n",
      "2049 loss:  1.33178 Prediction:  f you want mm\n",
      "2050 loss:  1.3317 Prediction:  f you want mm\n",
      "2051 loss:  1.33162 Prediction:  f you want mm\n",
      "2052 loss:  1.33155 Prediction:  f you want mm\n",
      "2053 loss:  1.33147 Prediction:  f you want mm\n",
      "2054 loss:  1.3314 Prediction:  f you want mm\n",
      "2055 loss:  1.33132 Prediction:  f you want mm\n",
      "2056 loss:  1.33125 Prediction:  f you want mm\n",
      "2057 loss:  1.33117 Prediction:  f you want mm\n",
      "2058 loss:  1.3311 Prediction:  f you want mm\n",
      "2059 loss:  1.33102 Prediction:  f you want mm\n",
      "2060 loss:  1.33095 Prediction:  f you want mm\n",
      "2061 loss:  1.33087 Prediction:  f you want mm\n",
      "2062 loss:  1.3308 Prediction:  f you want mm\n",
      "2063 loss:  1.33072 Prediction:  f you want mm\n",
      "2064 loss:  1.33065 Prediction:  f you want mm\n",
      "2065 loss:  1.33057 Prediction:  f you want mm\n",
      "2066 loss:  1.3305 Prediction:  f you want mm\n",
      "2067 loss:  1.33042 Prediction:  f you want mm\n",
      "2068 loss:  1.33035 Prediction:  f you want mm\n",
      "2069 loss:  1.33028 Prediction:  f you want mm\n",
      "2070 loss:  1.3302 Prediction:  f you want mm\n",
      "2071 loss:  1.33013 Prediction:  f you want mm\n",
      "2072 loss:  1.33005 Prediction:  f you want mm\n",
      "2073 loss:  1.32998 Prediction:  f you want mm\n",
      "2074 loss:  1.32991 Prediction:  f you want mm\n",
      "2075 loss:  1.32983 Prediction:  f you want mm\n",
      "2076 loss:  1.32976 Prediction:  f you want mm\n",
      "2077 loss:  1.32969 Prediction:  f you want mm\n",
      "2078 loss:  1.32961 Prediction:  f you want mm\n",
      "2079 loss:  1.32954 Prediction:  f you want mm\n",
      "2080 loss:  1.32947 Prediction:  f you want mm\n",
      "2081 loss:  1.32939 Prediction:  f you want mm\n",
      "2082 loss:  1.32932 Prediction:  f you want mm\n",
      "2083 loss:  1.32925 Prediction:  f you want mm\n",
      "2084 loss:  1.32917 Prediction:  f you want mm\n",
      "2085 loss:  1.3291 Prediction:  f you want mm\n",
      "2086 loss:  1.32903 Prediction:  f you want mm\n",
      "2087 loss:  1.32896 Prediction:  f you want mm\n",
      "2088 loss:  1.32888 Prediction:  f you want mm\n",
      "2089 loss:  1.32881 Prediction:  f you want mm\n",
      "2090 loss:  1.32874 Prediction:  f you want mm\n",
      "2091 loss:  1.32867 Prediction:  f you want mm\n",
      "2092 loss:  1.3286 Prediction:  f you want mm\n",
      "2093 loss:  1.32852 Prediction:  f you want mm\n",
      "2094 loss:  1.32845 Prediction:  f you want mm\n",
      "2095 loss:  1.32838 Prediction:  f you want mm\n",
      "2096 loss:  1.32831 Prediction:  f you want mm\n",
      "2097 loss:  1.32824 Prediction:  f you want mm\n",
      "2098 loss:  1.32817 Prediction:  f you want mm\n",
      "2099 loss:  1.32809 Prediction:  f you want mm\n",
      "2100 loss:  1.32802 Prediction:  f you want mm\n",
      "2101 loss:  1.32795 Prediction:  f you want mm\n",
      "2102 loss:  1.32788 Prediction:  f you want mm\n",
      "2103 loss:  1.32781 Prediction:  f you want mm\n",
      "2104 loss:  1.32774 Prediction:  f you want mm\n",
      "2105 loss:  1.32767 Prediction:  f you want mm\n",
      "2106 loss:  1.3276 Prediction:  f you want mm\n",
      "2107 loss:  1.32753 Prediction:  f you want mm\n",
      "2108 loss:  1.32745 Prediction:  f you want mm\n",
      "2109 loss:  1.32738 Prediction:  f you want mm\n",
      "2110 loss:  1.32731 Prediction:  f you want mm\n",
      "2111 loss:  1.32724 Prediction:  f you want mm\n",
      "2112 loss:  1.32717 Prediction:  f you want mm\n",
      "2113 loss:  1.3271 Prediction:  f you want mm\n",
      "2114 loss:  1.32703 Prediction:  f you want mm\n",
      "2115 loss:  1.32696 Prediction:  f you want mm\n",
      "2116 loss:  1.32689 Prediction:  f you want mm\n",
      "2117 loss:  1.32682 Prediction:  f you want mm\n",
      "2118 loss:  1.32675 Prediction:  f you want mm\n",
      "2119 loss:  1.32668 Prediction:  f you want mm\n",
      "2120 loss:  1.32661 Prediction:  f you want mm\n",
      "2121 loss:  1.32654 Prediction:  f you want mm\n",
      "2122 loss:  1.32647 Prediction:  f you want mm\n",
      "2123 loss:  1.3264 Prediction:  f you want mm\n",
      "2124 loss:  1.32634 Prediction:  f you want mm\n",
      "2125 loss:  1.32627 Prediction:  f you want mm\n",
      "2126 loss:  1.3262 Prediction:  f you want mm\n",
      "2127 loss:  1.32613 Prediction:  f you want mm\n",
      "2128 loss:  1.32606 Prediction:  f you want mm\n",
      "2129 loss:  1.32599 Prediction:  f you want mm\n",
      "2130 loss:  1.32592 Prediction:  f you want mm\n",
      "2131 loss:  1.32585 Prediction:  f you want mm\n",
      "2132 loss:  1.32578 Prediction:  f you want mm\n",
      "2133 loss:  1.32572 Prediction:  f you want mm\n",
      "2134 loss:  1.32565 Prediction:  f you want mm\n",
      "2135 loss:  1.32558 Prediction:  f you want mm\n",
      "2136 loss:  1.32551 Prediction:  f you want mm\n",
      "2137 loss:  1.32544 Prediction:  f you want mm\n",
      "2138 loss:  1.32537 Prediction:  f you want mm\n",
      "2139 loss:  1.32531 Prediction:  f you want mm\n",
      "2140 loss:  1.32524 Prediction:  f you want mm\n",
      "2141 loss:  1.32517 Prediction:  f you want mm\n",
      "2142 loss:  1.3251 Prediction:  f you want mm\n",
      "2143 loss:  1.32503 Prediction:  f you want mm\n",
      "2144 loss:  1.32497 Prediction:  f you want mm\n",
      "2145 loss:  1.3249 Prediction:  f you want mm\n",
      "2146 loss:  1.32483 Prediction:  f you want mm\n",
      "2147 loss:  1.32476 Prediction:  f you want mm\n",
      "2148 loss:  1.3247 Prediction:  f you want mm\n",
      "2149 loss:  1.32463 Prediction:  f you want mm\n",
      "2150 loss:  1.32456 Prediction:  f you want mm\n",
      "2151 loss:  1.32449 Prediction:  f you want mm\n",
      "2152 loss:  1.32443 Prediction:  f you want mm\n",
      "2153 loss:  1.32436 Prediction:  f you want mm\n",
      "2154 loss:  1.32429 Prediction:  f you want mm\n",
      "2155 loss:  1.32423 Prediction:  f you want mm\n",
      "2156 loss:  1.32416 Prediction:  f you want mm\n",
      "2157 loss:  1.32409 Prediction:  f you want mm\n",
      "2158 loss:  1.32403 Prediction:  f you want mm\n",
      "2159 loss:  1.32396 Prediction:  f you want mm\n",
      "2160 loss:  1.32389 Prediction:  f you want mm\n",
      "2161 loss:  1.32383 Prediction:  f you want mm\n",
      "2162 loss:  1.32376 Prediction:  f you want mm\n",
      "2163 loss:  1.3237 Prediction:  f you want mm\n",
      "2164 loss:  1.32363 Prediction:  f you want mm\n",
      "2165 loss:  1.32356 Prediction:  f you want mm\n",
      "2166 loss:  1.3235 Prediction:  f you want mm\n",
      "2167 loss:  1.32343 Prediction:  f you want mm\n",
      "2168 loss:  1.32337 Prediction:  f you want mm\n",
      "2169 loss:  1.3233 Prediction:  f you want mm\n",
      "2170 loss:  1.32323 Prediction:  f you want mm\n",
      "2171 loss:  1.32317 Prediction:  f you want mm\n",
      "2172 loss:  1.3231 Prediction:  f you want mm\n",
      "2173 loss:  1.32304 Prediction:  f you want mm\n",
      "2174 loss:  1.32297 Prediction:  f you want mm\n",
      "2175 loss:  1.32291 Prediction:  f you want mm\n",
      "2176 loss:  1.32284 Prediction:  f you want mm\n",
      "2177 loss:  1.32278 Prediction:  f you want mm\n",
      "2178 loss:  1.32271 Prediction:  f you want mm\n",
      "2179 loss:  1.32265 Prediction:  f you want mm\n",
      "2180 loss:  1.32258 Prediction:  f you want mm\n",
      "2181 loss:  1.32252 Prediction:  f you want mm\n",
      "2182 loss:  1.32245 Prediction:  f you want mm\n",
      "2183 loss:  1.32239 Prediction:  f you want mm\n",
      "2184 loss:  1.32232 Prediction:  f you want mm\n",
      "2185 loss:  1.32226 Prediction:  f you want mm\n",
      "2186 loss:  1.32219 Prediction:  f you want mm\n",
      "2187 loss:  1.32213 Prediction:  f you want mm\n",
      "2188 loss:  1.32207 Prediction:  f you want mm\n",
      "2189 loss:  1.322 Prediction:  f you want mm\n",
      "2190 loss:  1.32194 Prediction:  f you want mm\n",
      "2191 loss:  1.32187 Prediction:  f you want mm\n",
      "2192 loss:  1.32181 Prediction:  f you want mm\n",
      "2193 loss:  1.32175 Prediction:  f you want mm\n",
      "2194 loss:  1.32168 Prediction:  f you want mm\n",
      "2195 loss:  1.32162 Prediction:  f you want mm\n",
      "2196 loss:  1.32155 Prediction:  f you want mm\n",
      "2197 loss:  1.32149 Prediction:  f you want mm\n",
      "2198 loss:  1.32143 Prediction:  f you want mm\n",
      "2199 loss:  1.32136 Prediction:  f you want mm\n",
      "2200 loss:  1.3213 Prediction:  f you want mm\n",
      "2201 loss:  1.32124 Prediction:  f you want mm\n",
      "2202 loss:  1.32117 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2203 loss:  1.32111 Prediction:  f you want mm\n",
      "2204 loss:  1.32105 Prediction:  f you want mm\n",
      "2205 loss:  1.32098 Prediction:  f you want mm\n",
      "2206 loss:  1.32092 Prediction:  f you want mm\n",
      "2207 loss:  1.32086 Prediction:  f you want mm\n",
      "2208 loss:  1.3208 Prediction:  f you want mm\n",
      "2209 loss:  1.32073 Prediction:  f you want mm\n",
      "2210 loss:  1.32067 Prediction:  f you want mm\n",
      "2211 loss:  1.32061 Prediction:  f you want mm\n",
      "2212 loss:  1.32055 Prediction:  f you want mm\n",
      "2213 loss:  1.32048 Prediction:  f you want mm\n",
      "2214 loss:  1.32042 Prediction:  f you want mm\n",
      "2215 loss:  1.32036 Prediction:  f you want mm\n",
      "2216 loss:  1.3203 Prediction:  f you want mm\n",
      "2217 loss:  1.32023 Prediction:  f you want mm\n",
      "2218 loss:  1.32017 Prediction:  f you want mm\n",
      "2219 loss:  1.32011 Prediction:  f you want mm\n",
      "2220 loss:  1.32005 Prediction:  f you want mm\n",
      "2221 loss:  1.31999 Prediction:  f you want mm\n",
      "2222 loss:  1.31992 Prediction:  f you want mm\n",
      "2223 loss:  1.31986 Prediction:  f you want mm\n",
      "2224 loss:  1.3198 Prediction:  f you want mm\n",
      "2225 loss:  1.31974 Prediction:  f you want mm\n",
      "2226 loss:  1.31968 Prediction:  f you want mm\n",
      "2227 loss:  1.31962 Prediction:  f you want mm\n",
      "2228 loss:  1.31955 Prediction:  f you want mm\n",
      "2229 loss:  1.31949 Prediction:  f you want mm\n",
      "2230 loss:  1.31943 Prediction:  f you want mm\n",
      "2231 loss:  1.31937 Prediction:  f you want mm\n",
      "2232 loss:  1.31931 Prediction:  f you want mm\n",
      "2233 loss:  1.31925 Prediction:  f you want mm\n",
      "2234 loss:  1.31919 Prediction:  f you want mm\n",
      "2235 loss:  1.31913 Prediction:  f you want mm\n",
      "2236 loss:  1.31907 Prediction:  f you want mm\n",
      "2237 loss:  1.31901 Prediction:  f you want mm\n",
      "2238 loss:  1.31894 Prediction:  f you want mm\n",
      "2239 loss:  1.31888 Prediction:  f you want mm\n",
      "2240 loss:  1.31882 Prediction:  f you want mm\n",
      "2241 loss:  1.31876 Prediction:  f you want mm\n",
      "2242 loss:  1.3187 Prediction:  f you want mm\n",
      "2243 loss:  1.31864 Prediction:  f you want mm\n",
      "2244 loss:  1.31858 Prediction:  f you want mm\n",
      "2245 loss:  1.31852 Prediction:  f you want mm\n",
      "2246 loss:  1.31846 Prediction:  f you want mm\n",
      "2247 loss:  1.3184 Prediction:  f you want mm\n",
      "2248 loss:  1.31834 Prediction:  f you want mm\n",
      "2249 loss:  1.31828 Prediction:  f you want mm\n",
      "2250 loss:  1.31822 Prediction:  f you want mm\n",
      "2251 loss:  1.31816 Prediction:  f you want mm\n",
      "2252 loss:  1.3181 Prediction:  f you want mm\n",
      "2253 loss:  1.31804 Prediction:  f you want mm\n",
      "2254 loss:  1.31798 Prediction:  f you want mm\n",
      "2255 loss:  1.31792 Prediction:  f you want mm\n",
      "2256 loss:  1.31786 Prediction:  f you want mm\n",
      "2257 loss:  1.3178 Prediction:  f you want mm\n",
      "2258 loss:  1.31774 Prediction:  f you want mm\n",
      "2259 loss:  1.31768 Prediction:  f you want mm\n",
      "2260 loss:  1.31763 Prediction:  f you want mm\n",
      "2261 loss:  1.31757 Prediction:  f you want mm\n",
      "2262 loss:  1.31751 Prediction:  f you want mm\n",
      "2263 loss:  1.31745 Prediction:  f you want mm\n",
      "2264 loss:  1.31739 Prediction:  f you want mm\n",
      "2265 loss:  1.31733 Prediction:  f you want mm\n",
      "2266 loss:  1.31727 Prediction:  f you want mm\n",
      "2267 loss:  1.31721 Prediction:  f you want mm\n",
      "2268 loss:  1.31715 Prediction:  f you want mm\n",
      "2269 loss:  1.3171 Prediction:  f you want mm\n",
      "2270 loss:  1.31704 Prediction:  f you want mm\n",
      "2271 loss:  1.31698 Prediction:  f you want mm\n",
      "2272 loss:  1.31692 Prediction:  f you want mm\n",
      "2273 loss:  1.31686 Prediction:  f you want mm\n",
      "2274 loss:  1.3168 Prediction:  f you want mm\n",
      "2275 loss:  1.31674 Prediction:  f you want mm\n",
      "2276 loss:  1.31669 Prediction:  f you want mm\n",
      "2277 loss:  1.31663 Prediction:  f you want mm\n",
      "2278 loss:  1.31657 Prediction:  f you want mm\n",
      "2279 loss:  1.31651 Prediction:  f you want mm\n",
      "2280 loss:  1.31645 Prediction:  f you want mm\n",
      "2281 loss:  1.3164 Prediction:  f you want mm\n",
      "2282 loss:  1.31634 Prediction:  f you want mm\n",
      "2283 loss:  1.31628 Prediction:  f you want mm\n",
      "2284 loss:  1.31622 Prediction:  f you want mm\n",
      "2285 loss:  1.31617 Prediction:  f you want mm\n",
      "2286 loss:  1.31611 Prediction:  f you want mm\n",
      "2287 loss:  1.31605 Prediction:  f you want mm\n",
      "2288 loss:  1.31599 Prediction:  f you want mm\n",
      "2289 loss:  1.31594 Prediction:  f you want mm\n",
      "2290 loss:  1.31588 Prediction:  f you want mm\n",
      "2291 loss:  1.31582 Prediction:  f you want mm\n",
      "2292 loss:  1.31576 Prediction:  f you want mm\n",
      "2293 loss:  1.31571 Prediction:  f you want mm\n",
      "2294 loss:  1.31565 Prediction:  f you want mm\n",
      "2295 loss:  1.31559 Prediction:  f you want mm\n",
      "2296 loss:  1.31554 Prediction:  f you want mm\n",
      "2297 loss:  1.31548 Prediction:  f you want mm\n",
      "2298 loss:  1.31542 Prediction:  f you want mm\n",
      "2299 loss:  1.31536 Prediction:  f you want mm\n",
      "2300 loss:  1.31531 Prediction:  f you want mm\n",
      "2301 loss:  1.31525 Prediction:  f you want mm\n",
      "2302 loss:  1.31519 Prediction:  f you want mm\n",
      "2303 loss:  1.31514 Prediction:  f you want mm\n",
      "2304 loss:  1.31508 Prediction:  f you want mm\n",
      "2305 loss:  1.31503 Prediction:  f you want mm\n",
      "2306 loss:  1.31497 Prediction:  f you want mm\n",
      "2307 loss:  1.31491 Prediction:  f you want mm\n",
      "2308 loss:  1.31486 Prediction:  f you want mm\n",
      "2309 loss:  1.3148 Prediction:  f you want mm\n",
      "2310 loss:  1.31474 Prediction:  f you want mm\n",
      "2311 loss:  1.31469 Prediction:  f you want mm\n",
      "2312 loss:  1.31463 Prediction:  f you want mm\n",
      "2313 loss:  1.31458 Prediction:  f you want mm\n",
      "2314 loss:  1.31452 Prediction:  f you want mm\n",
      "2315 loss:  1.31446 Prediction:  f you want mm\n",
      "2316 loss:  1.31441 Prediction:  f you want mm\n",
      "2317 loss:  1.31435 Prediction:  f you want mm\n",
      "2318 loss:  1.3143 Prediction:  f you want mm\n",
      "2319 loss:  1.31424 Prediction:  f you want mm\n",
      "2320 loss:  1.31419 Prediction:  f you want mm\n",
      "2321 loss:  1.31413 Prediction:  f you want mm\n",
      "2322 loss:  1.31408 Prediction:  f you want mm\n",
      "2323 loss:  1.31402 Prediction:  f you want mm\n",
      "2324 loss:  1.31396 Prediction:  f you want mm\n",
      "2325 loss:  1.31391 Prediction:  f you want mm\n",
      "2326 loss:  1.31385 Prediction:  f you want mm\n",
      "2327 loss:  1.3138 Prediction:  f you want mm\n",
      "2328 loss:  1.31374 Prediction:  f you want mm\n",
      "2329 loss:  1.31369 Prediction:  f you want mm\n",
      "2330 loss:  1.31363 Prediction:  f you want mm\n",
      "2331 loss:  1.31358 Prediction:  f you want mm\n",
      "2332 loss:  1.31352 Prediction:  f you want mm\n",
      "2333 loss:  1.31347 Prediction:  f you want mm\n",
      "2334 loss:  1.31342 Prediction:  f you want mm\n",
      "2335 loss:  1.31336 Prediction:  f you want mm\n",
      "2336 loss:  1.31331 Prediction:  f you want mm\n",
      "2337 loss:  1.31325 Prediction:  f you want mm\n",
      "2338 loss:  1.3132 Prediction:  f you want mm\n",
      "2339 loss:  1.31314 Prediction:  f you want mm\n",
      "2340 loss:  1.31309 Prediction:  f you want mm\n",
      "2341 loss:  1.31303 Prediction:  f you want mm\n",
      "2342 loss:  1.31298 Prediction:  f you want mm\n",
      "2343 loss:  1.31293 Prediction:  f you want mm\n",
      "2344 loss:  1.31287 Prediction:  f you want mm\n",
      "2345 loss:  1.31282 Prediction:  f you want mm\n",
      "2346 loss:  1.31276 Prediction:  f you want mm\n",
      "2347 loss:  1.31271 Prediction:  f you want mm\n",
      "2348 loss:  1.31266 Prediction:  f you want mm\n",
      "2349 loss:  1.3126 Prediction:  f you want mm\n",
      "2350 loss:  1.31255 Prediction:  f you want mm\n",
      "2351 loss:  1.31249 Prediction:  f you want mm\n",
      "2352 loss:  1.31244 Prediction:  f you want mm\n",
      "2353 loss:  1.31239 Prediction:  f you want mm\n",
      "2354 loss:  1.31233 Prediction:  f you want mm\n",
      "2355 loss:  1.31228 Prediction:  f you want mm\n",
      "2356 loss:  1.31223 Prediction:  f you want mm\n",
      "2357 loss:  1.31217 Prediction:  f you want mm\n",
      "2358 loss:  1.31212 Prediction:  f you want mm\n",
      "2359 loss:  1.31207 Prediction:  f you want mm\n",
      "2360 loss:  1.31201 Prediction:  f you want mm\n",
      "2361 loss:  1.31196 Prediction:  f you want mm\n",
      "2362 loss:  1.31191 Prediction:  f you want mm\n",
      "2363 loss:  1.31185 Prediction:  f you want mm\n",
      "2364 loss:  1.3118 Prediction:  f you want mm\n",
      "2365 loss:  1.31175 Prediction:  f you want mm\n",
      "2366 loss:  1.31169 Prediction:  f you want mm\n",
      "2367 loss:  1.31164 Prediction:  f you want mm\n",
      "2368 loss:  1.31159 Prediction:  f you want mm\n",
      "2369 loss:  1.31154 Prediction:  f you want mm\n",
      "2370 loss:  1.31148 Prediction:  f you want mm\n",
      "2371 loss:  1.31143 Prediction:  f you want mm\n",
      "2372 loss:  1.31138 Prediction:  f you want mm\n",
      "2373 loss:  1.31133 Prediction:  f you want mm\n",
      "2374 loss:  1.31127 Prediction:  f you want mm\n",
      "2375 loss:  1.31122 Prediction:  f you want mm\n",
      "2376 loss:  1.31117 Prediction:  f you want mm\n",
      "2377 loss:  1.31112 Prediction:  f you want mm\n",
      "2378 loss:  1.31106 Prediction:  f you want mm\n",
      "2379 loss:  1.31101 Prediction:  f you want mm\n",
      "2380 loss:  1.31096 Prediction:  f you want mm\n",
      "2381 loss:  1.31091 Prediction:  f you want mm\n",
      "2382 loss:  1.31086 Prediction:  f you want mm\n",
      "2383 loss:  1.3108 Prediction:  f you want mm\n",
      "2384 loss:  1.31075 Prediction:  f you want mm\n",
      "2385 loss:  1.3107 Prediction:  f you want mm\n",
      "2386 loss:  1.31065 Prediction:  f you want mm\n",
      "2387 loss:  1.3106 Prediction:  f you want mm\n",
      "2388 loss:  1.31054 Prediction:  f you want mm\n",
      "2389 loss:  1.31049 Prediction:  f you want mm\n",
      "2390 loss:  1.31044 Prediction:  f you want mm\n",
      "2391 loss:  1.31039 Prediction:  f you want mm\n",
      "2392 loss:  1.31034 Prediction:  f you want mm\n",
      "2393 loss:  1.31029 Prediction:  f you want mm\n",
      "2394 loss:  1.31023 Prediction:  f you want mm\n",
      "2395 loss:  1.31018 Prediction:  f you want mm\n",
      "2396 loss:  1.31013 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397 loss:  1.31008 Prediction:  f you want mm\n",
      "2398 loss:  1.31003 Prediction:  f you want mm\n",
      "2399 loss:  1.30998 Prediction:  f you want mm\n",
      "2400 loss:  1.30993 Prediction:  f you want mm\n",
      "2401 loss:  1.30988 Prediction:  f you want mm\n",
      "2402 loss:  1.30983 Prediction:  f you want mm\n",
      "2403 loss:  1.30977 Prediction:  f you want mm\n",
      "2404 loss:  1.30972 Prediction:  f you want mm\n",
      "2405 loss:  1.30967 Prediction:  f you want mm\n",
      "2406 loss:  1.30962 Prediction:  f you want mm\n",
      "2407 loss:  1.30957 Prediction:  f you want mm\n",
      "2408 loss:  1.30952 Prediction:  f you want mm\n",
      "2409 loss:  1.30947 Prediction:  f you want mm\n",
      "2410 loss:  1.30942 Prediction:  f you want mm\n",
      "2411 loss:  1.30937 Prediction:  f you want mm\n",
      "2412 loss:  1.30932 Prediction:  f you want mm\n",
      "2413 loss:  1.30927 Prediction:  f you want mm\n",
      "2414 loss:  1.30922 Prediction:  f you want mm\n",
      "2415 loss:  1.30917 Prediction:  f you want mm\n",
      "2416 loss:  1.30912 Prediction:  f you want mm\n",
      "2417 loss:  1.30907 Prediction:  f you want mm\n",
      "2418 loss:  1.30902 Prediction:  f you want mm\n",
      "2419 loss:  1.30897 Prediction:  f you want mm\n",
      "2420 loss:  1.30892 Prediction:  f you want mm\n",
      "2421 loss:  1.30887 Prediction:  f you want mm\n",
      "2422 loss:  1.30882 Prediction:  f you want mm\n",
      "2423 loss:  1.30877 Prediction:  f you want mm\n",
      "2424 loss:  1.30872 Prediction:  f you want mm\n",
      "2425 loss:  1.30867 Prediction:  f you want mm\n",
      "2426 loss:  1.30862 Prediction:  f you want mm\n",
      "2427 loss:  1.30857 Prediction:  f you want mm\n",
      "2428 loss:  1.30852 Prediction:  f you want mm\n",
      "2429 loss:  1.30847 Prediction:  f you want mm\n",
      "2430 loss:  1.30842 Prediction:  f you want mm\n",
      "2431 loss:  1.30837 Prediction:  f you want mm\n",
      "2432 loss:  1.30832 Prediction:  f you want mm\n",
      "2433 loss:  1.30827 Prediction:  f you want mm\n",
      "2434 loss:  1.30822 Prediction:  f you want mm\n",
      "2435 loss:  1.30817 Prediction:  f you want mm\n",
      "2436 loss:  1.30812 Prediction:  f you want mm\n",
      "2437 loss:  1.30807 Prediction:  f you want mm\n",
      "2438 loss:  1.30802 Prediction:  f you want mm\n",
      "2439 loss:  1.30797 Prediction:  f you want mm\n",
      "2440 loss:  1.30792 Prediction:  f you want mm\n",
      "2441 loss:  1.30788 Prediction:  f you want mm\n",
      "2442 loss:  1.30783 Prediction:  f you want mm\n",
      "2443 loss:  1.30778 Prediction:  f you want mm\n",
      "2444 loss:  1.30773 Prediction:  f you want mm\n",
      "2445 loss:  1.30768 Prediction:  f you want mm\n",
      "2446 loss:  1.30763 Prediction:  f you want mm\n",
      "2447 loss:  1.30758 Prediction:  f you want mm\n",
      "2448 loss:  1.30753 Prediction:  f you want mm\n",
      "2449 loss:  1.30749 Prediction:  f you want mm\n",
      "2450 loss:  1.30744 Prediction:  f you want mm\n",
      "2451 loss:  1.30739 Prediction:  f you want mm\n",
      "2452 loss:  1.30734 Prediction:  f you want mm\n",
      "2453 loss:  1.30729 Prediction:  f you want mm\n",
      "2454 loss:  1.30724 Prediction:  f you want mm\n",
      "2455 loss:  1.30719 Prediction:  f you want mm\n",
      "2456 loss:  1.30715 Prediction:  f you want mm\n",
      "2457 loss:  1.3071 Prediction:  f you want mm\n",
      "2458 loss:  1.30705 Prediction:  f you want mm\n",
      "2459 loss:  1.307 Prediction:  f you want mm\n",
      "2460 loss:  1.30695 Prediction:  f you want mm\n",
      "2461 loss:  1.3069 Prediction:  f you want mm\n",
      "2462 loss:  1.30686 Prediction:  f you want mm\n",
      "2463 loss:  1.30681 Prediction:  f you want mm\n",
      "2464 loss:  1.30676 Prediction:  f you want mm\n",
      "2465 loss:  1.30671 Prediction:  f you want mm\n",
      "2466 loss:  1.30666 Prediction:  f you want mm\n",
      "2467 loss:  1.30662 Prediction:  f you want mm\n",
      "2468 loss:  1.30657 Prediction:  f you want mm\n",
      "2469 loss:  1.30652 Prediction:  f you want mm\n",
      "2470 loss:  1.30647 Prediction:  f you want mm\n",
      "2471 loss:  1.30643 Prediction:  f you want mm\n",
      "2472 loss:  1.30638 Prediction:  f you want mm\n",
      "2473 loss:  1.30633 Prediction:  f you want mm\n",
      "2474 loss:  1.30628 Prediction:  f you want mm\n",
      "2475 loss:  1.30624 Prediction:  f you want mm\n",
      "2476 loss:  1.30619 Prediction:  f you want mm\n",
      "2477 loss:  1.30614 Prediction:  f you want mm\n",
      "2478 loss:  1.30609 Prediction:  f you want mm\n",
      "2479 loss:  1.30605 Prediction:  f you want mm\n",
      "2480 loss:  1.306 Prediction:  f you want mm\n",
      "2481 loss:  1.30595 Prediction:  f you want mm\n",
      "2482 loss:  1.3059 Prediction:  f you want mm\n",
      "2483 loss:  1.30586 Prediction:  f you want mm\n",
      "2484 loss:  1.30581 Prediction:  f you want mm\n",
      "2485 loss:  1.30576 Prediction:  f you want mm\n",
      "2486 loss:  1.30572 Prediction:  f you want mm\n",
      "2487 loss:  1.30567 Prediction:  f you want mm\n",
      "2488 loss:  1.30562 Prediction:  f you want mm\n",
      "2489 loss:  1.30558 Prediction:  f you want mm\n",
      "2490 loss:  1.30553 Prediction:  f you want mm\n",
      "2491 loss:  1.30548 Prediction:  f you want mm\n",
      "2492 loss:  1.30544 Prediction:  f you want mm\n",
      "2493 loss:  1.30539 Prediction:  f you want mm\n",
      "2494 loss:  1.30534 Prediction:  f you want mm\n",
      "2495 loss:  1.3053 Prediction:  f you want mm\n",
      "2496 loss:  1.30525 Prediction:  f you want mm\n",
      "2497 loss:  1.3052 Prediction:  f you want mm\n",
      "2498 loss:  1.30516 Prediction:  f you want mm\n",
      "2499 loss:  1.30511 Prediction:  f you want mm\n",
      "2500 loss:  1.30506 Prediction:  f you want mm\n",
      "2501 loss:  1.30502 Prediction:  f you want mm\n",
      "2502 loss:  1.30497 Prediction:  f you want mm\n",
      "2503 loss:  1.30493 Prediction:  f you want mm\n",
      "2504 loss:  1.30488 Prediction:  f you want mm\n",
      "2505 loss:  1.30483 Prediction:  f you want mm\n",
      "2506 loss:  1.30479 Prediction:  f you want mm\n",
      "2507 loss:  1.30474 Prediction:  f you want mm\n",
      "2508 loss:  1.30469 Prediction:  f you want mm\n",
      "2509 loss:  1.30465 Prediction:  f you want mm\n",
      "2510 loss:  1.3046 Prediction:  f you want mm\n",
      "2511 loss:  1.30456 Prediction:  f you want mm\n",
      "2512 loss:  1.30451 Prediction:  f you want mm\n",
      "2513 loss:  1.30447 Prediction:  f you want mm\n",
      "2514 loss:  1.30442 Prediction:  f you want mm\n",
      "2515 loss:  1.30437 Prediction:  f you want mm\n",
      "2516 loss:  1.30433 Prediction:  f you want mm\n",
      "2517 loss:  1.30428 Prediction:  f you want mm\n",
      "2518 loss:  1.30424 Prediction:  f you want mm\n",
      "2519 loss:  1.30419 Prediction:  f you want mm\n",
      "2520 loss:  1.30415 Prediction:  f you want mm\n",
      "2521 loss:  1.3041 Prediction:  f you want mm\n",
      "2522 loss:  1.30406 Prediction:  f you want mm\n",
      "2523 loss:  1.30401 Prediction:  f you want mm\n",
      "2524 loss:  1.30396 Prediction:  f you want mm\n",
      "2525 loss:  1.30392 Prediction:  f you want mm\n",
      "2526 loss:  1.30387 Prediction:  f you want mm\n",
      "2527 loss:  1.30383 Prediction:  f you want mm\n",
      "2528 loss:  1.30378 Prediction:  f you want mm\n",
      "2529 loss:  1.30374 Prediction:  f you want mm\n",
      "2530 loss:  1.30369 Prediction:  f you want mm\n",
      "2531 loss:  1.30365 Prediction:  f you want mm\n",
      "2532 loss:  1.3036 Prediction:  f you want mm\n",
      "2533 loss:  1.30356 Prediction:  f you want mm\n",
      "2534 loss:  1.30351 Prediction:  f you want mm\n",
      "2535 loss:  1.30347 Prediction:  f you want mm\n",
      "2536 loss:  1.30342 Prediction:  f you want mm\n",
      "2537 loss:  1.30338 Prediction:  f you want mm\n",
      "2538 loss:  1.30333 Prediction:  f you want mm\n",
      "2539 loss:  1.30329 Prediction:  f you want mm\n",
      "2540 loss:  1.30325 Prediction:  f you want mm\n",
      "2541 loss:  1.3032 Prediction:  f you want mm\n",
      "2542 loss:  1.30316 Prediction:  f you want mm\n",
      "2543 loss:  1.30311 Prediction:  f you want mm\n",
      "2544 loss:  1.30307 Prediction:  f you want mm\n",
      "2545 loss:  1.30302 Prediction:  f you want mm\n",
      "2546 loss:  1.30298 Prediction:  f you want mm\n",
      "2547 loss:  1.30293 Prediction:  f you want mm\n",
      "2548 loss:  1.30289 Prediction:  f you want mm\n",
      "2549 loss:  1.30285 Prediction:  f you want mm\n",
      "2550 loss:  1.3028 Prediction:  f you want mm\n",
      "2551 loss:  1.30276 Prediction:  f you want mm\n",
      "2552 loss:  1.30271 Prediction:  f you want mm\n",
      "2553 loss:  1.30267 Prediction:  f you want mm\n",
      "2554 loss:  1.30262 Prediction:  f you want mm\n",
      "2555 loss:  1.30258 Prediction:  f you want mm\n",
      "2556 loss:  1.30254 Prediction:  f you want mm\n",
      "2557 loss:  1.30249 Prediction:  f you want mm\n",
      "2558 loss:  1.30245 Prediction:  f you want mm\n",
      "2559 loss:  1.3024 Prediction:  f you want mm\n",
      "2560 loss:  1.30236 Prediction:  f you want mm\n",
      "2561 loss:  1.30232 Prediction:  f you want mm\n",
      "2562 loss:  1.30227 Prediction:  f you want mm\n",
      "2563 loss:  1.30223 Prediction:  f you want mm\n",
      "2564 loss:  1.30219 Prediction:  f you want mm\n",
      "2565 loss:  1.30214 Prediction:  f you want mm\n",
      "2566 loss:  1.3021 Prediction:  f you want mm\n",
      "2567 loss:  1.30206 Prediction:  f you want mm\n",
      "2568 loss:  1.30201 Prediction:  f you want mm\n",
      "2569 loss:  1.30197 Prediction:  f you want mm\n",
      "2570 loss:  1.30192 Prediction:  f you want mm\n",
      "2571 loss:  1.30188 Prediction:  f you want mm\n",
      "2572 loss:  1.30184 Prediction:  f you want mm\n",
      "2573 loss:  1.30179 Prediction:  f you want mm\n",
      "2574 loss:  1.30175 Prediction:  f you want mm\n",
      "2575 loss:  1.30171 Prediction:  f you want mm\n",
      "2576 loss:  1.30166 Prediction:  f you want mm\n",
      "2577 loss:  1.30162 Prediction:  f you want mm\n",
      "2578 loss:  1.30158 Prediction:  f you want mm\n",
      "2579 loss:  1.30154 Prediction:  f you want mm\n",
      "2580 loss:  1.30149 Prediction:  f you want mm\n",
      "2581 loss:  1.30145 Prediction:  f you want mm\n",
      "2582 loss:  1.30141 Prediction:  f you want mm\n",
      "2583 loss:  1.30136 Prediction:  f you want mm\n",
      "2584 loss:  1.30132 Prediction:  f you want mm\n",
      "2585 loss:  1.30128 Prediction:  f you want mm\n",
      "2586 loss:  1.30123 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2587 loss:  1.30119 Prediction:  f you want mm\n",
      "2588 loss:  1.30115 Prediction:  f you want mm\n",
      "2589 loss:  1.30111 Prediction:  f you want mm\n",
      "2590 loss:  1.30106 Prediction:  f you want mm\n",
      "2591 loss:  1.30102 Prediction:  f you want mm\n",
      "2592 loss:  1.30098 Prediction:  f you want mm\n",
      "2593 loss:  1.30094 Prediction:  f you want mm\n",
      "2594 loss:  1.30089 Prediction:  f you want mm\n",
      "2595 loss:  1.30085 Prediction:  f you want mm\n",
      "2596 loss:  1.30081 Prediction:  f you want mm\n",
      "2597 loss:  1.30077 Prediction:  f you want mm\n",
      "2598 loss:  1.30072 Prediction:  f you want mm\n",
      "2599 loss:  1.30068 Prediction:  f you want mm\n",
      "2600 loss:  1.30064 Prediction:  f you want mm\n",
      "2601 loss:  1.3006 Prediction:  f you want mm\n",
      "2602 loss:  1.30055 Prediction:  f you want mm\n",
      "2603 loss:  1.30051 Prediction:  f you want mm\n",
      "2604 loss:  1.30047 Prediction:  f you want mm\n",
      "2605 loss:  1.30043 Prediction:  f you want mm\n",
      "2606 loss:  1.30039 Prediction:  f you want mm\n",
      "2607 loss:  1.30034 Prediction:  f you want mm\n",
      "2608 loss:  1.3003 Prediction:  f you want mm\n",
      "2609 loss:  1.30026 Prediction:  f you want mm\n",
      "2610 loss:  1.30022 Prediction:  f you want mm\n",
      "2611 loss:  1.30018 Prediction:  f you want mm\n",
      "2612 loss:  1.30013 Prediction:  f you want mm\n",
      "2613 loss:  1.30009 Prediction:  f you want mm\n",
      "2614 loss:  1.30005 Prediction:  f you want mm\n",
      "2615 loss:  1.30001 Prediction:  f you want mm\n",
      "2616 loss:  1.29997 Prediction:  f you want mm\n",
      "2617 loss:  1.29993 Prediction:  f you want mm\n",
      "2618 loss:  1.29988 Prediction:  f you want mm\n",
      "2619 loss:  1.29984 Prediction:  f you want mm\n",
      "2620 loss:  1.2998 Prediction:  f you want mm\n",
      "2621 loss:  1.29976 Prediction:  f you want mm\n",
      "2622 loss:  1.29972 Prediction:  f you want mm\n",
      "2623 loss:  1.29968 Prediction:  f you want mm\n",
      "2624 loss:  1.29963 Prediction:  f you want mm\n",
      "2625 loss:  1.29959 Prediction:  f you want mm\n",
      "2626 loss:  1.29955 Prediction:  f you want mm\n",
      "2627 loss:  1.29951 Prediction:  f you want mm\n",
      "2628 loss:  1.29947 Prediction:  f you want mm\n",
      "2629 loss:  1.29943 Prediction:  f you want mm\n",
      "2630 loss:  1.29939 Prediction:  f you want mm\n",
      "2631 loss:  1.29935 Prediction:  f you want mm\n",
      "2632 loss:  1.2993 Prediction:  f you want mm\n",
      "2633 loss:  1.29926 Prediction:  f you want mm\n",
      "2634 loss:  1.29922 Prediction:  f you want mm\n",
      "2635 loss:  1.29918 Prediction:  f you want mm\n",
      "2636 loss:  1.29914 Prediction:  f you want mm\n",
      "2637 loss:  1.2991 Prediction:  f you want mm\n",
      "2638 loss:  1.29906 Prediction:  f you want mm\n",
      "2639 loss:  1.29902 Prediction:  f you want mm\n",
      "2640 loss:  1.29898 Prediction:  f you want mm\n",
      "2641 loss:  1.29894 Prediction:  f you want mm\n",
      "2642 loss:  1.29889 Prediction:  f you want mm\n",
      "2643 loss:  1.29885 Prediction:  f you want mm\n",
      "2644 loss:  1.29881 Prediction:  f you want mm\n",
      "2645 loss:  1.29877 Prediction:  f you want mm\n",
      "2646 loss:  1.29873 Prediction:  f you want mm\n",
      "2647 loss:  1.29869 Prediction:  f you want mm\n",
      "2648 loss:  1.29865 Prediction:  f you want mm\n",
      "2649 loss:  1.29861 Prediction:  f you want mm\n",
      "2650 loss:  1.29857 Prediction:  f you want mm\n",
      "2651 loss:  1.29853 Prediction:  f you want mm\n",
      "2652 loss:  1.29849 Prediction:  f you want mm\n",
      "2653 loss:  1.29845 Prediction:  f you want mm\n",
      "2654 loss:  1.29841 Prediction:  f you want mm\n",
      "2655 loss:  1.29837 Prediction:  f you want mm\n",
      "2656 loss:  1.29833 Prediction:  f you want mm\n",
      "2657 loss:  1.29829 Prediction:  f you want mm\n",
      "2658 loss:  1.29825 Prediction:  f you want mm\n",
      "2659 loss:  1.29821 Prediction:  f you want mm\n",
      "2660 loss:  1.29817 Prediction:  f you want mm\n",
      "2661 loss:  1.29813 Prediction:  f you want mm\n",
      "2662 loss:  1.29809 Prediction:  f you want mm\n",
      "2663 loss:  1.29805 Prediction:  f you want mm\n",
      "2664 loss:  1.29801 Prediction:  f you want mm\n",
      "2665 loss:  1.29797 Prediction:  f you want mm\n",
      "2666 loss:  1.29793 Prediction:  f you want mm\n",
      "2667 loss:  1.29789 Prediction:  f you want mm\n",
      "2668 loss:  1.29785 Prediction:  f you want mm\n",
      "2669 loss:  1.29781 Prediction:  f you want mm\n",
      "2670 loss:  1.29777 Prediction:  f you want mm\n",
      "2671 loss:  1.29773 Prediction:  f you want mm\n",
      "2672 loss:  1.29769 Prediction:  f you want mm\n",
      "2673 loss:  1.29765 Prediction:  f you want mm\n",
      "2674 loss:  1.29761 Prediction:  f you want mm\n",
      "2675 loss:  1.29757 Prediction:  f you want mm\n",
      "2676 loss:  1.29753 Prediction:  f you want mm\n",
      "2677 loss:  1.29749 Prediction:  f you want mm\n",
      "2678 loss:  1.29745 Prediction:  f you want mm\n",
      "2679 loss:  1.29741 Prediction:  f you want mm\n",
      "2680 loss:  1.29737 Prediction:  f you want mm\n",
      "2681 loss:  1.29733 Prediction:  f you want mm\n",
      "2682 loss:  1.29729 Prediction:  f you want mm\n",
      "2683 loss:  1.29725 Prediction:  f you want mm\n",
      "2684 loss:  1.29721 Prediction:  f you want mm\n",
      "2685 loss:  1.29717 Prediction:  f you want mm\n",
      "2686 loss:  1.29713 Prediction:  f you want mm\n",
      "2687 loss:  1.29709 Prediction:  f you want mm\n",
      "2688 loss:  1.29706 Prediction:  f you want mm\n",
      "2689 loss:  1.29702 Prediction:  f you want mm\n",
      "2690 loss:  1.29698 Prediction:  f you want mm\n",
      "2691 loss:  1.29694 Prediction:  f you want mm\n",
      "2692 loss:  1.2969 Prediction:  f you want mm\n",
      "2693 loss:  1.29686 Prediction:  f you want mm\n",
      "2694 loss:  1.29682 Prediction:  f you want mm\n",
      "2695 loss:  1.29678 Prediction:  f you want mm\n",
      "2696 loss:  1.29674 Prediction:  f you want mm\n",
      "2697 loss:  1.2967 Prediction:  f you want mm\n",
      "2698 loss:  1.29666 Prediction:  f you want mm\n",
      "2699 loss:  1.29663 Prediction:  f you want mm\n",
      "2700 loss:  1.29659 Prediction:  f you want mm\n",
      "2701 loss:  1.29655 Prediction:  f you want mm\n",
      "2702 loss:  1.29651 Prediction:  f you want mm\n",
      "2703 loss:  1.29647 Prediction:  f you want mm\n",
      "2704 loss:  1.29643 Prediction:  f you want mm\n",
      "2705 loss:  1.29639 Prediction:  f you want mm\n",
      "2706 loss:  1.29635 Prediction:  f you want mm\n",
      "2707 loss:  1.29632 Prediction:  f you want mm\n",
      "2708 loss:  1.29628 Prediction:  f you want mm\n",
      "2709 loss:  1.29624 Prediction:  f you want mm\n",
      "2710 loss:  1.2962 Prediction:  f you want mm\n",
      "2711 loss:  1.29616 Prediction:  f you want mm\n",
      "2712 loss:  1.29612 Prediction:  f you want mm\n",
      "2713 loss:  1.29608 Prediction:  f you want mm\n",
      "2714 loss:  1.29605 Prediction:  f you want mm\n",
      "2715 loss:  1.29601 Prediction:  f you want mm\n",
      "2716 loss:  1.29597 Prediction:  f you want mm\n",
      "2717 loss:  1.29593 Prediction:  f you want mm\n",
      "2718 loss:  1.29589 Prediction:  f you want mm\n",
      "2719 loss:  1.29585 Prediction:  f you want mm\n",
      "2720 loss:  1.29582 Prediction:  f you want mm\n",
      "2721 loss:  1.29578 Prediction:  f you want mm\n",
      "2722 loss:  1.29574 Prediction:  f you want mm\n",
      "2723 loss:  1.2957 Prediction:  f you want mm\n",
      "2724 loss:  1.29566 Prediction:  f you want mm\n",
      "2725 loss:  1.29562 Prediction:  f you want mm\n",
      "2726 loss:  1.29559 Prediction:  f you want mm\n",
      "2727 loss:  1.29555 Prediction:  f you want mm\n",
      "2728 loss:  1.29551 Prediction:  f you want mm\n",
      "2729 loss:  1.29547 Prediction:  f you want mm\n",
      "2730 loss:  1.29543 Prediction:  f you want mm\n",
      "2731 loss:  1.2954 Prediction:  f you want mm\n",
      "2732 loss:  1.29536 Prediction:  f you want mm\n",
      "2733 loss:  1.29532 Prediction:  f you want mm\n",
      "2734 loss:  1.29528 Prediction:  f you want mm\n",
      "2735 loss:  1.29525 Prediction:  f you want mm\n",
      "2736 loss:  1.29521 Prediction:  f you want mm\n",
      "2737 loss:  1.29517 Prediction:  f you want mm\n",
      "2738 loss:  1.29513 Prediction:  f you want mm\n",
      "2739 loss:  1.29509 Prediction:  f you want mm\n",
      "2740 loss:  1.29506 Prediction:  f you want mm\n",
      "2741 loss:  1.29502 Prediction:  f you want mm\n",
      "2742 loss:  1.29498 Prediction:  f you want mm\n",
      "2743 loss:  1.29494 Prediction:  f you want mm\n",
      "2744 loss:  1.29491 Prediction:  f you want mm\n",
      "2745 loss:  1.29487 Prediction:  f you want mm\n",
      "2746 loss:  1.29483 Prediction:  f you want mm\n",
      "2747 loss:  1.29479 Prediction:  f you want mm\n",
      "2748 loss:  1.29476 Prediction:  f you want mm\n",
      "2749 loss:  1.29472 Prediction:  f you want mm\n",
      "2750 loss:  1.29468 Prediction:  f you want mm\n",
      "2751 loss:  1.29464 Prediction:  f you want mm\n",
      "2752 loss:  1.29461 Prediction:  f you want mm\n",
      "2753 loss:  1.29457 Prediction:  f you want mm\n",
      "2754 loss:  1.29453 Prediction:  f you want mm\n",
      "2755 loss:  1.2945 Prediction:  f you want mm\n",
      "2756 loss:  1.29446 Prediction:  f you want mm\n",
      "2757 loss:  1.29442 Prediction:  f you want mm\n",
      "2758 loss:  1.29438 Prediction:  f you want mm\n",
      "2759 loss:  1.29435 Prediction:  f you want mm\n",
      "2760 loss:  1.29431 Prediction:  f you want mm\n",
      "2761 loss:  1.29427 Prediction:  f you want mm\n",
      "2762 loss:  1.29424 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2763 loss:  1.2942 Prediction:  f you want mm\n",
      "2764 loss:  1.29416 Prediction:  f you want mm\n",
      "2765 loss:  1.29413 Prediction:  f you want mm\n",
      "2766 loss:  1.29409 Prediction:  f you want mm\n",
      "2767 loss:  1.29405 Prediction:  f you want mm\n",
      "2768 loss:  1.29401 Prediction:  f you want mm\n",
      "2769 loss:  1.29398 Prediction:  f you want mm\n",
      "2770 loss:  1.29394 Prediction:  f you want mm\n",
      "2771 loss:  1.2939 Prediction:  f you want mm\n",
      "2772 loss:  1.29387 Prediction:  f you want mm\n",
      "2773 loss:  1.29383 Prediction:  f you want mm\n",
      "2774 loss:  1.29379 Prediction:  f you want mm\n",
      "2775 loss:  1.29376 Prediction:  f you want mm\n",
      "2776 loss:  1.29372 Prediction:  f you want mm\n",
      "2777 loss:  1.29368 Prediction:  f you want mm\n",
      "2778 loss:  1.29365 Prediction:  f you want mm\n",
      "2779 loss:  1.29361 Prediction:  f you want mm\n",
      "2780 loss:  1.29357 Prediction:  f you want mm\n",
      "2781 loss:  1.29354 Prediction:  f you want mm\n",
      "2782 loss:  1.2935 Prediction:  f you want mm\n",
      "2783 loss:  1.29347 Prediction:  f you want mm\n",
      "2784 loss:  1.29343 Prediction:  f you want mm\n",
      "2785 loss:  1.29339 Prediction:  f you want mm\n",
      "2786 loss:  1.29336 Prediction:  f you want mm\n",
      "2787 loss:  1.29332 Prediction:  f you want mm\n",
      "2788 loss:  1.29328 Prediction:  f you want mm\n",
      "2789 loss:  1.29325 Prediction:  f you want mm\n",
      "2790 loss:  1.29321 Prediction:  f you want mm\n",
      "2791 loss:  1.29317 Prediction:  f you want mm\n",
      "2792 loss:  1.29314 Prediction:  f you want mm\n",
      "2793 loss:  1.2931 Prediction:  f you want mm\n",
      "2794 loss:  1.29307 Prediction:  f you want mm\n",
      "2795 loss:  1.29303 Prediction:  f you want mm\n",
      "2796 loss:  1.29299 Prediction:  f you want mm\n",
      "2797 loss:  1.29296 Prediction:  f you want mm\n",
      "2798 loss:  1.29292 Prediction:  f you want mm\n",
      "2799 loss:  1.29289 Prediction:  f you want mm\n",
      "2800 loss:  1.29285 Prediction:  f you want mm\n",
      "2801 loss:  1.29281 Prediction:  f you want mm\n",
      "2802 loss:  1.29278 Prediction:  f you want mm\n",
      "2803 loss:  1.29274 Prediction:  f you want mm\n",
      "2804 loss:  1.29271 Prediction:  f you want mm\n",
      "2805 loss:  1.29267 Prediction:  f you want mm\n",
      "2806 loss:  1.29264 Prediction:  f you want mm\n",
      "2807 loss:  1.2926 Prediction:  f you want mm\n",
      "2808 loss:  1.29256 Prediction:  f you want mm\n",
      "2809 loss:  1.29253 Prediction:  f you want mm\n",
      "2810 loss:  1.29249 Prediction:  f you want mm\n",
      "2811 loss:  1.29246 Prediction:  f you want mm\n",
      "2812 loss:  1.29242 Prediction:  f you want mm\n",
      "2813 loss:  1.29239 Prediction:  f you want mm\n",
      "2814 loss:  1.29235 Prediction:  f you want mm\n",
      "2815 loss:  1.29231 Prediction:  f you want mm\n",
      "2816 loss:  1.29228 Prediction:  f you want mm\n",
      "2817 loss:  1.29224 Prediction:  f you want mm\n",
      "2818 loss:  1.29221 Prediction:  f you want mm\n",
      "2819 loss:  1.29217 Prediction:  f you want mm\n",
      "2820 loss:  1.29214 Prediction:  f you want mm\n",
      "2821 loss:  1.2921 Prediction:  f you want mm\n",
      "2822 loss:  1.29207 Prediction:  f you want mm\n",
      "2823 loss:  1.29203 Prediction:  f you want mm\n",
      "2824 loss:  1.292 Prediction:  f you want mm\n",
      "2825 loss:  1.29196 Prediction:  f you want mm\n",
      "2826 loss:  1.29192 Prediction:  f you want mm\n",
      "2827 loss:  1.29189 Prediction:  f you want mm\n",
      "2828 loss:  1.29185 Prediction:  f you want mm\n",
      "2829 loss:  1.29182 Prediction:  f you want mm\n",
      "2830 loss:  1.29178 Prediction:  f you want mm\n",
      "2831 loss:  1.29175 Prediction:  f you want mm\n",
      "2832 loss:  1.29171 Prediction:  f you want mm\n",
      "2833 loss:  1.29168 Prediction:  f you want mm\n",
      "2834 loss:  1.29164 Prediction:  f you want mm\n",
      "2835 loss:  1.29161 Prediction:  f you want mm\n",
      "2836 loss:  1.29157 Prediction:  f you want mm\n",
      "2837 loss:  1.29154 Prediction:  f you want mm\n",
      "2838 loss:  1.2915 Prediction:  f you want mm\n",
      "2839 loss:  1.29147 Prediction:  f you want mm\n",
      "2840 loss:  1.29143 Prediction:  f you want mm\n",
      "2841 loss:  1.2914 Prediction:  f you want mm\n",
      "2842 loss:  1.29136 Prediction:  f you want mm\n",
      "2843 loss:  1.29133 Prediction:  f you want mm\n",
      "2844 loss:  1.29129 Prediction:  f you want mm\n",
      "2845 loss:  1.29126 Prediction:  f you want mm\n",
      "2846 loss:  1.29122 Prediction:  f you want mm\n",
      "2847 loss:  1.29119 Prediction:  f you want mm\n",
      "2848 loss:  1.29115 Prediction:  f you want mm\n",
      "2849 loss:  1.29112 Prediction:  f you want mm\n",
      "2850 loss:  1.29109 Prediction:  f you want mm\n",
      "2851 loss:  1.29105 Prediction:  f you want mm\n",
      "2852 loss:  1.29102 Prediction:  f you want mm\n",
      "2853 loss:  1.29098 Prediction:  f you want mm\n",
      "2854 loss:  1.29095 Prediction:  f you want mm\n",
      "2855 loss:  1.29091 Prediction:  f you want mm\n",
      "2856 loss:  1.29088 Prediction:  f you want mm\n",
      "2857 loss:  1.29084 Prediction:  f you want mm\n",
      "2858 loss:  1.29081 Prediction:  f you want mm\n",
      "2859 loss:  1.29077 Prediction:  f you want mm\n",
      "2860 loss:  1.29074 Prediction:  f you want mm\n",
      "2861 loss:  1.29071 Prediction:  f you want mm\n",
      "2862 loss:  1.29067 Prediction:  f you want mm\n",
      "2863 loss:  1.29064 Prediction:  f you want mm\n",
      "2864 loss:  1.2906 Prediction:  f you want mm\n",
      "2865 loss:  1.29057 Prediction:  f you want mm\n",
      "2866 loss:  1.29053 Prediction:  f you want mm\n",
      "2867 loss:  1.2905 Prediction:  f you want mm\n",
      "2868 loss:  1.29047 Prediction:  f you want mm\n",
      "2869 loss:  1.29043 Prediction:  f you want mm\n",
      "2870 loss:  1.2904 Prediction:  f you want mm\n",
      "2871 loss:  1.29036 Prediction:  f you want mm\n",
      "2872 loss:  1.29033 Prediction:  f you want mm\n",
      "2873 loss:  1.29029 Prediction:  f you want mm\n",
      "2874 loss:  1.29026 Prediction:  f you want mm\n",
      "2875 loss:  1.29023 Prediction:  f you want mm\n",
      "2876 loss:  1.29019 Prediction:  f you want mm\n",
      "2877 loss:  1.29016 Prediction:  f you want mm\n",
      "2878 loss:  1.29012 Prediction:  f you want mm\n",
      "2879 loss:  1.29009 Prediction:  f you want mm\n",
      "2880 loss:  1.29006 Prediction:  f you want mm\n",
      "2881 loss:  1.29002 Prediction:  f you want mm\n",
      "2882 loss:  1.28999 Prediction:  f you want mm\n",
      "2883 loss:  1.28995 Prediction:  f you want mm\n",
      "2884 loss:  1.28992 Prediction:  f you want mm\n",
      "2885 loss:  1.28989 Prediction:  f you want mm\n",
      "2886 loss:  1.28985 Prediction:  f you want mm\n",
      "2887 loss:  1.28982 Prediction:  f you want mm\n",
      "2888 loss:  1.28979 Prediction:  f you want mm\n",
      "2889 loss:  1.28975 Prediction:  f you want mm\n",
      "2890 loss:  1.28972 Prediction:  f you want mm\n",
      "2891 loss:  1.28968 Prediction:  f you want mm\n",
      "2892 loss:  1.28965 Prediction:  f you want mm\n",
      "2893 loss:  1.28962 Prediction:  f you want mm\n",
      "2894 loss:  1.28958 Prediction:  f you want mm\n",
      "2895 loss:  1.28955 Prediction:  f you want mm\n",
      "2896 loss:  1.28952 Prediction:  f you want mm\n",
      "2897 loss:  1.28948 Prediction:  f you want mm\n",
      "2898 loss:  1.28945 Prediction:  f you want mm\n",
      "2899 loss:  1.28942 Prediction:  f you want mm\n",
      "2900 loss:  1.28938 Prediction:  f you want mm\n",
      "2901 loss:  1.28935 Prediction:  f you want mm\n",
      "2902 loss:  1.28932 Prediction:  f you want mm\n",
      "2903 loss:  1.28928 Prediction:  f you want mm\n",
      "2904 loss:  1.28925 Prediction:  f you want mm\n",
      "2905 loss:  1.28922 Prediction:  f you want mm\n",
      "2906 loss:  1.28918 Prediction:  f you want mm\n",
      "2907 loss:  1.28915 Prediction:  f you want mm\n",
      "2908 loss:  1.28912 Prediction:  f you want mm\n",
      "2909 loss:  1.28908 Prediction:  f you want mm\n",
      "2910 loss:  1.28905 Prediction:  f you want mm\n",
      "2911 loss:  1.28902 Prediction:  f you want mm\n",
      "2912 loss:  1.28898 Prediction:  f you want mm\n",
      "2913 loss:  1.28895 Prediction:  f you want mm\n",
      "2914 loss:  1.28892 Prediction:  f you want mm\n",
      "2915 loss:  1.28888 Prediction:  f you want mm\n",
      "2916 loss:  1.28885 Prediction:  f you want mm\n",
      "2917 loss:  1.28882 Prediction:  f you want mm\n",
      "2918 loss:  1.28878 Prediction:  f you want mm\n",
      "2919 loss:  1.28875 Prediction:  f you want mm\n",
      "2920 loss:  1.28872 Prediction:  f you want mm\n",
      "2921 loss:  1.28868 Prediction:  f you want mm\n",
      "2922 loss:  1.28865 Prediction:  f you want mm\n",
      "2923 loss:  1.28862 Prediction:  f you want mm\n",
      "2924 loss:  1.28858 Prediction:  f you want mm\n",
      "2925 loss:  1.28855 Prediction:  f you want mm\n",
      "2926 loss:  1.28852 Prediction:  f you want mm\n",
      "2927 loss:  1.28849 Prediction:  f you want mm\n",
      "2928 loss:  1.28845 Prediction:  f you want mm\n",
      "2929 loss:  1.28842 Prediction:  f you want mm\n",
      "2930 loss:  1.28839 Prediction:  f you want mm\n",
      "2931 loss:  1.28835 Prediction:  f you want mm\n",
      "2932 loss:  1.28832 Prediction:  f you want mm\n",
      "2933 loss:  1.28829 Prediction:  f you want mm\n",
      "2934 loss:  1.28826 Prediction:  f you want mm\n",
      "2935 loss:  1.28822 Prediction:  f you want mm\n",
      "2936 loss:  1.28819 Prediction:  f you want mm\n",
      "2937 loss:  1.28816 Prediction:  f you want mm\n",
      "2938 loss:  1.28813 Prediction:  f you want mm\n",
      "2939 loss:  1.28809 Prediction:  f you want mm\n",
      "2940 loss:  1.28806 Prediction:  f you want mm\n",
      "2941 loss:  1.28803 Prediction:  f you want mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2942 loss:  1.28799 Prediction:  f you want mm\n",
      "2943 loss:  1.28796 Prediction:  f you want mm\n",
      "2944 loss:  1.28793 Prediction:  f you want mm\n",
      "2945 loss:  1.2879 Prediction:  f you want mm\n",
      "2946 loss:  1.28786 Prediction:  f you want mm\n",
      "2947 loss:  1.28783 Prediction:  f you want mm\n",
      "2948 loss:  1.2878 Prediction:  f you want mm\n",
      "2949 loss:  1.28777 Prediction:  f you want mm\n",
      "2950 loss:  1.28773 Prediction:  f you want mm\n",
      "2951 loss:  1.2877 Prediction:  f you want mm\n",
      "2952 loss:  1.28767 Prediction:  f you want mm\n",
      "2953 loss:  1.28764 Prediction:  f you want mm\n",
      "2954 loss:  1.28761 Prediction:  f you want mm\n",
      "2955 loss:  1.28757 Prediction:  f you want mm\n",
      "2956 loss:  1.28754 Prediction:  f you want mm\n",
      "2957 loss:  1.28751 Prediction:  f you want mm\n",
      "2958 loss:  1.28748 Prediction:  f you want mm\n",
      "2959 loss:  1.28744 Prediction:  f you want mm\n",
      "2960 loss:  1.28741 Prediction:  f you want mm\n",
      "2961 loss:  1.28738 Prediction:  f you want mm\n",
      "2962 loss:  1.28735 Prediction:  f you want mm\n",
      "2963 loss:  1.28732 Prediction:  f you want mm\n",
      "2964 loss:  1.28728 Prediction:  f you want mm\n",
      "2965 loss:  1.28725 Prediction:  f you want mm\n",
      "2966 loss:  1.28722 Prediction:  f you want mm\n",
      "2967 loss:  1.28719 Prediction:  f you want mm\n",
      "2968 loss:  1.28715 Prediction:  f you want mm\n",
      "2969 loss:  1.28712 Prediction:  f you want mm\n",
      "2970 loss:  1.28709 Prediction:  f you want mm\n",
      "2971 loss:  1.28706 Prediction:  f you want mm\n",
      "2972 loss:  1.28703 Prediction:  f you want mm\n",
      "2973 loss:  1.28699 Prediction:  f you want mm\n",
      "2974 loss:  1.28696 Prediction:  f you want mm\n",
      "2975 loss:  1.28693 Prediction:  f you want mm\n",
      "2976 loss:  1.2869 Prediction:  f you want mm\n",
      "2977 loss:  1.28687 Prediction:  f you want mm\n",
      "2978 loss:  1.28683 Prediction:  f you want mm\n",
      "2979 loss:  1.2868 Prediction:  f you want mm\n",
      "2980 loss:  1.28677 Prediction:  f you want mm\n",
      "2981 loss:  1.28674 Prediction:  f you want mm\n",
      "2982 loss:  1.28671 Prediction:  f you want mm\n",
      "2983 loss:  1.28668 Prediction:  f you want mm\n",
      "2984 loss:  1.28664 Prediction:  f you want mm\n",
      "2985 loss:  1.28661 Prediction:  f you want mm\n",
      "2986 loss:  1.28658 Prediction:  f you want me\n",
      "2987 loss:  1.28655 Prediction:  f you want me\n",
      "2988 loss:  1.28652 Prediction:  f you want me\n",
      "2989 loss:  1.28649 Prediction:  f you want me\n",
      "2990 loss:  1.28645 Prediction:  f you want me\n",
      "2991 loss:  1.28642 Prediction:  f you want me\n",
      "2992 loss:  1.28639 Prediction:  f you want me\n",
      "2993 loss:  1.28636 Prediction:  f you want me\n",
      "2994 loss:  1.28633 Prediction:  f you want me\n",
      "2995 loss:  1.2863 Prediction:  f you want me\n",
      "2996 loss:  1.28626 Prediction:  f you want me\n",
      "2997 loss:  1.28623 Prediction:  f you want me\n",
      "2998 loss:  1.2862 Prediction:  f you want me\n",
      "2999 loss:  1.28617 Prediction:  f you want me\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(3000):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_data, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_data})\n",
    "        \n",
    "        #print char using dic\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(i , \"loss: \", l, \"Prediction: \", ''.join(result_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. long sequence RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether to \n",
      "52 gether to  -> ether to c\n",
      "53 ether to c -> ther to co\n",
      "54 ther to co -> her to col\n",
      "55 her to col -> er to coll\n",
      "56 er to coll -> r to colle\n",
      "57 r to colle ->  to collec\n",
      "58  to collec -> to collect\n",
      "59 to collect -> o collect \n",
      "60 o collect  ->  collect w\n",
      "61  collect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for e\n",
      "138 long for e -> ong for en\n",
      "139 ong for en -> ng for end\n",
      "140 ng for end -> g for endl\n",
      "141 g for endl ->  for endle\n",
      "142  for endle -> for endles\n",
      "143 for endles -> or endless\n",
      "144 or endless -> r endless \n",
      "145 r endless  ->  endless i\n",
      "146  endless i -> endless im\n",
      "147 endless im -> ndless imm\n",
      "148 ndless imm -> dless imme\n",
      "149 dless imme -> less immen\n",
      "150 less immen -> ess immens\n",
      "151 ess immens -> ss immensi\n",
      "152 ss immensi -> s immensit\n",
      "153 s immensit ->  immensity\n",
      "154  immensity -> immensity \n",
      "155 immensity  -> mmensity o\n",
      "156 mmensity o -> mensity of\n",
      "157 mensity of -> ensity of \n",
      "158 ensity of  -> nsity of t\n",
      "159 nsity of t -> sity of th\n",
      "160 sity of th -> ity of the\n",
      "161 ity of the -> ty of the \n",
      "162 ty of the  -> y of the s\n",
      "163 y of the s ->  of the se\n",
      "164  of the se -> of the sea\n",
      "165 of the sea -> f the sea.\n",
      "['m', 'a', 'l', 'e', 'u', \"'\", 'k', 's', 'd', 'o', 'c', 'h', 'n', 't', 'f', 'b', ',', 'g', 'p', 'w', 'y', 'r', '.', ' ', 'i']\n",
      "{'m': 0, 'a': 1, 'l': 2, 'e': 3, 'u': 4, \"'\": 5, 'k': 6, 's': 7, 'd': 8, 'o': 9, 'c': 10, 'h': 11, 'n': 12, 't': 13, 'f': 14, 'b': 15, ',': 16, 'g': 17, 'p': 18, 'w': 19, 'y': 20, 'r': 21, '.': 22, ' ': 23, 'i': 24}\n"
     ]
    }
   ],
   "source": [
    "#1. 데이터 정의\n",
    "sentence = \"if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for endless immensity of the sea.\"\n",
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "#hyperparameter\n",
    "sequence_length = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i+1 : i+sequence_length+1]\n",
    "    \n",
    "    print(i, x_str, '->', y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    \n",
    "batch_size = len(dataX)\n",
    "\n",
    "print(char_set)\n",
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot:0\", shape=(?, 10, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes)\n",
    "print(X_one_hot)\n",
    "\n",
    "#2. cell 정의\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "#3. loss 정의\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "\n",
    "#4. train 정의\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#5. prediction 정의\n",
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-31829c38f6fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print char using dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresult_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Prediction: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-31829c38f6fe>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print char using dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresult_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Prediction: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(500):\n",
    "    _, l, results = sess.run(\n",
    "        [train_op, loss, outputs], feed_dict={X: dataX, Y: dataY})\n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "        print(i, j, ''.join([char_set[t] for t in index]), l)\n",
    "\n",
    "# Let's print the last char of each result to check it works\n",
    "results = sess.run(outputs, feed_dict={X: dataX})\n",
    "for j, result in enumerate(results):\n",
    "    index = np.argmax(result, axis=1)\n",
    "    if j is 0:  # print all for the first result to make a sentence\n",
    "        print(''.join([char_set[t] for t in index]), end='')\n",
    "    else:\n",
    "        print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
