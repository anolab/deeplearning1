{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./photo/softmax1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 개념 다지기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. softmax는 logistic regression의 multiclass 판<br/>\n",
    "    -> binary classification에서 multiclass classification으로 변경<br/><br/>\n",
    "    \n",
    "2. logistic regression의 경우 g(z): sigmoid function으로 H(X)를 0 <= H(X) = g(z) = g(X*w) <=1로 유지하고, 출력을 확률 값으로 변경<br/>\n",
    "    -> sigmoid regression의 경우 H(X): softmax function(e^Wk.T*x / sigma(e^Wi.T.x))를 사용<br/>\n",
    "    -> 마찬가지로 각 Class 에 속할 확률으로 표현<br/><br/>\n",
    "\n",
    "3. costfunction\n",
    "    -> cross entropy 개념<br/>\n",
    "    -> D(S, L) = sigma(실제 값(Li) * log(예측값=softmax(i))<br/>\n",
    "    -> W = W - learning_rate * derivative 로 이동하면서 개선 가능(왜냐하면 convex)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.데이터 및 변수 설정\n",
    "x_data = [[1,2,1,1],\n",
    "          [2,1,3,2],\n",
    "          [3,1,3,4],\n",
    "          [4,1,5,5],\n",
    "          [1,7,5,5],\n",
    "          [1,2,5,6],\n",
    "          [1,6,6,6],\n",
    "          [1,7,7,7]]\n",
    "\n",
    "y_data = [[0,0,1],\n",
    "          [0,0,1],\n",
    "          [0,0,1],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [1,0,0],\n",
    "          [1,0,0]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. 가설 설정\n",
    "#tf.nn.softmax computes softmax activation\n",
    "#softmax = exp(Logits) / reduce_sum(exp(Logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. cost 함수\n",
    "#Cross Entropy Loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 126.9\n",
      "200 49.4237\n",
      "400 18.1062\n",
      "600 2.0185\n",
      "800 55.5735\n",
      "1000 0.0242367\n",
      "1200 0.0161528\n",
      "1400 0.0129173\n",
      "1600 0.0112206\n",
      "1800 0.0102909\n",
      "2000 0.00979997\n",
      "[[  9.21498121e-12   1.00000000e+00   8.31275221e-14]] [1]\n",
      "[[  9.21498121e-12   1.00000000e+00   8.31275153e-14]\n",
      " [  9.99859095e-01   1.40729462e-04   7.95577648e-08]\n",
      " [  1.32816656e-35   1.38087417e-13   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#5. Launch\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "    \n",
    "    #6. Testing & One-hot encoding\n",
    "    a = sess.run(hypothesis, feed_dict={X:[[1,11,7,9]]})\n",
    "    print(a, sess.run(tf.argmax(a, 1)))\n",
    "    \n",
    "    all = sess.run(hypothesis, feed_dict={X: [[1,11,7,9],\n",
    "                                              [1,3,4,3],\n",
    "                                              [1,1,0,1]]})\n",
    "    print(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fancy Softmax Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5ed0af29abe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#현재\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcost_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "#기존\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_mean(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "#현재\n",
    "logits = tf.matmul(X,W)+b\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32),\n",
       " array([101,   1,   7], dtype=int32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. 데이터 및 변수 설정\n",
    "xy = np.loadtxt('./data/data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "nb_classes = 7\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 16])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "#Y_one_hot 출력\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "Y_one_hot_shape = tf.shape(Y_one_hot)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run([Y_one_hot, Y_one_hot_shape], feed_dict={Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32),\n",
       " array([0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 1, 3, 6, 6, 6, 1, 0, 3, 0, 1, 1, 0,\n",
       "        1, 5, 4, 4, 0, 0, 0, 5, 0, 0, 1, 3, 0, 0, 1, 3, 5, 5, 1, 5, 1, 0, 0,\n",
       "        6, 0, 0, 0, 0, 5, 4, 6, 0, 0, 1, 1, 1, 1, 3, 3, 2, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 6, 3, 0, 0, 2, 6, 1, 1, 2, 6, 3, 1, 0, 6, 3, 1, 5, 4, 2, 2,\n",
       "        3, 0, 0, 1, 0, 5, 0, 6, 1])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y_one_hot shape 조정\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "Y_one_hot_check = tf.argmax(Y_one_hot, 1)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run([Y_one_hot, Y_one_hot_check], feed_dict={Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_one_hot shape 조정\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "Y_one_hot_check = tf.argmax(Y_one_hot, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. hypothesis\n",
    "#tf.nn.softmax computes softmax activations\n",
    "logits = tf.matmul(X,W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "#3. cost\n",
    "#cross entropy cost/loss\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                 labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction \n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 1 6 6 6 6 1 1 6 6 6 1 4 4 6 6 6 4 6 6 6 6 6 6 6 6 6 6 5 6 6 5 6 1 6 6\n",
      " 6 1 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 6 4 1 1 4 6 6 6 6 6 6 6 6 6 1\n",
      " 5 6 4 4 6 6 1 1 1 6 6 6 4 6 6 6 6 6 4 6 6 6 6 6 6 1 6]\n",
      "[False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False]\n"
     ]
    }
   ],
   "source": [
    "#출력\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "arg_max = tf.argmax(Y_one_hot, 1)\n",
    "\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(prediction, feed_dict={X: x_data, Y: y_data}))\n",
    "print(sess.run(correct_prediction, feed_dict={X: x_data, Y: y_data}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 4.224\tAcc: 16.83%\n",
      "Step:   200\tLoss: 0.348\tAcc: 92.08%\n",
      "Step:   400\tLoss: 0.208\tAcc: 94.06%\n",
      "Step:   600\tLoss: 0.149\tAcc: 97.03%\n",
      "Step:   800\tLoss: 0.117\tAcc: 99.01%\n",
      "Step:  1000\tLoss: 0.096\tAcc: 99.01%\n",
      "Step:  1200\tLoss: 0.082\tAcc: 100.00%\n",
      "Step:  1400\tLoss: 0.071\tAcc: 100.00%\n",
      "Step:  1600\tLoss: 0.063\tAcc: 100.00%\n",
      "Step:  1800\tLoss: 0.057\tAcc: 100.00%\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "#5. Launch\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2000):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "        if step % 200 == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "\n",
    "        pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "    \n",
    "    for p, y in zip(pred, y_data.flatten()):\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 1.]]\n",
      "[ 0.  0.  3.  0.  0.  0.  0.  3.  3.  0.  0.  1.  3.  6.  6.  6.  1.  0.\n",
      "  3.  0.  1.  1.  0.  1.  5.  4.  4.  0.  0.  0.  5.  0.  0.  1.  3.  0.\n",
      "  0.  1.  3.  5.  5.  1.  5.  1.  0.  0.  6.  0.  0.  0.  0.  5.  4.  6.\n",
      "  0.  0.  1.  1.  1.  1.  3.  3.  2.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  6.  3.  0.  0.  2.  6.  1.  1.  2.  6.  3.  1.  0.  6.  3.  1.  5.  4.\n",
      "  2.  2.  3.  0.  0.  1.  0.  5.  0.  6.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_data)\n",
    "print(y_data.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('./data/data-04-zoo.csv', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:,:-1]\n",
    "y_data = xy[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#클래스는 7가지 -> one_hot encoding으로 변경\n",
    "y_data = y_data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = np.zeros((len(y_data), np.max(y_data) + 1))\n",
    "y_one_hot[np.arange(len(y_data)), y_data] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내가 정의해야 하는 입력 데이터는 x_data 와 y_data에 대한 Placeholder<br/>\n",
    "내가 정의해야 하는 변수는 Softmax Regression의 Weight와 Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 16])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([16, 7]), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([7]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. cost function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax\n",
    "pred = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(pred), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. gradient descent 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction \n",
    "prediction = tf.argmax(pred, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.158416 3.30159\n",
      "200 1.0 0.0516882\n",
      "400 1.0 0.0268815\n",
      "600 1.0 0.0183329\n",
      "800 1.0 0.0139747\n",
      "1000 1.0 0.0113195\n",
      "1200 1.0 0.00952683\n",
      "1400 1.0 0.00823258\n",
      "1600 1.0 0.00725301\n",
      "1800 1.0 0.00648504\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # 초기화\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(2000):\n",
    "        [icost, iaccuracy, ioptimizer] = sess.run([cost, accuracy, optimizer], feed_dict= {X: x_data, Y: y_one_hot})\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(step, iaccuracy, icost)\n",
    "            \n",
    "        pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "    \n",
    "    for p, y in zip(pred, y_data.flatten()):\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
