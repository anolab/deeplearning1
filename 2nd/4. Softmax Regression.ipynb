{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./photo/softmax1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 개념 다지기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. softmax는 logistic regression의 multiclass 판<br/>\n",
    "    -> binary classification에서 multiclass classification으로 변경<br/><br/>\n",
    "    \n",
    "2. logistic regression의 경우 g(z): sigmoid function으로 H(X)를 0 <= H(X) = g(z) = g(X*w) <=1로 유지하고, 출력을 확률 값으로 변경<br/>\n",
    "    -> sigmoid regression의 경우 H(X): softmax function(e^Wk.T*x / sigma(e^Wi.T.x))를 사용<br/>\n",
    "    -> 마찬가지로 각 Class 에 속할 확률으로 표현<br/><br/>\n",
    "\n",
    "3. costfunction\n",
    "    -> cross entropy 개념<br/>\n",
    "    -> D(S, L) = sigma(실제 값(Li) * log(예측값=softmax(i))<br/>\n",
    "    -> W = W - learning_rate * derivative 로 이동하면서 개선 가능(왜냐하면 convex)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.데이터 및 변수 설정\n",
    "x_data = [[1,2,1,1],\n",
    "          [2,1,3,2],\n",
    "          [3,1,3,4],\n",
    "          [4,1,5,5],\n",
    "          [1,7,5,5],\n",
    "          [1,2,5,6],\n",
    "          [1,6,6,6],\n",
    "          [1,7,7,7]]\n",
    "\n",
    "y_data = [[0,0,1],\n",
    "          [0,0,1],\n",
    "          [0,0,1],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [0,1,0],\n",
    "          [1,0,0],\n",
    "          [1,0,0]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. 가설 설정\n",
    "#tf.nn.softmax computes softmax activation\n",
    "#softmax = exp(Logits) / reduce_sum(exp(Logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. cost 함수\n",
    "#Cross Entropy Loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 126.9\n",
      "200 49.4237\n",
      "400 18.1062\n",
      "600 2.0185\n",
      "800 55.5735\n",
      "1000 0.0242367\n",
      "1200 0.0161528\n",
      "1400 0.0129173\n",
      "1600 0.0112206\n",
      "1800 0.0102909\n",
      "2000 0.00979997\n",
      "[[  9.21498121e-12   1.00000000e+00   8.31275221e-14]] [1]\n",
      "[[  9.21498121e-12   1.00000000e+00   8.31275153e-14]\n",
      " [  9.99859095e-01   1.40729462e-04   7.95577648e-08]\n",
      " [  1.32816656e-35   1.38087417e-13   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#5. Launch\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "    \n",
    "    #6. Testing & One-hot encoding\n",
    "    a = sess.run(hypothesis, feed_dict={X:[[1,11,7,9]]})\n",
    "    print(a, sess.run(tf.argmax(a, 1)))\n",
    "    \n",
    "    all = sess.run(hypothesis, feed_dict={X: [[1,11,7,9],\n",
    "                                              [1,3,4,3],\n",
    "                                              [1,1,0,1]]})\n",
    "    print(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fancy Softmax Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5ed0af29abe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#현재\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcost_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "#기존\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_mean(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "#현재\n",
    "logits = tf.matmul(X,W)+b\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  1.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32),\n",
       " array([101,   1,   7], dtype=int32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. 데이터 및 변수 설정\n",
    "xy = np.loadtxt('./data/data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "nb_classes = 7\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 16])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "#Y_one_hot 출력\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "Y_one_hot_shape = tf.shape(Y_one_hot)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run([Y_one_hot, Y_one_hot_shape], feed_dict={Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32),\n",
       " array([0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 1, 3, 6, 6, 6, 1, 0, 3, 0, 1, 1, 0,\n",
       "        1, 5, 4, 4, 0, 0, 0, 5, 0, 0, 1, 3, 0, 0, 1, 3, 5, 5, 1, 5, 1, 0, 0,\n",
       "        6, 0, 0, 0, 0, 5, 4, 6, 0, 0, 1, 1, 1, 1, 3, 3, 2, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 6, 3, 0, 0, 2, 6, 1, 1, 2, 6, 3, 1, 0, 6, 3, 1, 5, 4, 2, 2,\n",
       "        3, 0, 0, 1, 0, 5, 0, 6, 1])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y_one_hot shape 조정\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "Y_one_hot_check = tf.argmax(Y_one_hot, 1)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run([Y_one_hot, Y_one_hot_check], feed_dict={Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_one_hot shape 조정\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "Y_one_hot_check = tf.argmax(Y_one_hot, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. hypothesis\n",
    "#tf.nn.softmax computes softmax activations\n",
    "logits = tf.matmul(X,W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "#3. cost\n",
    "#cross entropy cost/loss\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                 labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction \n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 6 2 2 2 2 1 6 2 2 2 6 2 2 2 2 2 6 6 2 3 2 3 2 2 2 2 2 2 2 2 2 2 6 2 2\n",
      " 2 6 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 6 6 1 2 2 2 6 2 2 2 2 3 2 6\n",
      " 6 6 1 2 2 2 2 2 6 3 2 2 1 3 2 2 3 2 6 2 2 1 1 2 2 2 3]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False  True False False False  True\n",
      " False False False False False]\n"
     ]
    }
   ],
   "source": [
    "#출력\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "arg_max = tf.argmax(Y_one_hot, 1)\n",
    "\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(prediction, feed_dict={X: x_data, Y: y_data}))\n",
    "print(sess.run(correct_prediction, feed_dict={X: x_data, Y: y_data}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 4.395\tAcc: 19.80%\n",
      "Step:   200\tLoss: 0.401\tAcc: 88.12%\n",
      "Step:   400\tLoss: 0.230\tAcc: 95.05%\n",
      "Step:   600\tLoss: 0.162\tAcc: 97.03%\n",
      "Step:   800\tLoss: 0.126\tAcc: 97.03%\n",
      "Step:  1000\tLoss: 0.103\tAcc: 99.01%\n",
      "Step:  1200\tLoss: 0.088\tAcc: 100.00%\n",
      "Step:  1400\tLoss: 0.076\tAcc: 100.00%\n",
      "Step:  1600\tLoss: 0.067\tAcc: 100.00%\n",
      "Step:  1800\tLoss: 0.060\tAcc: 100.00%\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "#5. Launch\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2000):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "        if step % 200 == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "\n",
    "        pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "    \n",
    "    for p, y in zip(pred, y_data.flatten()):\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 5.]\n",
      " [ 0.]\n",
      " [ 6.]\n",
      " [ 1.]]\n",
      "[ 0.  0.  3.  0.  0.  0.  0.  3.  3.  0.  0.  1.  3.  6.  6.  6.  1.  0.\n",
      "  3.  0.  1.  1.  0.  1.  5.  4.  4.  0.  0.  0.  5.  0.  0.  1.  3.  0.\n",
      "  0.  1.  3.  5.  5.  1.  5.  1.  0.  0.  6.  0.  0.  0.  0.  5.  4.  6.\n",
      "  0.  0.  1.  1.  1.  1.  3.  3.  2.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  6.  3.  0.  0.  2.  6.  1.  1.  2.  6.  3.  1.  0.  6.  3.  1.  5.  4.\n",
      "  2.  2.  3.  0.  0.  1.  0.  5.  0.  6.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_data)\n",
    "print(y_data.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
